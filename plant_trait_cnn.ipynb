{
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30627,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giyeongyoon/3rd_AGC/blob/master/plant_trait_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install albumentations==1.1.0\n",
        "!pip install agml"
      ],
      "metadata": {
        "id": "P7YSvf_oKlPr",
        "execution": {
          "iopub.status.busy": "2023-12-18T06:31:44.926292Z",
          "iopub.execute_input": "2023-12-18T06:31:44.926662Z",
          "iopub.status.idle": "2023-12-18T06:32:10.533333Z",
          "shell.execute_reply.started": "2023-12-18T06:31:44.926635Z",
          "shell.execute_reply": "2023-12-18T06:32:10.532104Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries"
      ],
      "metadata": {
        "id": "XeVhzZvgLCt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision import models, transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import albumentations as A\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "metadata": {
        "id": "6BZ4j2lzK6wQ",
        "execution": {
          "iopub.status.busy": "2023-12-18T06:33:54.782802Z",
          "iopub.execute_input": "2023-12-18T06:33:54.783659Z",
          "iopub.status.idle": "2023-12-18T06:34:09.131801Z",
          "shell.execute_reply.started": "2023-12-18T06:33:54.783618Z",
          "shell.execute_reply": "2023-12-18T06:34:09.130906Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download 2021 Autonomous Greenhouse Challenge dataset"
      ],
      "metadata": {
        "id": "JhSMln48K_iJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import agml\n",
        "loader = agml.data.AgMLDataLoader('autonomous_greenhouse_regression', dataset_path = './')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "T3-oDY-ZLBdJ",
        "outputId": "7bd30879-d726-4d37-b3da-b0fd312c07c4",
        "execution": {
          "iopub.status.busy": "2023-12-18T06:34:09.133680Z",
          "iopub.execute_input": "2023-12-18T06:34:09.134252Z",
          "iopub.status.idle": "2023-12-18T06:34:58.928141Z",
          "shell.execute_reply.started": "2023-12-18T06:34:09.134223Z",
          "shell.execute_reply": "2023-12-18T06:34:58.926537Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading autonomous_greenhouse_regression (size = 887.2 MB): 887226368it [00:10, 87914936.51it/s]                               \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AgML Download]: Extracting files for autonomous_greenhouse_regression... Done!\n",
            "\n",
            "====================================================================================================\n",
            "You have just downloaded \u001b[1mautonomous_greenhouse_regression\u001b[0m.\n",
            "\n",
            "This dataset is licensed under the \u001b[1mCC BY-SA 4.0\u001b[0m license.\n",
            "To learn more, visit: https://creativecommons.org/licenses/by-sa/4.0/\n",
            "\n",
            "When using this dataset, please cite the following:\n",
            "\n",
            "@misc{https://doi.org/10.4121/15023088.v1,\n",
            "  doi = {10.4121/15023088.V1},\n",
            "  url = {https://data.4tu.nl/articles/_/15023088/1},\n",
            "  author = {Hemming,  S. (Silke) and de Zwart,  H.F. (Feije) and Elings,  A. (Anne) and bijlaard,  monique and Marrewijk,  van,  Bart and Petropoulou,  Anna},\n",
            "  keywords = {Horticultural Crops,  Mechanical Engineering,  FOS: Mechanical engineering,  Artificial Intelligence and Image Processing,  FOS: Computer and information sciences,  Horticultural Production,  FOS: Agriculture,  forestry and fisheries,  Autonomous Greenhouse Challenge,  autonomous greenhouse,  Artificial Intelligence,  image processing,  computer vision,  Horticulture,  Lettuce,  sensors,  non-destructive sensing},\n",
            "  title = {3rd Autonomous Greenhouse Challenge: Online Challenge Lettuce Images},\n",
            "  publisher = {4TU.ResearchData},\n",
            "  year = {2021},\n",
            "  copyright = {Creative Commons Attribution 4.0 International}\n",
            "}\n",
            "\n",
            "You can find additional information about this dataset at:\n",
            "https://data.4tu.nl/articles/dataset/3rd_Autonomous_Greenhouse_Challenge_Online_Challenge_Lettuce_Images/15023088/1\n",
            "\n",
            "This message will \u001b[1mnot\u001b[0m be automatically shown\n",
            "again. To view this message again, in an AgMLDataLoader\n",
            "run `loader.info.citation_summary()`. Otherwise, you\n",
            "can use `agml.data.source(<name>).citation_summary().`\n",
            "\n",
            "You can find your dataset at /content/autonomous_greenhouse_regression.\n",
            "====================================================================================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/agml/data/metadata.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;31m# Some weird behavior with lookups can happen.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/agml/data/metadata.py\u001b[0m in \u001b[0;36mnum_to_class\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m                     \u001b[0mnums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m                     \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_type\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnums\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'keys'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-2fbc67e4142a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0magml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAgMLDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'autonomous_greenhouse_regression'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/agml/data/loader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;34m'classes'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;34m'num_classes'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0;34m'num_to_class'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_to_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m             \u001b[0;34m'class_to_num'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_to_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             'data_distributions': {self.name: self._info.num_images}}\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/agml/data/metadata.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             raise AttributeError(\n\u001b[0m\u001b[1;32m    158\u001b[0m                 maybe_you_meant(\n\u001b[1;32m    159\u001b[0m                     \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Received invalid info parameter: '{key}'.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Received invalid info parameter: 'num_to_class'."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define data and output directories"
      ],
      "metadata": {
        "id": "D5kHbdg3LMBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sav_dir='model_weights/'\n",
        "if not os.path.exists(sav_dir):\n",
        "    os.mkdir(sav_dir)\n",
        "# Comment these two lines and uncomment the next two if you've already croppped the images to another directory\n",
        "RGB_Data_Dir   = './autonomous_greenhouse_regression/images/'\n",
        "Depth_Data_Dir = './autonomous_greenhouse_regression/depth_images/'\n",
        "\n",
        "\n",
        "# RGB_Data_Dir='./autonomous_greenhouse_regression/cropped_images/'\n",
        "# Depth_Data_Dir='./autonomous_greenhouse_regression/cropped_depth_images/'\n",
        "\n",
        "\n",
        "JSON_Files_Dir = './autonomous_greenhouse_regression/annotations.json'"
      ],
      "metadata": {
        "id": "8BTdADxwLLH0",
        "execution": {
          "iopub.status.busy": "2023-12-18T06:57:28.688438Z",
          "iopub.execute_input": "2023-12-18T06:57:28.689264Z",
          "iopub.status.idle": "2023-12-18T06:57:28.694559Z",
          "shell.execute_reply.started": "2023-12-18T06:57:28.689222Z",
          "shell.execute_reply": "2023-12-18T06:57:28.693637Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Crop"
      ],
      "metadata": {
        "id": "Xwp2Qb1KLPNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "min_x=650\n",
        "max_x=1450\n",
        "min_y=200\n",
        "max_y=900\n",
        "cropped_img_dir='./autonomous_greenhouse_regression/cropped_images/'\n",
        "\n",
        "cropped_depth_img_dir='./autonomous_greenhouse_regression/cropped_depth_images/'\n",
        "\n",
        "if not os.path.exists(cropped_img_dir):\n",
        "    os.mkdir(cropped_img_dir)\n",
        "\n",
        "if not os.path.exists(cropped_depth_img_dir):\n",
        "    os.mkdir(cropped_depth_img_dir)\n",
        "\n",
        "for im in os.listdir(RGB_Data_Dir):\n",
        "    img = cv2.imread(RGB_Data_Dir+im)\n",
        "    crop_img = img[min_y:max_y,min_x:max_x]\n",
        "    cv2.imwrite(cropped_img_dir+im, crop_img)\n",
        "\n",
        "for depth_im in os.listdir(Depth_Data_Dir):\n",
        "    depth_img = cv2.imread(Depth_Data_Dir+depth_im, 0)\n",
        "    crop_depth_img = depth_img[min_y:max_y,min_x:max_x]\n",
        "    cv2.imwrite(cropped_depth_img_dir+depth_im, crop_depth_img)\n",
        "\n",
        "RGB_Data_Dir   = cropped_img_dir\n",
        "Depth_Data_Dir = cropped_depth_img_dir"
      ],
      "metadata": {
        "id": "5P0jSdmTLPyW",
        "execution": {
          "iopub.status.busy": "2023-12-18T06:57:30.265688Z",
          "iopub.execute_input": "2023-12-18T06:57:30.266551Z",
          "iopub.status.idle": "2023-12-18T06:58:07.053571Z",
          "shell.execute_reply.started": "2023-12-18T06:57:30.266515Z",
          "shell.execute_reply": "2023-12-18T06:58:07.052528Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create PyTorch dataset, create PyTorch dataloader, and split train/val/test"
      ],
      "metadata": {
        "id": "ZIGY6TuxLSs-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split_seed = 12"
      ],
      "metadata": {
        "id": "Lfl_4s8ILTMC",
        "execution": {
          "iopub.status.busy": "2023-12-18T06:58:07.055214Z",
          "iopub.execute_input": "2023-12-18T06:58:07.055521Z",
          "iopub.status.idle": "2023-12-18T06:58:07.059515Z",
          "shell.execute_reply.started": "2023-12-18T06:58:07.055495Z",
          "shell.execute_reply": "2023-12-18T06:58:07.058583Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GreenhouseDataset(Dataset):\n",
        "    def __init__(self, rgb_dir, d_dir, jsonfile_dir, rgb_transforms=None, d_transforms=None):\n",
        "\n",
        "        self.df= pd.read_json(jsonfile_dir)\n",
        "        # flatten_json is a custom function to flat the nested json files!\n",
        "\n",
        "        self.rgb_transforms = rgb_transforms\n",
        "        self.d_transforms = d_transforms\n",
        "        self.rgb_dir = rgb_dir\n",
        "        self.d_dir = d_dir\n",
        "        self.num_outputs = len(self.df.iloc[0]['outputs']['regression'])\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # load images\n",
        "        row=self.df.iloc[idx]\n",
        "\n",
        "        rgb = plt.imread(self.rgb_dir+row['image'])\n",
        "        depth = plt.imread(self.d_dir+row['depth_image'])\n",
        "        depth = np.expand_dims(depth, 2)\n",
        "\n",
        "        target = list(row['outputs']['regression'].values())\n",
        "\n",
        "        #make sure your img and mask array are in this format before passing into albumentations transforms, img.shape=[H, W, C]\n",
        "        if self.rgb_transforms is not None:\n",
        "            aug_rgb = self.rgb_transforms(image=rgb)\n",
        "            rgb = aug_rgb['image']\n",
        "        elif self.d_transforms is not None:\n",
        "            aug_depth = self.d_transforms(image=depth)\n",
        "            depth = aug_depth['image']\n",
        "\n",
        "        rgb = np.transpose(rgb, (2,0,1))\n",
        "        depth = np.transpose(depth, (2,0,1))\n",
        "\n",
        "        #pytorch wants a different format for the image ([C, H, W])\n",
        "        rgb = torch.as_tensor(rgb, dtype=torch.float32)\n",
        "        depth = torch.as_tensor(depth, dtype=torch.float32)\n",
        "        target=torch.as_tensor(target, dtype=torch.float32)\n",
        "\n",
        "        return rgb, depth, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)"
      ],
      "metadata": {
        "id": "ZXdeZfsiLZIJ",
        "execution": {
          "iopub.status.busy": "2023-12-18T06:58:07.060951Z",
          "iopub.execute_input": "2023-12-18T06:58:07.061374Z",
          "iopub.status.idle": "2023-12-18T06:58:07.073398Z",
          "shell.execute_reply.started": "2023-12-18T06:58:07.061341Z",
          "shell.execute_reply": "2023-12-18T06:58:07.072556Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## FIGURE OUT HOW TO CROP ALL THE IMAGES TO GET RID OF EXTRANIOUS PIXELS\n",
        "def get_transforms(train, means, stds):\n",
        "    if train:\n",
        "        transforms = A.Compose([\n",
        "        # A.Crop(x_min=650, y_min=200, x_max=1450, y_max=900, always_apply=False, p=1.0),\n",
        "        A.Flip(p=0.5),\n",
        "        A.ShiftScaleRotate(always_apply=False, p=0.5, shift_limit=(-0.06, 0.06), scale_limit=(-0.1, 0.1), rotate_limit=(-5, 5), interpolation=0, border_mode=0, value=means, mask_value=None),\n",
        "        A.Normalize(mean=means, std=stds, max_pixel_value=1.0, always_apply=False, p=1.0)\n",
        "        ])\n",
        "    else:\n",
        "        transforms =  A.Compose([\n",
        "        # A.Crop(x_min=650, y_min=200, x_max=1450, y_max=900, always_apply=False, p=1.0),\n",
        "        A.Normalize(mean=means, std=stds, max_pixel_value=1.0, always_apply=False, p=1.0)\n",
        "        ])\n",
        "    return transforms"
      ],
      "metadata": {
        "id": "__m1vXj4LcDy",
        "execution": {
          "iopub.status.busy": "2023-12-18T06:58:07.076054Z",
          "iopub.execute_input": "2023-12-18T06:58:07.076376Z",
          "iopub.status.idle": "2023-12-18T06:58:07.086696Z",
          "shell.execute_reply.started": "2023-12-18T06:58:07.076342Z",
          "shell.execute_reply": "2023-12-18T06:58:07.085721Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the PyTorch datalaoder the autonomous greenhouse dataset.\n",
        "dataset = GreenhouseDataset(rgb_dir = RGB_Data_Dir,\n",
        "                            d_dir = Depth_Data_Dir,\n",
        "                            jsonfile_dir = JSON_Files_Dir,\n",
        "                            rgb_transforms = get_transforms(train=False, means=[0,0,0],stds=[1,1,1]),\n",
        "                            d_transforms = get_transforms(train=False, means=[0,0,0],stds=[1,1,1]))\n",
        "\n",
        "# Remove last 50 images from training/validation set. These are the test set.\n",
        "dataset.df= dataset.df.iloc[:-50]\n",
        "\n",
        "# Split train and validation set. Stratify based on variety.\n",
        "train_split, val_split = train_test_split(dataset.df,\n",
        "                                          test_size = 0.2,\n",
        "                                          random_state = split_seed,\n",
        "                                          stratify = dataset.df['outputs'].str['classification']) #change to None if you don't have class info\n",
        "train = torch.utils.data.Subset(dataset, train_split.index.tolist())\n",
        "val   = torch.utils.data.Subset(dataset, val_split.index.tolist())\n",
        "\n",
        "# Create train and validation dataloaders\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size=6, num_workers=6, shuffle=True)\n",
        "val_loader   = torch.utils.data.DataLoader(val,   batch_size=6, shuffle=False, num_workers=6)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjw72weiLdB-",
        "outputId": "b91664af-d44a-4994-8fd5-f8fd91e1f1d3",
        "execution": {
          "iopub.status.busy": "2023-12-18T06:58:07.087749Z",
          "iopub.execute_input": "2023-12-18T06:58:07.088100Z",
          "iopub.status.idle": "2023-12-18T06:58:07.124658Z",
          "shell.execute_reply.started": "2023-12-18T06:58:07.088075Z",
          "shell.execute_reply": "2023-12-18T06:58:07.123853Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Determine the mean and standard deviation of images for normalization (Only need to do once for a new dataset)"
      ],
      "metadata": {
        "id": "vGXtUu6LLiHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this part is just to check the MEAN and STD of the dataset (dont run unless you need mu and sigma)\n",
        "\n",
        "n_rgb = 0\n",
        "n_depth = 0\n",
        "mean_rgb = 0.\n",
        "std_rgb = 0.\n",
        "mean_depth = 0.\n",
        "std_depth = 0.\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=5, shuffle=False, num_workers=12)\n",
        "for rgb, depth, _ in dataloader:\n",
        "\n",
        "    # Rearrange batch to be the shape of [B, C, W * H]\n",
        "    rgb = rgb.view(rgb.size(0), rgb.size(1), -1)\n",
        "    depth = depth.view(depth.size(0), depth.size(1), -1)\n",
        "    # Update total number of images\n",
        "    n_rgb += rgb.size(0)\n",
        "    n_depth += depth.size(0)\n",
        "    # Compute mean and std here\n",
        "    mean_rgb += rgb.mean(2).sum(0)\n",
        "    std_rgb += rgb.std(2).sum(0)\n",
        "    mean_depth += depth.mean(2).sum(0)\n",
        "    std_depth += depth.std(2).sum(0)\n",
        "\n",
        "# Final step\n",
        "mean_rgb /= n_rgb\n",
        "std_rgb /= n_rgb\n",
        "mean_depth /= n_depth\n",
        "std_depth /= n_depth\n",
        "\n",
        "print('Mean of RGB: '+ str(mean_rgb))\n",
        "print('Standard Deviation of RGB', str(std_rgb))\n",
        "print('Mean of Depth: '+ str(mean_depth))\n",
        "print('Standard Deviation of Depth', str(std_depth))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHD3FI6ULioT",
        "outputId": "d9ed6125-4a70-4726-dfcc-853e7f47b06b",
        "execution": {
          "iopub.status.busy": "2023-12-18T06:58:07.125749Z",
          "iopub.execute_input": "2023-12-18T06:58:07.126087Z",
          "iopub.status.idle": "2023-12-18T06:58:16.946956Z",
          "shell.execute_reply.started": "2023-12-18T06:58:07.126058Z",
          "shell.execute_reply": "2023-12-18T06:58:16.945869Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean of RGB: tensor([0.5482, 0.4620, 0.3602])\n",
            "Standard Deviation of RGB tensor([0.1639, 0.1761, 0.2659])\n",
            "Mean of Depth: tensor([0.0127])\n",
            "Standard Deviation of Depth tensor([0.0035])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy the output of the previous cells into here to avoid needing to redetermine mean and std every time"
      ],
      "metadata": {
        "id": "6eveLzxiLlUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.means = [0.5482, 0.4620, 0.3602, 0.0127]  #these values were copied from the previous cell\n",
        "dataset.stds = [0.1639, 0.1761, 0.2659, 0.0035]   #copy and paste the values to avoid having\n",
        "                                                  # to rerun the previous cell for every iteration"
      ],
      "metadata": {
        "id": "qAp_KbHvLl0P",
        "execution": {
          "iopub.status.busy": "2023-12-18T06:58:16.948423Z",
          "iopub.execute_input": "2023-12-18T06:58:16.948785Z",
          "iopub.status.idle": "2023-12-18T06:58:16.953763Z",
          "shell.execute_reply.started": "2023-12-18T06:58:16.948750Z",
          "shell.execute_reply": "2023-12-18T06:58:16.952906Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set device"
      ],
      "metadata": {
        "id": "B9is_me-LndB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')"
      ],
      "metadata": {
        "id": "AhORwK3MLo4y",
        "execution": {
          "iopub.status.busy": "2023-12-18T06:58:16.954946Z",
          "iopub.execute_input": "2023-12-18T06:58:16.955300Z",
          "iopub.status.idle": "2023-12-18T06:58:16.962715Z",
          "shell.execute_reply.started": "2023-12-18T06:58:16.955270Z",
          "shell.execute_reply": "2023-12-18T06:58:16.962025Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model"
      ],
      "metadata": {
        "id": "7dMdA76JLuEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PlantTraitModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PlantTraitModel, self).__init__()\n",
        "        # RGB Model\n",
        "        self.resNet1rgb = models.resnet18(pretrained = True)\n",
        "        self.resNet2rgb = models.resnet18(pretrained = True)\n",
        "        self.depthEncoder1 = nn.Sequential(nn.Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), nn.ReLU(), models.resnet18(pretrained = True))\n",
        "        self.depthEncoder2 = nn.Sequential(nn.Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), nn.ReLU(), models.resnet18(pretrained = True))\n",
        "\n",
        "        dropout_p = 0.05\n",
        "        self.fcn1 = nn.Sequential(nn.Dropout(dropout_p), nn.ReLU(), nn.Linear(2000, 1000), nn.ReLU(), nn.Dropout(dropout_p), nn.Linear(1000, 500), nn.Dropout(dropout_p), nn.ReLU(), nn.Linear(500, 1), nn.ReLU())\n",
        "        self.fcn2 = nn.Sequential(nn.Dropout(dropout_p), nn.ReLU(), nn.Linear(2000, 1000), nn.ReLU(), nn.Dropout(dropout_p), nn.Linear(1000, 500), nn.Dropout(dropout_p), nn.ReLU(), nn.Linear(500, 1), nn.ReLU())\n",
        "\n",
        "    def forward(self, rgb, depth):\n",
        "        out1 = self.fcn1(torch.cat([self.resNet1rgb(rgb), self.depthEncoder1(depth)], dim = 1))\n",
        "        out2 = self.fcn2(torch.cat([self.resNet2rgb(rgb), self.depthEncoder2(depth)], dim = 1))\n",
        "        outs = torch.cat([out1, out2], dim = 1)  # fresh weight, dry weight\n",
        "\n",
        "        return outs"
      ],
      "metadata": {
        "id": "bFOdKraL-LqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = PlantTraitModel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EryoPktnMl9w",
        "outputId": "d0ddec57-14dd-4aac-9afc-3171339a2660",
        "execution": {
          "iopub.status.busy": "2023-12-18T08:14:20.085716Z",
          "iopub.execute_input": "2023-12-18T08:14:20.086384Z",
          "iopub.status.idle": "2023-12-18T08:14:23.066113Z",
          "shell.execute_reply.started": "2023-12-18T08:14:20.086348Z",
          "shell.execute_reply": "2023-12-18T08:14:23.065058Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 162MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter"
      ],
      "metadata": {
        "id": "jgW2kfIZMs_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.0005\n",
        "epochs = 400"
      ],
      "metadata": {
        "id": "RftkG91CMu32",
        "execution": {
          "iopub.status.busy": "2023-12-18T08:14:33.253788Z",
          "iopub.execute_input": "2023-12-18T08:14:33.254180Z",
          "iopub.status.idle": "2023-12-18T08:14:33.258686Z",
          "shell.execute_reply.started": "2023-12-18T08:14:33.254147Z",
          "shell.execute_reply": "2023-12-18T08:14:33.257772Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NMSE loss"
      ],
      "metadata": {
        "id": "XPEmPNzLNG6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NMSELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "          # super(diceloss, self).init()\n",
        "        super(NMSELoss, self).__init__()\n",
        "          # print('HI')\n",
        "    def forward(self, pred, target):\n",
        "        if target.size() != pred.size():\n",
        "              raise ValueError(\"Target size ({}) must be the same as input size ({})\".format(target.size(), pred.size()))\n",
        "\n",
        "        num=torch.sum((target-pred)**2,0)\n",
        "        den=torch.sum(target**2,0)\n",
        "\n",
        "        return torch.sum(num/den)"
      ],
      "metadata": {
        "id": "W7B_B5Y9NKbH",
        "execution": {
          "iopub.status.busy": "2023-12-18T08:14:35.907035Z",
          "iopub.execute_input": "2023-12-18T08:14:35.907378Z",
          "iopub.status.idle": "2023-12-18T08:14:35.913930Z",
          "shell.execute_reply.started": "2023-12-18T08:14:35.907354Z",
          "shell.execute_reply": "2023-12-18T08:14:35.912871Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss and optimizer"
      ],
      "metadata": {
        "id": "dbPA1SYpNAqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = NMSELoss()\n",
        "# optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "optimizer = torch.optim.Adam(model.parameters(),\n",
        "                            lr=lr,\n",
        "                            betas=(0.9, 0.999),\n",
        "                            eps=1e-08,\n",
        "                            weight_decay = 0,\n",
        "                            amsgrad = False)"
      ],
      "metadata": {
        "id": "QgiJS3F_NCXm",
        "execution": {
          "iopub.status.busy": "2023-12-18T08:14:37.715799Z",
          "iopub.execute_input": "2023-12-18T08:14:37.716185Z",
          "iopub.status.idle": "2023-12-18T08:14:37.723086Z",
          "shell.execute_reply.started": "2023-12-18T08:14:37.716151Z",
          "shell.execute_reply": "2023-12-18T08:14:37.722024Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train"
      ],
      "metadata": {
        "id": "W3mXlgx1M3th"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_single_epoch(model, dataset, device,\n",
        "                       criterion, optimizer,\n",
        "                       writer, epoch, train_loader):\n",
        "    model.train()\n",
        "\n",
        "    dataset.rgb_transforms = get_transforms(train=True, means=dataset.means[:3], stds=dataset.stds[:3])\n",
        "    dataset.d_transforms = get_transforms(train=True, means=dataset.means[3:], stds=dataset.stds[3:])\n",
        "\n",
        "    for i, (rgb, depth, label) in enumerate(train_loader):\n",
        "        rgb = rgb.to(device)\n",
        "        depth = depth.to(device)\n",
        "        label = label.to(device)  # ['FreshWeightShoot', 'DryWeightShoot', 'Height', 'Diameter', 'LeafArea']\n",
        "\n",
        "        # Forward pass\n",
        "        pred = model(rgb, depth)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(pred, label[:, :2])\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Batch {i+1}/{len(train_loader)}, Loss: {loss.item()}')\n",
        "        with open('run.txt', 'a') as f:\n",
        "            f.write('\\n')\n",
        "            f.write('Train MSE: '+ str(loss.tolist()))\n"
      ],
      "metadata": {
        "id": "atHQ5B1XM5NP",
        "execution": {
          "iopub.status.busy": "2023-12-18T08:14:39.664702Z",
          "iopub.execute_input": "2023-12-18T08:14:39.665418Z",
          "iopub.status.idle": "2023-12-18T08:14:39.674811Z",
          "shell.execute_reply.started": "2023-12-18T08:14:39.665380Z",
          "shell.execute_reply": "2023-12-18T08:14:39.673806Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, dataset, device, sav_dir, criterion, writer, epoch, val_loader, best_val_loss):\n",
        "    current_val_loss = 0\n",
        "    # training_val_loss=0s\n",
        "\n",
        "    model.eval()\n",
        "    print('Validating and Checkpointing!')\n",
        "\n",
        "    dataset.rgb_transforms = get_transforms(train=True, means=dataset.means[:3], stds=dataset.stds[:3])\n",
        "    dataset.d_transforms = get_transforms(train=True, means=dataset.means[3:], stds=dataset.stds[3:])\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (rgb, depth, label) in enumerate(val_loader):\n",
        "            rgb = rgb.to(device)\n",
        "            depth = depth.to(device)\n",
        "            label = label.to(device)\n",
        "\n",
        "            pred = model(rgb, depth)\n",
        "\n",
        "            loss = criterion(pred, label[:, :2])\n",
        "            # acc=nmse(preds.detach(), targets)\n",
        "            current_val_loss = current_val_loss + loss.item()\n",
        "            # training_val_loss=training_val_loss+loss.detach().cpu().numpy()\n",
        "\n",
        "        # writer.add_scalar(\"MSE Loss/val\", training_val_loss, epoch)\n",
        "        writer.add_scalar(\"MSE Loss/val\", current_val_loss, epoch)\n",
        "\n",
        "    if current_val_loss < best_val_loss or epoch == 0:\n",
        "        best_val_loss = current_val_loss\n",
        "        torch.save(model.state_dict(), sav_dir+'bestmodel' + '.pth')\n",
        "        print('Best model Saved! Val MSE: ', str(best_val_loss))\n",
        "        with open('run.txt', 'a') as f:\n",
        "            f.write('\\n')\n",
        "            f.write('Best model Saved! Val MSE: '+ str(best_val_loss))\n",
        "\n",
        "    else:\n",
        "        print('Model is not good (might be overfitting)! Current val MSE: ', str(current_val_loss), 'Best Val MSE: ', str(best_val_loss))\n",
        "        with open('run.txt', 'a') as f:\n",
        "            f.write('\\n')\n",
        "            f.write('Model is not good (might be overfitting)! Current val MSE: '+ str(current_val_loss)+ 'Best Val MSE: '+ str(best_val_loss))\n",
        "    return best_val_loss"
      ],
      "metadata": {
        "id": "ieE0dxwgP3F0",
        "execution": {
          "iopub.status.busy": "2023-12-18T08:14:40.210955Z",
          "iopub.execute_input": "2023-12-18T08:14:40.211334Z",
          "iopub.status.idle": "2023-12-18T08:14:40.223403Z",
          "shell.execute_reply.started": "2023-12-18T08:14:40.211302Z",
          "shell.execute_reply": "2023-12-18T08:14:40.222428Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "\n",
        "best_val_loss = 9999999 # initial dummy value\n",
        "current_val_loss = 0\n",
        "\n",
        "writer = SummaryWriter()\n",
        "start = time.time()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    with open('run.txt', 'a') as f:\n",
        "                f.write('\\n')\n",
        "                f.write('Epoch: '+ str(epoch + 1) + ', Time Elapsed: '+ str((time.time()-start)/60) + ' mins')\n",
        "    print('Epoch: ', str(epoch + 1), ', Time Elapsed: ', str((time.time()-start)/60), ' mins')\n",
        "    train_single_epoch(model, dataset, device,\n",
        "                        criterion, optimizer,\n",
        "                        writer, epoch, train_loader)\n",
        "    best_val_loss = validate(model, dataset, device, sav_dir,\n",
        "                                criterion, writer, epoch, val_loader, best_val_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B38GTKhJP6rJ",
        "outputId": "07b7b393-447e-4cba-be17-145329dccf4c",
        "execution": {
          "iopub.status.busy": "2023-12-18T08:14:43.115392Z",
          "iopub.execute_input": "2023-12-18T08:14:43.116068Z",
          "iopub.status.idle": "2023-12-18T08:46:44.793672Z",
          "shell.execute_reply.started": "2023-12-18T08:14:43.116032Z",
          "shell.execute_reply": "2023-12-18T08:46:44.792474Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "Epoch 140/400, Batch 33/45, Loss: 0.03937474638223648\n",
            "Epoch 140/400, Batch 34/45, Loss: 0.10786815732717514\n",
            "Epoch 140/400, Batch 35/45, Loss: 0.08383471518754959\n",
            "Epoch 140/400, Batch 36/45, Loss: 0.0375974215567112\n",
            "Epoch 140/400, Batch 37/45, Loss: 0.05634515359997749\n",
            "Epoch 140/400, Batch 38/45, Loss: 0.4323814809322357\n",
            "Epoch 140/400, Batch 39/45, Loss: 0.03902170807123184\n",
            "Epoch 140/400, Batch 40/45, Loss: 0.2003374546766281\n",
            "Epoch 140/400, Batch 41/45, Loss: 0.06542736291885376\n",
            "Epoch 140/400, Batch 42/45, Loss: 0.11878029257059097\n",
            "Epoch 140/400, Batch 43/45, Loss: 0.12333615869283676\n",
            "Epoch 140/400, Batch 44/45, Loss: 0.08078011870384216\n",
            "Epoch 140/400, Batch 45/45, Loss: 0.17127853631973267\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  2.976848915219307 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  141 , Time Elapsed:  111.69883975187938  mins\n",
            "Epoch 141/400, Batch 1/45, Loss: 0.11713463813066483\n",
            "Epoch 141/400, Batch 2/45, Loss: 0.06365278363227844\n",
            "Epoch 141/400, Batch 3/45, Loss: 0.09288875013589859\n",
            "Epoch 141/400, Batch 4/45, Loss: 0.0907839834690094\n",
            "Epoch 141/400, Batch 5/45, Loss: 0.05063507333397865\n",
            "Epoch 141/400, Batch 6/45, Loss: 0.07092730700969696\n",
            "Epoch 141/400, Batch 7/45, Loss: 0.12106405198574066\n",
            "Epoch 141/400, Batch 8/45, Loss: 0.14455768465995789\n",
            "Epoch 141/400, Batch 9/45, Loss: 0.06330201029777527\n",
            "Epoch 141/400, Batch 10/45, Loss: 0.09972824901342392\n",
            "Epoch 141/400, Batch 11/45, Loss: 0.043110545724630356\n",
            "Epoch 141/400, Batch 12/45, Loss: 0.11301027238368988\n",
            "Epoch 141/400, Batch 13/45, Loss: 0.028057334944605827\n",
            "Epoch 141/400, Batch 14/45, Loss: 0.010819075629115105\n",
            "Epoch 141/400, Batch 15/45, Loss: 0.0634562149643898\n",
            "Epoch 141/400, Batch 16/45, Loss: 0.2858692705631256\n",
            "Epoch 141/400, Batch 17/45, Loss: 0.03844070062041283\n",
            "Epoch 141/400, Batch 18/45, Loss: 0.024951456114649773\n",
            "Epoch 141/400, Batch 19/45, Loss: 0.04162490367889404\n",
            "Epoch 141/400, Batch 20/45, Loss: 0.05341821163892746\n",
            "Epoch 141/400, Batch 21/45, Loss: 0.132594496011734\n",
            "Epoch 141/400, Batch 22/45, Loss: 0.05589650571346283\n",
            "Epoch 141/400, Batch 23/45, Loss: 0.054170504212379456\n",
            "Epoch 141/400, Batch 24/45, Loss: 0.048635248094797134\n",
            "Epoch 141/400, Batch 25/45, Loss: 0.024776611477136612\n",
            "Epoch 141/400, Batch 26/45, Loss: 0.030859246850013733\n",
            "Epoch 141/400, Batch 27/45, Loss: 0.013013563118875027\n",
            "Epoch 141/400, Batch 28/45, Loss: 0.078537218272686\n",
            "Epoch 141/400, Batch 29/45, Loss: 0.056538596749305725\n",
            "Epoch 141/400, Batch 30/45, Loss: 0.0402207188308239\n",
            "Epoch 141/400, Batch 31/45, Loss: 0.043311707675457\n",
            "Epoch 141/400, Batch 32/45, Loss: 0.043050460517406464\n",
            "Epoch 141/400, Batch 33/45, Loss: 0.040684547275304794\n",
            "Epoch 141/400, Batch 34/45, Loss: 0.12657968699932098\n",
            "Epoch 141/400, Batch 35/45, Loss: 0.13717037439346313\n",
            "Epoch 141/400, Batch 36/45, Loss: 0.08390472829341888\n",
            "Epoch 141/400, Batch 37/45, Loss: 0.058573897927999496\n",
            "Epoch 141/400, Batch 38/45, Loss: 0.04922543093562126\n",
            "Epoch 141/400, Batch 39/45, Loss: 0.09453564882278442\n",
            "Epoch 141/400, Batch 40/45, Loss: 0.044515084475278854\n",
            "Epoch 141/400, Batch 41/45, Loss: 0.05804125964641571\n",
            "Epoch 141/400, Batch 42/45, Loss: 0.026394542306661606\n",
            "Epoch 141/400, Batch 43/45, Loss: 0.0350249782204628\n",
            "Epoch 141/400, Batch 44/45, Loss: 0.051791056990623474\n",
            "Epoch 141/400, Batch 45/45, Loss: 0.07147412747144699\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.7775235511362553 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  142 , Time Elapsed:  112.48461339871089  mins\n",
            "Epoch 142/400, Batch 1/45, Loss: 0.04477385804057121\n",
            "Epoch 142/400, Batch 2/45, Loss: 0.03839515894651413\n",
            "Epoch 142/400, Batch 3/45, Loss: 0.03319492191076279\n",
            "Epoch 142/400, Batch 4/45, Loss: 0.046424783766269684\n",
            "Epoch 142/400, Batch 5/45, Loss: 0.014572988264262676\n",
            "Epoch 142/400, Batch 6/45, Loss: 0.0324489064514637\n",
            "Epoch 142/400, Batch 7/45, Loss: 0.11063560843467712\n",
            "Epoch 142/400, Batch 8/45, Loss: 0.09301389008760452\n",
            "Epoch 142/400, Batch 9/45, Loss: 0.03234926611185074\n",
            "Epoch 142/400, Batch 10/45, Loss: 0.016409387812018394\n",
            "Epoch 142/400, Batch 11/45, Loss: 0.04896637424826622\n",
            "Epoch 142/400, Batch 12/45, Loss: 0.04384087398648262\n",
            "Epoch 142/400, Batch 13/45, Loss: 0.06176796928048134\n",
            "Epoch 142/400, Batch 14/45, Loss: 0.03594870865345001\n",
            "Epoch 142/400, Batch 15/45, Loss: 0.07924511283636093\n",
            "Epoch 142/400, Batch 16/45, Loss: 0.09453778713941574\n",
            "Epoch 142/400, Batch 17/45, Loss: 0.0361582413315773\n",
            "Epoch 142/400, Batch 18/45, Loss: 0.062011294066905975\n",
            "Epoch 142/400, Batch 19/45, Loss: 0.021988645195961\n",
            "Epoch 142/400, Batch 20/45, Loss: 0.057991012930870056\n",
            "Epoch 142/400, Batch 21/45, Loss: 0.05820900574326515\n",
            "Epoch 142/400, Batch 22/45, Loss: 0.03132743015885353\n",
            "Epoch 142/400, Batch 23/45, Loss: 0.041576895862817764\n",
            "Epoch 142/400, Batch 24/45, Loss: 0.05503959581255913\n",
            "Epoch 142/400, Batch 25/45, Loss: 0.02040775492787361\n",
            "Epoch 142/400, Batch 26/45, Loss: 0.09502816200256348\n",
            "Epoch 142/400, Batch 27/45, Loss: 0.02090228721499443\n",
            "Epoch 142/400, Batch 28/45, Loss: 0.04290309175848961\n",
            "Epoch 142/400, Batch 29/45, Loss: 0.09114838391542435\n",
            "Epoch 142/400, Batch 30/45, Loss: 0.041503213346004486\n",
            "Epoch 142/400, Batch 31/45, Loss: 0.07563447207212448\n",
            "Epoch 142/400, Batch 32/45, Loss: 0.0995107889175415\n",
            "Epoch 142/400, Batch 33/45, Loss: 0.04644529148936272\n",
            "Epoch 142/400, Batch 34/45, Loss: 0.048256274312734604\n",
            "Epoch 142/400, Batch 35/45, Loss: 0.007018571719527245\n",
            "Epoch 142/400, Batch 36/45, Loss: 0.03135113790631294\n",
            "Epoch 142/400, Batch 37/45, Loss: 0.05983099341392517\n",
            "Epoch 142/400, Batch 38/45, Loss: 0.08291742205619812\n",
            "Epoch 142/400, Batch 39/45, Loss: 0.0352911502122879\n",
            "Epoch 142/400, Batch 40/45, Loss: 0.04286051169037819\n",
            "Epoch 142/400, Batch 41/45, Loss: 0.0345735028386116\n",
            "Epoch 142/400, Batch 42/45, Loss: 0.06744644790887833\n",
            "Epoch 142/400, Batch 43/45, Loss: 0.030127108097076416\n",
            "Epoch 142/400, Batch 44/45, Loss: 0.06042306870222092\n",
            "Epoch 142/400, Batch 45/45, Loss: 0.060356590896844864\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.5028739050030708 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  143 , Time Elapsed:  113.27935586770376  mins\n",
            "Epoch 143/400, Batch 1/45, Loss: 0.058337483555078506\n",
            "Epoch 143/400, Batch 2/45, Loss: 0.016754118725657463\n",
            "Epoch 143/400, Batch 3/45, Loss: 0.02476739138364792\n",
            "Epoch 143/400, Batch 4/45, Loss: 0.019904926419258118\n",
            "Epoch 143/400, Batch 5/45, Loss: 0.031838275492191315\n",
            "Epoch 143/400, Batch 6/45, Loss: 0.023926256224513054\n",
            "Epoch 143/400, Batch 7/45, Loss: 0.01888015866279602\n",
            "Epoch 143/400, Batch 8/45, Loss: 0.05322728678584099\n",
            "Epoch 143/400, Batch 9/45, Loss: 0.030478958040475845\n",
            "Epoch 143/400, Batch 10/45, Loss: 0.022248685359954834\n",
            "Epoch 143/400, Batch 11/45, Loss: 0.0075917793437838554\n",
            "Epoch 143/400, Batch 12/45, Loss: 0.057388488203287125\n",
            "Epoch 143/400, Batch 13/45, Loss: 0.08713454008102417\n",
            "Epoch 143/400, Batch 14/45, Loss: 0.0369570292532444\n",
            "Epoch 143/400, Batch 15/45, Loss: 0.02373446710407734\n",
            "Epoch 143/400, Batch 16/45, Loss: 0.04759426414966583\n",
            "Epoch 143/400, Batch 17/45, Loss: 0.0067593613639473915\n",
            "Epoch 143/400, Batch 18/45, Loss: 0.034868273884058\n",
            "Epoch 143/400, Batch 19/45, Loss: 0.01917140744626522\n",
            "Epoch 143/400, Batch 20/45, Loss: 0.02844715304672718\n",
            "Epoch 143/400, Batch 21/45, Loss: 0.14612753689289093\n",
            "Epoch 143/400, Batch 22/45, Loss: 0.025838397443294525\n",
            "Epoch 143/400, Batch 23/45, Loss: 0.0806477814912796\n",
            "Epoch 143/400, Batch 24/45, Loss: 0.11881047487258911\n",
            "Epoch 143/400, Batch 25/45, Loss: 0.01769864931702614\n",
            "Epoch 143/400, Batch 26/45, Loss: 0.03093034215271473\n",
            "Epoch 143/400, Batch 27/45, Loss: 0.06973450630903244\n",
            "Epoch 143/400, Batch 28/45, Loss: 0.049124836921691895\n",
            "Epoch 143/400, Batch 29/45, Loss: 0.1261165887117386\n",
            "Epoch 143/400, Batch 30/45, Loss: 0.0947837233543396\n",
            "Epoch 143/400, Batch 31/45, Loss: 0.0704856812953949\n",
            "Epoch 143/400, Batch 32/45, Loss: 0.05697527155280113\n",
            "Epoch 143/400, Batch 33/45, Loss: 0.1395077109336853\n",
            "Epoch 143/400, Batch 34/45, Loss: 0.05458877980709076\n",
            "Epoch 143/400, Batch 35/45, Loss: 0.03452363982796669\n",
            "Epoch 143/400, Batch 36/45, Loss: 0.00336863799020648\n",
            "Epoch 143/400, Batch 37/45, Loss: 0.18599556386470795\n",
            "Epoch 143/400, Batch 38/45, Loss: 0.10064850747585297\n",
            "Epoch 143/400, Batch 39/45, Loss: 0.03497187793254852\n",
            "Epoch 143/400, Batch 40/45, Loss: 0.02104979380965233\n",
            "Epoch 143/400, Batch 41/45, Loss: 0.04389398172497749\n",
            "Epoch 143/400, Batch 42/45, Loss: 0.044285718351602554\n",
            "Epoch 143/400, Batch 43/45, Loss: 0.04369955509901047\n",
            "Epoch 143/400, Batch 44/45, Loss: 0.07409091293811798\n",
            "Epoch 143/400, Batch 45/45, Loss: 0.057316988706588745\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.7961584627628326 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  144 , Time Elapsed:  114.08572138547898  mins\n",
            "Epoch 144/400, Batch 1/45, Loss: 0.03485695645213127\n",
            "Epoch 144/400, Batch 2/45, Loss: 0.017618602141737938\n",
            "Epoch 144/400, Batch 3/45, Loss: 0.03778544440865517\n",
            "Epoch 144/400, Batch 4/45, Loss: 0.08329708874225616\n",
            "Epoch 144/400, Batch 5/45, Loss: 0.03949727118015289\n",
            "Epoch 144/400, Batch 6/45, Loss: 0.03244253247976303\n",
            "Epoch 144/400, Batch 7/45, Loss: 0.054777514189481735\n",
            "Epoch 144/400, Batch 8/45, Loss: 0.05776475742459297\n",
            "Epoch 144/400, Batch 9/45, Loss: 0.0189810860902071\n",
            "Epoch 144/400, Batch 10/45, Loss: 0.07303348183631897\n",
            "Epoch 144/400, Batch 11/45, Loss: 0.015789911150932312\n",
            "Epoch 144/400, Batch 12/45, Loss: 0.02789008617401123\n",
            "Epoch 144/400, Batch 13/45, Loss: 0.054601117968559265\n",
            "Epoch 144/400, Batch 14/45, Loss: 0.046058427542448044\n",
            "Epoch 144/400, Batch 15/45, Loss: 0.023031864315271378\n",
            "Epoch 144/400, Batch 16/45, Loss: 0.03813770413398743\n",
            "Epoch 144/400, Batch 17/45, Loss: 0.04557199031114578\n",
            "Epoch 144/400, Batch 18/45, Loss: 0.031122148036956787\n",
            "Epoch 144/400, Batch 19/45, Loss: 0.11491186916828156\n",
            "Epoch 144/400, Batch 20/45, Loss: 0.016236577183008194\n",
            "Epoch 144/400, Batch 21/45, Loss: 0.048679087311029434\n",
            "Epoch 144/400, Batch 22/45, Loss: 0.10682544857263565\n",
            "Epoch 144/400, Batch 23/45, Loss: 0.02927973121404648\n",
            "Epoch 144/400, Batch 24/45, Loss: 0.04358932375907898\n",
            "Epoch 144/400, Batch 25/45, Loss: 0.045091159641742706\n",
            "Epoch 144/400, Batch 26/45, Loss: 0.01762997731566429\n",
            "Epoch 144/400, Batch 27/45, Loss: 0.03832191973924637\n",
            "Epoch 144/400, Batch 28/45, Loss: 0.02233739197254181\n",
            "Epoch 144/400, Batch 29/45, Loss: 0.05262003093957901\n",
            "Epoch 144/400, Batch 30/45, Loss: 0.04307802766561508\n",
            "Epoch 144/400, Batch 31/45, Loss: 0.049310583621263504\n",
            "Epoch 144/400, Batch 32/45, Loss: 0.035195544362068176\n",
            "Epoch 144/400, Batch 33/45, Loss: 0.02800603024661541\n",
            "Epoch 144/400, Batch 34/45, Loss: 0.08925595879554749\n",
            "Epoch 144/400, Batch 35/45, Loss: 0.026650797575712204\n",
            "Epoch 144/400, Batch 36/45, Loss: 0.04640571027994156\n",
            "Epoch 144/400, Batch 37/45, Loss: 0.05236854404211044\n",
            "Epoch 144/400, Batch 38/45, Loss: 0.0146644227206707\n",
            "Epoch 144/400, Batch 39/45, Loss: 0.07594489306211472\n",
            "Epoch 144/400, Batch 40/45, Loss: 0.033892177045345306\n",
            "Epoch 144/400, Batch 41/45, Loss: 0.031465064734220505\n",
            "Epoch 144/400, Batch 42/45, Loss: 0.008874790742993355\n",
            "Epoch 144/400, Batch 43/45, Loss: 0.03838125243782997\n",
            "Epoch 144/400, Batch 44/45, Loss: 0.03784426674246788\n",
            "Epoch 144/400, Batch 45/45, Loss: 0.01502454373985529\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.736775167286396 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  145 , Time Elapsed:  114.87931933403016  mins\n",
            "Epoch 145/400, Batch 1/45, Loss: 0.02507781609892845\n",
            "Epoch 145/400, Batch 2/45, Loss: 0.004841622896492481\n",
            "Epoch 145/400, Batch 3/45, Loss: 0.04421856626868248\n",
            "Epoch 145/400, Batch 4/45, Loss: 0.06604724377393723\n",
            "Epoch 145/400, Batch 5/45, Loss: 0.044932782649993896\n",
            "Epoch 145/400, Batch 6/45, Loss: 0.03366575390100479\n",
            "Epoch 145/400, Batch 7/45, Loss: 0.022716861218214035\n",
            "Epoch 145/400, Batch 8/45, Loss: 0.012570984661579132\n",
            "Epoch 145/400, Batch 9/45, Loss: 0.10413762927055359\n",
            "Epoch 145/400, Batch 10/45, Loss: 0.03929003328084946\n",
            "Epoch 145/400, Batch 11/45, Loss: 0.037447914481163025\n",
            "Epoch 145/400, Batch 12/45, Loss: 0.07120410352945328\n",
            "Epoch 145/400, Batch 13/45, Loss: 0.011268533766269684\n",
            "Epoch 145/400, Batch 14/45, Loss: 0.03405371308326721\n",
            "Epoch 145/400, Batch 15/45, Loss: 0.037814911454916\n",
            "Epoch 145/400, Batch 16/45, Loss: 0.025143258273601532\n",
            "Epoch 145/400, Batch 17/45, Loss: 0.04850570857524872\n",
            "Epoch 145/400, Batch 18/45, Loss: 0.07488792389631271\n",
            "Epoch 145/400, Batch 19/45, Loss: 0.029998138546943665\n",
            "Epoch 145/400, Batch 20/45, Loss: 0.014460464008152485\n",
            "Epoch 145/400, Batch 21/45, Loss: 0.07836075127124786\n",
            "Epoch 145/400, Batch 22/45, Loss: 0.04245612025260925\n",
            "Epoch 145/400, Batch 23/45, Loss: 0.054679449647665024\n",
            "Epoch 145/400, Batch 24/45, Loss: 0.021391045302152634\n",
            "Epoch 145/400, Batch 25/45, Loss: 0.0319809690117836\n",
            "Epoch 145/400, Batch 26/45, Loss: 0.12930776178836823\n",
            "Epoch 145/400, Batch 27/45, Loss: 0.026999153196811676\n",
            "Epoch 145/400, Batch 28/45, Loss: 0.02877729758620262\n",
            "Epoch 145/400, Batch 29/45, Loss: 0.06122560054063797\n",
            "Epoch 145/400, Batch 30/45, Loss: 0.06675145030021667\n",
            "Epoch 145/400, Batch 31/45, Loss: 0.04830625653266907\n",
            "Epoch 145/400, Batch 32/45, Loss: 0.05328661948442459\n",
            "Epoch 145/400, Batch 33/45, Loss: 0.06262075901031494\n",
            "Epoch 145/400, Batch 34/45, Loss: 0.02707936055958271\n",
            "Epoch 145/400, Batch 35/45, Loss: 0.02784568816423416\n",
            "Epoch 145/400, Batch 36/45, Loss: 0.064303457736969\n",
            "Epoch 145/400, Batch 37/45, Loss: 0.04992464929819107\n",
            "Epoch 145/400, Batch 38/45, Loss: 0.026323165744543076\n",
            "Epoch 145/400, Batch 39/45, Loss: 0.038796406239271164\n",
            "Epoch 145/400, Batch 40/45, Loss: 0.08969695121049881\n",
            "Epoch 145/400, Batch 41/45, Loss: 0.029294412583112717\n",
            "Epoch 145/400, Batch 42/45, Loss: 0.20085573196411133\n",
            "Epoch 145/400, Batch 43/45, Loss: 0.03427496179938316\n",
            "Epoch 145/400, Batch 44/45, Loss: 0.03902692347764969\n",
            "Epoch 145/400, Batch 45/45, Loss: 0.049328628927469254\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.4918344356119633 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  146 , Time Elapsed:  115.7008283774058  mins\n",
            "Epoch 146/400, Batch 1/45, Loss: 0.028525453060865402\n",
            "Epoch 146/400, Batch 2/45, Loss: 0.020663723349571228\n",
            "Epoch 146/400, Batch 3/45, Loss: 0.03293845057487488\n",
            "Epoch 146/400, Batch 4/45, Loss: 0.057510193437337875\n",
            "Epoch 146/400, Batch 5/45, Loss: 0.025068646296858788\n",
            "Epoch 146/400, Batch 6/45, Loss: 0.0617789551615715\n",
            "Epoch 146/400, Batch 7/45, Loss: 0.05073055252432823\n",
            "Epoch 146/400, Batch 8/45, Loss: 0.035367898643016815\n",
            "Epoch 146/400, Batch 9/45, Loss: 0.0880189836025238\n",
            "Epoch 146/400, Batch 10/45, Loss: 0.048268284648656845\n",
            "Epoch 146/400, Batch 11/45, Loss: 0.05787501484155655\n",
            "Epoch 146/400, Batch 12/45, Loss: 0.04039916396141052\n",
            "Epoch 146/400, Batch 13/45, Loss: 0.01696966215968132\n",
            "Epoch 146/400, Batch 14/45, Loss: 0.04997526854276657\n",
            "Epoch 146/400, Batch 15/45, Loss: 0.08074384927749634\n",
            "Epoch 146/400, Batch 16/45, Loss: 0.00953597854822874\n",
            "Epoch 146/400, Batch 17/45, Loss: 0.041185200214385986\n",
            "Epoch 146/400, Batch 18/45, Loss: 0.02909090742468834\n",
            "Epoch 146/400, Batch 19/45, Loss: 0.020626403391361237\n",
            "Epoch 146/400, Batch 20/45, Loss: 0.019685054197907448\n",
            "Epoch 146/400, Batch 21/45, Loss: 0.03177125006914139\n",
            "Epoch 146/400, Batch 22/45, Loss: 0.023287102580070496\n",
            "Epoch 146/400, Batch 23/45, Loss: 0.13252513110637665\n",
            "Epoch 146/400, Batch 24/45, Loss: 0.10923000425100327\n",
            "Epoch 146/400, Batch 25/45, Loss: 0.009555572643876076\n",
            "Epoch 146/400, Batch 26/45, Loss: 0.049280907958745956\n",
            "Epoch 146/400, Batch 27/45, Loss: 0.06836984306573868\n",
            "Epoch 146/400, Batch 28/45, Loss: 0.02409357577562332\n",
            "Epoch 146/400, Batch 29/45, Loss: 0.06774210929870605\n",
            "Epoch 146/400, Batch 30/45, Loss: 0.10835948586463928\n",
            "Epoch 146/400, Batch 31/45, Loss: 0.32054683566093445\n",
            "Epoch 146/400, Batch 32/45, Loss: 0.09983909875154495\n",
            "Epoch 146/400, Batch 33/45, Loss: 0.0987883135676384\n",
            "Epoch 146/400, Batch 34/45, Loss: 0.12595947086811066\n",
            "Epoch 146/400, Batch 35/45, Loss: 0.08025028556585312\n",
            "Epoch 146/400, Batch 36/45, Loss: 0.03687714412808418\n",
            "Epoch 146/400, Batch 37/45, Loss: 0.057005539536476135\n",
            "Epoch 146/400, Batch 38/45, Loss: 0.027553003281354904\n",
            "Epoch 146/400, Batch 39/45, Loss: 0.09586988389492035\n",
            "Epoch 146/400, Batch 40/45, Loss: 0.029141180217266083\n",
            "Epoch 146/400, Batch 41/45, Loss: 0.07049786299467087\n",
            "Epoch 146/400, Batch 42/45, Loss: 0.02464275062084198\n",
            "Epoch 146/400, Batch 43/45, Loss: 0.034578628838062286\n",
            "Epoch 146/400, Batch 44/45, Loss: 0.06299204379320145\n",
            "Epoch 146/400, Batch 45/45, Loss: 0.19579026103019714\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.7037588953971863 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  147 , Time Elapsed:  116.49248406887054  mins\n",
            "Epoch 147/400, Batch 1/45, Loss: 0.013855062425136566\n",
            "Epoch 147/400, Batch 2/45, Loss: 0.10067686438560486\n",
            "Epoch 147/400, Batch 3/45, Loss: 0.0678684413433075\n",
            "Epoch 147/400, Batch 4/45, Loss: 0.047507137060165405\n",
            "Epoch 147/400, Batch 5/45, Loss: 0.06885308027267456\n",
            "Epoch 147/400, Batch 6/45, Loss: 0.06674179434776306\n",
            "Epoch 147/400, Batch 7/45, Loss: 0.10948265343904495\n",
            "Epoch 147/400, Batch 8/45, Loss: 0.05807355418801308\n",
            "Epoch 147/400, Batch 9/45, Loss: 0.03429035469889641\n",
            "Epoch 147/400, Batch 10/45, Loss: 0.02280966192483902\n",
            "Epoch 147/400, Batch 11/45, Loss: 0.04751922935247421\n",
            "Epoch 147/400, Batch 12/45, Loss: 0.020803645253181458\n",
            "Epoch 147/400, Batch 13/45, Loss: 0.021347634494304657\n",
            "Epoch 147/400, Batch 14/45, Loss: 0.036376915872097015\n",
            "Epoch 147/400, Batch 15/45, Loss: 0.04169014096260071\n",
            "Epoch 147/400, Batch 16/45, Loss: 0.0349806547164917\n",
            "Epoch 147/400, Batch 17/45, Loss: 0.03853556141257286\n",
            "Epoch 147/400, Batch 18/45, Loss: 0.04352511465549469\n",
            "Epoch 147/400, Batch 19/45, Loss: 0.033194977790117264\n",
            "Epoch 147/400, Batch 20/45, Loss: 0.04512489587068558\n",
            "Epoch 147/400, Batch 21/45, Loss: 0.01932452991604805\n",
            "Epoch 147/400, Batch 22/45, Loss: 0.07523642480373383\n",
            "Epoch 147/400, Batch 23/45, Loss: 0.007458930369466543\n",
            "Epoch 147/400, Batch 24/45, Loss: 0.023066045716404915\n",
            "Epoch 147/400, Batch 25/45, Loss: 0.02703121304512024\n",
            "Epoch 147/400, Batch 26/45, Loss: 0.009026259183883667\n",
            "Epoch 147/400, Batch 27/45, Loss: 0.14540642499923706\n",
            "Epoch 147/400, Batch 28/45, Loss: 0.012919582426548004\n",
            "Epoch 147/400, Batch 29/45, Loss: 0.04828721284866333\n",
            "Epoch 147/400, Batch 30/45, Loss: 0.1393202841281891\n",
            "Epoch 147/400, Batch 31/45, Loss: 0.07461585104465485\n",
            "Epoch 147/400, Batch 32/45, Loss: 0.04432868957519531\n",
            "Epoch 147/400, Batch 33/45, Loss: 0.03516445681452751\n",
            "Epoch 147/400, Batch 34/45, Loss: 0.14411422610282898\n",
            "Epoch 147/400, Batch 35/45, Loss: 0.07883627712726593\n",
            "Epoch 147/400, Batch 36/45, Loss: 0.030266739428043365\n",
            "Epoch 147/400, Batch 37/45, Loss: 0.06222417950630188\n",
            "Epoch 147/400, Batch 38/45, Loss: 0.012314781546592712\n",
            "Epoch 147/400, Batch 39/45, Loss: 0.04579158127307892\n",
            "Epoch 147/400, Batch 40/45, Loss: 0.05696289986371994\n",
            "Epoch 147/400, Batch 41/45, Loss: 0.07333700358867645\n",
            "Epoch 147/400, Batch 42/45, Loss: 0.034422773867845535\n",
            "Epoch 147/400, Batch 43/45, Loss: 0.008891662582755089\n",
            "Epoch 147/400, Batch 44/45, Loss: 0.1336439847946167\n",
            "Epoch 147/400, Batch 45/45, Loss: 0.05287633463740349\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.5404556766152382 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  148 , Time Elapsed:  117.28227609793345  mins\n",
            "Epoch 148/400, Batch 1/45, Loss: 0.013693072833120823\n",
            "Epoch 148/400, Batch 2/45, Loss: 0.03449147567152977\n",
            "Epoch 148/400, Batch 3/45, Loss: 0.021350132301449776\n",
            "Epoch 148/400, Batch 4/45, Loss: 0.026357559487223625\n",
            "Epoch 148/400, Batch 5/45, Loss: 0.06539398431777954\n",
            "Epoch 148/400, Batch 6/45, Loss: 0.04122458025813103\n",
            "Epoch 148/400, Batch 7/45, Loss: 0.014542519114911556\n",
            "Epoch 148/400, Batch 8/45, Loss: 0.022887635976076126\n",
            "Epoch 148/400, Batch 9/45, Loss: 0.01686488464474678\n",
            "Epoch 148/400, Batch 10/45, Loss: 0.09816183149814606\n",
            "Epoch 148/400, Batch 11/45, Loss: 0.02846122346818447\n",
            "Epoch 148/400, Batch 12/45, Loss: 0.02407541126012802\n",
            "Epoch 148/400, Batch 13/45, Loss: 0.01906629279255867\n",
            "Epoch 148/400, Batch 14/45, Loss: 0.04036565124988556\n",
            "Epoch 148/400, Batch 15/45, Loss: 0.14719536900520325\n",
            "Epoch 148/400, Batch 16/45, Loss: 0.009884195402264595\n",
            "Epoch 148/400, Batch 17/45, Loss: 0.034872688353061676\n",
            "Epoch 148/400, Batch 18/45, Loss: 0.039106231182813644\n",
            "Epoch 148/400, Batch 19/45, Loss: 0.008772972039878368\n",
            "Epoch 148/400, Batch 20/45, Loss: 0.058256298303604126\n",
            "Epoch 148/400, Batch 21/45, Loss: 0.028470048680901527\n",
            "Epoch 148/400, Batch 22/45, Loss: 0.016874486580491066\n",
            "Epoch 148/400, Batch 23/45, Loss: 0.025763295590877533\n",
            "Epoch 148/400, Batch 24/45, Loss: 0.06597401201725006\n",
            "Epoch 148/400, Batch 25/45, Loss: 0.02362801879644394\n",
            "Epoch 148/400, Batch 26/45, Loss: 0.024902381002902985\n",
            "Epoch 148/400, Batch 27/45, Loss: 0.025644317269325256\n",
            "Epoch 148/400, Batch 28/45, Loss: 0.041941769421100616\n",
            "Epoch 148/400, Batch 29/45, Loss: 0.022821281105279922\n",
            "Epoch 148/400, Batch 30/45, Loss: 0.0407983660697937\n",
            "Epoch 148/400, Batch 31/45, Loss: 0.03114057146012783\n",
            "Epoch 148/400, Batch 32/45, Loss: 0.015619081445038319\n",
            "Epoch 148/400, Batch 33/45, Loss: 0.007230063900351524\n",
            "Epoch 148/400, Batch 34/45, Loss: 0.13466034829616547\n",
            "Epoch 148/400, Batch 35/45, Loss: 0.029460903257131577\n",
            "Epoch 148/400, Batch 36/45, Loss: 0.021689463406801224\n",
            "Epoch 148/400, Batch 37/45, Loss: 0.17393149435520172\n",
            "Epoch 148/400, Batch 38/45, Loss: 0.06647767871618271\n",
            "Epoch 148/400, Batch 39/45, Loss: 0.04433486983180046\n",
            "Epoch 148/400, Batch 40/45, Loss: 0.04549902677536011\n",
            "Epoch 148/400, Batch 41/45, Loss: 0.05916279926896095\n",
            "Epoch 148/400, Batch 42/45, Loss: 0.15626592934131622\n",
            "Epoch 148/400, Batch 43/45, Loss: 0.12275433540344238\n",
            "Epoch 148/400, Batch 44/45, Loss: 0.08797364681959152\n",
            "Epoch 148/400, Batch 45/45, Loss: 0.00543635431677103\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.4468030259013176 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  149 , Time Elapsed:  118.08915410439174  mins\n",
            "Epoch 149/400, Batch 1/45, Loss: 0.0313950777053833\n",
            "Epoch 149/400, Batch 2/45, Loss: 0.0338364839553833\n",
            "Epoch 149/400, Batch 3/45, Loss: 0.010404220782220364\n",
            "Epoch 149/400, Batch 4/45, Loss: 0.029843859374523163\n",
            "Epoch 149/400, Batch 5/45, Loss: 0.029413355514407158\n",
            "Epoch 149/400, Batch 6/45, Loss: 0.024870596826076508\n",
            "Epoch 149/400, Batch 7/45, Loss: 0.0589461550116539\n",
            "Epoch 149/400, Batch 8/45, Loss: 0.009356108494102955\n",
            "Epoch 149/400, Batch 9/45, Loss: 0.01543623860925436\n",
            "Epoch 149/400, Batch 10/45, Loss: 0.022223569452762604\n",
            "Epoch 149/400, Batch 11/45, Loss: 0.02206074260175228\n",
            "Epoch 149/400, Batch 12/45, Loss: 0.043159905821084976\n",
            "Epoch 149/400, Batch 13/45, Loss: 0.026315294206142426\n",
            "Epoch 149/400, Batch 14/45, Loss: 0.020901605486869812\n",
            "Epoch 149/400, Batch 15/45, Loss: 0.01189972274005413\n",
            "Epoch 149/400, Batch 16/45, Loss: 0.09175936132669449\n",
            "Epoch 149/400, Batch 17/45, Loss: 0.02236461639404297\n",
            "Epoch 149/400, Batch 18/45, Loss: 0.06319114565849304\n",
            "Epoch 149/400, Batch 19/45, Loss: 0.033523079007864\n",
            "Epoch 149/400, Batch 20/45, Loss: 0.047168049961328506\n",
            "Epoch 149/400, Batch 21/45, Loss: 0.029494307935237885\n",
            "Epoch 149/400, Batch 22/45, Loss: 0.0396592915058136\n",
            "Epoch 149/400, Batch 23/45, Loss: 0.11236536502838135\n",
            "Epoch 149/400, Batch 24/45, Loss: 0.06190856173634529\n",
            "Epoch 149/400, Batch 25/45, Loss: 0.0707591325044632\n",
            "Epoch 149/400, Batch 26/45, Loss: 0.011979065835475922\n",
            "Epoch 149/400, Batch 27/45, Loss: 0.02769378386437893\n",
            "Epoch 149/400, Batch 28/45, Loss: 0.04042862355709076\n",
            "Epoch 149/400, Batch 29/45, Loss: 0.014235245995223522\n",
            "Epoch 149/400, Batch 30/45, Loss: 0.023810163140296936\n",
            "Epoch 149/400, Batch 31/45, Loss: 0.04186597466468811\n",
            "Epoch 149/400, Batch 32/45, Loss: 0.007260672748088837\n",
            "Epoch 149/400, Batch 33/45, Loss: 0.02044944278895855\n",
            "Epoch 149/400, Batch 34/45, Loss: 0.04448802024126053\n",
            "Epoch 149/400, Batch 35/45, Loss: 0.039782535284757614\n",
            "Epoch 149/400, Batch 36/45, Loss: 0.02011975087225437\n",
            "Epoch 149/400, Batch 37/45, Loss: 0.05281708762049675\n",
            "Epoch 149/400, Batch 38/45, Loss: 0.04450506716966629\n",
            "Epoch 149/400, Batch 39/45, Loss: 0.03062088042497635\n",
            "Epoch 149/400, Batch 40/45, Loss: 0.020641392096877098\n",
            "Epoch 149/400, Batch 41/45, Loss: 0.023288056254386902\n",
            "Epoch 149/400, Batch 42/45, Loss: 0.05408833548426628\n",
            "Epoch 149/400, Batch 43/45, Loss: 0.021901965141296387\n",
            "Epoch 149/400, Batch 44/45, Loss: 0.011679241433739662\n",
            "Epoch 149/400, Batch 45/45, Loss: 0.026159554719924927\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.38173234090209 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  150 , Time Elapsed:  118.89615122874578  mins\n",
            "Epoch 150/400, Batch 1/45, Loss: 0.01888353005051613\n",
            "Epoch 150/400, Batch 2/45, Loss: 0.04450564458966255\n",
            "Epoch 150/400, Batch 3/45, Loss: 0.034209735691547394\n",
            "Epoch 150/400, Batch 4/45, Loss: 0.024513348937034607\n",
            "Epoch 150/400, Batch 5/45, Loss: 0.006814511027187109\n",
            "Epoch 150/400, Batch 6/45, Loss: 0.035837240517139435\n",
            "Epoch 150/400, Batch 7/45, Loss: 0.0026072219479829073\n",
            "Epoch 150/400, Batch 8/45, Loss: 0.0058916290290653706\n",
            "Epoch 150/400, Batch 9/45, Loss: 0.1920357346534729\n",
            "Epoch 150/400, Batch 10/45, Loss: 0.010845857672393322\n",
            "Epoch 150/400, Batch 11/45, Loss: 0.1999295949935913\n",
            "Epoch 150/400, Batch 12/45, Loss: 0.02218550443649292\n",
            "Epoch 150/400, Batch 13/45, Loss: 0.04040677100419998\n",
            "Epoch 150/400, Batch 14/45, Loss: 0.06577453762292862\n",
            "Epoch 150/400, Batch 15/45, Loss: 0.02587069943547249\n",
            "Epoch 150/400, Batch 16/45, Loss: 0.03175777941942215\n",
            "Epoch 150/400, Batch 17/45, Loss: 0.06886132061481476\n",
            "Epoch 150/400, Batch 18/45, Loss: 0.09550575911998749\n",
            "Epoch 150/400, Batch 19/45, Loss: 0.030491510406136513\n",
            "Epoch 150/400, Batch 20/45, Loss: 0.02647821418941021\n",
            "Epoch 150/400, Batch 21/45, Loss: 0.0063639478757977486\n",
            "Epoch 150/400, Batch 22/45, Loss: 0.015793483704328537\n",
            "Epoch 150/400, Batch 23/45, Loss: 0.01101564522832632\n",
            "Epoch 150/400, Batch 24/45, Loss: 0.015649396926164627\n",
            "Epoch 150/400, Batch 25/45, Loss: 0.055675819516181946\n",
            "Epoch 150/400, Batch 26/45, Loss: 0.027542997151613235\n",
            "Epoch 150/400, Batch 27/45, Loss: 0.040633659809827805\n",
            "Epoch 150/400, Batch 28/45, Loss: 0.031631335616111755\n",
            "Epoch 150/400, Batch 29/45, Loss: 0.024197950959205627\n",
            "Epoch 150/400, Batch 30/45, Loss: 0.014882490038871765\n",
            "Epoch 150/400, Batch 31/45, Loss: 0.02997460588812828\n",
            "Epoch 150/400, Batch 32/45, Loss: 0.016603857278823853\n",
            "Epoch 150/400, Batch 33/45, Loss: 0.039928484708070755\n",
            "Epoch 150/400, Batch 34/45, Loss: 0.028590448200702667\n",
            "Epoch 150/400, Batch 35/45, Loss: 0.054357290267944336\n",
            "Epoch 150/400, Batch 36/45, Loss: 0.08083102107048035\n",
            "Epoch 150/400, Batch 37/45, Loss: 0.05720093473792076\n",
            "Epoch 150/400, Batch 38/45, Loss: 0.044083017855882645\n",
            "Epoch 150/400, Batch 39/45, Loss: 0.02207326702773571\n",
            "Epoch 150/400, Batch 40/45, Loss: 0.035674385726451874\n",
            "Epoch 150/400, Batch 41/45, Loss: 0.038121916353702545\n",
            "Epoch 150/400, Batch 42/45, Loss: 0.04287303611636162\n",
            "Epoch 150/400, Batch 43/45, Loss: 0.05175473913550377\n",
            "Epoch 150/400, Batch 44/45, Loss: 0.009634238667786121\n",
            "Epoch 150/400, Batch 45/45, Loss: 0.05949220806360245\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.7088354341685772 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  151 , Time Elapsed:  119.69309321244558  mins\n",
            "Epoch 151/400, Batch 1/45, Loss: 0.040601085871458054\n",
            "Epoch 151/400, Batch 2/45, Loss: 0.03583306819200516\n",
            "Epoch 151/400, Batch 3/45, Loss: 0.03559952974319458\n",
            "Epoch 151/400, Batch 4/45, Loss: 0.02481870725750923\n",
            "Epoch 151/400, Batch 5/45, Loss: 0.011527827009558678\n",
            "Epoch 151/400, Batch 6/45, Loss: 0.020305346697568893\n",
            "Epoch 151/400, Batch 7/45, Loss: 0.029950585216283798\n",
            "Epoch 151/400, Batch 8/45, Loss: 0.037134017795324326\n",
            "Epoch 151/400, Batch 9/45, Loss: 0.058213844895362854\n",
            "Epoch 151/400, Batch 10/45, Loss: 0.021975096315145493\n",
            "Epoch 151/400, Batch 11/45, Loss: 0.036304790526628494\n",
            "Epoch 151/400, Batch 12/45, Loss: 0.014920868910849094\n",
            "Epoch 151/400, Batch 13/45, Loss: 0.01657499186694622\n",
            "Epoch 151/400, Batch 14/45, Loss: 0.02062765695154667\n",
            "Epoch 151/400, Batch 15/45, Loss: 0.030057916417717934\n",
            "Epoch 151/400, Batch 16/45, Loss: 0.047862522304058075\n",
            "Epoch 151/400, Batch 17/45, Loss: 0.04023129492998123\n",
            "Epoch 151/400, Batch 18/45, Loss: 0.0402241125702858\n",
            "Epoch 151/400, Batch 19/45, Loss: 0.04043450206518173\n",
            "Epoch 151/400, Batch 20/45, Loss: 0.011220823973417282\n",
            "Epoch 151/400, Batch 21/45, Loss: 0.03332705423235893\n",
            "Epoch 151/400, Batch 22/45, Loss: 0.01779276691377163\n",
            "Epoch 151/400, Batch 23/45, Loss: 0.017547879368066788\n",
            "Epoch 151/400, Batch 24/45, Loss: 0.05209775269031525\n",
            "Epoch 151/400, Batch 25/45, Loss: 0.03372330218553543\n",
            "Epoch 151/400, Batch 26/45, Loss: 0.09520228207111359\n",
            "Epoch 151/400, Batch 27/45, Loss: 0.038224298506975174\n",
            "Epoch 151/400, Batch 28/45, Loss: 0.058675121515989304\n",
            "Epoch 151/400, Batch 29/45, Loss: 0.06740576773881912\n",
            "Epoch 151/400, Batch 30/45, Loss: 0.03352292999625206\n",
            "Epoch 151/400, Batch 31/45, Loss: 0.0486002042889595\n",
            "Epoch 151/400, Batch 32/45, Loss: 0.021323703229427338\n",
            "Epoch 151/400, Batch 33/45, Loss: 0.04437161982059479\n",
            "Epoch 151/400, Batch 34/45, Loss: 0.033890992403030396\n",
            "Epoch 151/400, Batch 35/45, Loss: 0.09040643274784088\n",
            "Epoch 151/400, Batch 36/45, Loss: 0.01401187852025032\n",
            "Epoch 151/400, Batch 37/45, Loss: 0.030428607016801834\n",
            "Epoch 151/400, Batch 38/45, Loss: 0.01454245951026678\n",
            "Epoch 151/400, Batch 39/45, Loss: 0.04343726485967636\n",
            "Epoch 151/400, Batch 40/45, Loss: 0.030612416565418243\n",
            "Epoch 151/400, Batch 41/45, Loss: 0.03172532469034195\n",
            "Epoch 151/400, Batch 42/45, Loss: 0.06593823432922363\n",
            "Epoch 151/400, Batch 43/45, Loss: 0.029816044494509697\n",
            "Epoch 151/400, Batch 44/45, Loss: 0.016247885301709175\n",
            "Epoch 151/400, Batch 45/45, Loss: 0.10525286942720413\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.7203632965683937 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  152 , Time Elapsed:  120.51038459539413  mins\n",
            "Epoch 152/400, Batch 1/45, Loss: 0.053600192070007324\n",
            "Epoch 152/400, Batch 2/45, Loss: 0.04639819636940956\n",
            "Epoch 152/400, Batch 3/45, Loss: 0.034860700368881226\n",
            "Epoch 152/400, Batch 4/45, Loss: 0.014831677079200745\n",
            "Epoch 152/400, Batch 5/45, Loss: 0.0062972018495202065\n",
            "Epoch 152/400, Batch 6/45, Loss: 0.07994836568832397\n",
            "Epoch 152/400, Batch 7/45, Loss: 0.048997342586517334\n",
            "Epoch 152/400, Batch 8/45, Loss: 0.04925907030701637\n",
            "Epoch 152/400, Batch 9/45, Loss: 0.03400231897830963\n",
            "Epoch 152/400, Batch 10/45, Loss: 0.0387592576444149\n",
            "Epoch 152/400, Batch 11/45, Loss: 0.032724522054195404\n",
            "Epoch 152/400, Batch 12/45, Loss: 0.0513186976313591\n",
            "Epoch 152/400, Batch 13/45, Loss: 0.03229347616434097\n",
            "Epoch 152/400, Batch 14/45, Loss: 0.004261009395122528\n",
            "Epoch 152/400, Batch 15/45, Loss: 0.08300071954727173\n",
            "Epoch 152/400, Batch 16/45, Loss: 0.02539818361401558\n",
            "Epoch 152/400, Batch 17/45, Loss: 0.007043791934847832\n",
            "Epoch 152/400, Batch 18/45, Loss: 0.025338679552078247\n",
            "Epoch 152/400, Batch 19/45, Loss: 0.09935837239027023\n",
            "Epoch 152/400, Batch 20/45, Loss: 0.04897692799568176\n",
            "Epoch 152/400, Batch 21/45, Loss: 0.03537401184439659\n",
            "Epoch 152/400, Batch 22/45, Loss: 0.0133444145321846\n",
            "Epoch 152/400, Batch 23/45, Loss: 0.03825566917657852\n",
            "Epoch 152/400, Batch 24/45, Loss: 0.024230610579252243\n",
            "Epoch 152/400, Batch 25/45, Loss: 0.004884777590632439\n",
            "Epoch 152/400, Batch 26/45, Loss: 0.017707597464323044\n",
            "Epoch 152/400, Batch 27/45, Loss: 0.01825108379125595\n",
            "Epoch 152/400, Batch 28/45, Loss: 0.024963168427348137\n",
            "Epoch 152/400, Batch 29/45, Loss: 0.12616132199764252\n",
            "Epoch 152/400, Batch 30/45, Loss: 0.031555112451314926\n",
            "Epoch 152/400, Batch 31/45, Loss: 0.006217328831553459\n",
            "Epoch 152/400, Batch 32/45, Loss: 0.02165870927274227\n",
            "Epoch 152/400, Batch 33/45, Loss: 0.03071850910782814\n",
            "Epoch 152/400, Batch 34/45, Loss: 0.025766709819436073\n",
            "Epoch 152/400, Batch 35/45, Loss: 0.04681599140167236\n",
            "Epoch 152/400, Batch 36/45, Loss: 0.038679562509059906\n",
            "Epoch 152/400, Batch 37/45, Loss: 0.01618790440261364\n",
            "Epoch 152/400, Batch 38/45, Loss: 0.025142744183540344\n",
            "Epoch 152/400, Batch 39/45, Loss: 0.04769591987133026\n",
            "Epoch 152/400, Batch 40/45, Loss: 0.013852315954864025\n",
            "Epoch 152/400, Batch 41/45, Loss: 0.02830004133284092\n",
            "Epoch 152/400, Batch 42/45, Loss: 0.0265563502907753\n",
            "Epoch 152/400, Batch 43/45, Loss: 0.03793138265609741\n",
            "Epoch 152/400, Batch 44/45, Loss: 0.04704437404870987\n",
            "Epoch 152/400, Batch 45/45, Loss: 0.018441976979374886\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.4637616872787476 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  153 , Time Elapsed:  121.29730662902196  mins\n",
            "Epoch 153/400, Batch 1/45, Loss: 0.018008073791861534\n",
            "Epoch 153/400, Batch 2/45, Loss: 0.009028378874063492\n",
            "Epoch 153/400, Batch 3/45, Loss: 0.007711626589298248\n",
            "Epoch 153/400, Batch 4/45, Loss: 0.044864244759082794\n",
            "Epoch 153/400, Batch 5/45, Loss: 0.023282228037714958\n",
            "Epoch 153/400, Batch 6/45, Loss: 0.02367251366376877\n",
            "Epoch 153/400, Batch 7/45, Loss: 0.013767724856734276\n",
            "Epoch 153/400, Batch 8/45, Loss: 0.019284401088953018\n",
            "Epoch 153/400, Batch 9/45, Loss: 0.03361320123076439\n",
            "Epoch 153/400, Batch 10/45, Loss: 0.023520514369010925\n",
            "Epoch 153/400, Batch 11/45, Loss: 0.01566362753510475\n",
            "Epoch 153/400, Batch 12/45, Loss: 0.013492417521774769\n",
            "Epoch 153/400, Batch 13/45, Loss: 0.030468912795186043\n",
            "Epoch 153/400, Batch 14/45, Loss: 0.009012797847390175\n",
            "Epoch 153/400, Batch 15/45, Loss: 0.021013883873820305\n",
            "Epoch 153/400, Batch 16/45, Loss: 0.024506308138370514\n",
            "Epoch 153/400, Batch 17/45, Loss: 0.01641574501991272\n",
            "Epoch 153/400, Batch 18/45, Loss: 0.015454160049557686\n",
            "Epoch 153/400, Batch 19/45, Loss: 0.007471230812370777\n",
            "Epoch 153/400, Batch 20/45, Loss: 0.041050154715776443\n",
            "Epoch 153/400, Batch 21/45, Loss: 0.21270132064819336\n",
            "Epoch 153/400, Batch 22/45, Loss: 0.04010479897260666\n",
            "Epoch 153/400, Batch 23/45, Loss: 0.01874438300728798\n",
            "Epoch 153/400, Batch 24/45, Loss: 3.0054244995117188\n",
            "Epoch 153/400, Batch 25/45, Loss: 0.07979340851306915\n",
            "Epoch 153/400, Batch 26/45, Loss: 0.39618808031082153\n",
            "Epoch 153/400, Batch 27/45, Loss: 0.5496640205383301\n",
            "Epoch 153/400, Batch 28/45, Loss: 0.4705196022987366\n",
            "Epoch 153/400, Batch 29/45, Loss: 0.6406263113021851\n",
            "Epoch 153/400, Batch 30/45, Loss: 0.9545406103134155\n",
            "Epoch 153/400, Batch 31/45, Loss: 0.7130553722381592\n",
            "Epoch 153/400, Batch 32/45, Loss: 0.5486100912094116\n",
            "Epoch 153/400, Batch 33/45, Loss: 0.6845061779022217\n",
            "Epoch 153/400, Batch 34/45, Loss: 0.46434563398361206\n",
            "Epoch 153/400, Batch 35/45, Loss: 0.4805699288845062\n",
            "Epoch 153/400, Batch 36/45, Loss: 0.33952370285987854\n",
            "Epoch 153/400, Batch 37/45, Loss: 0.03293153643608093\n",
            "Epoch 153/400, Batch 38/45, Loss: 1.4248616695404053\n",
            "Epoch 153/400, Batch 39/45, Loss: 0.36206698417663574\n",
            "Epoch 153/400, Batch 40/45, Loss: 0.48113152384757996\n",
            "Epoch 153/400, Batch 41/45, Loss: 0.43166038393974304\n",
            "Epoch 153/400, Batch 42/45, Loss: 0.5178914666175842\n",
            "Epoch 153/400, Batch 43/45, Loss: 0.5021007061004639\n",
            "Epoch 153/400, Batch 44/45, Loss: 0.6390897035598755\n",
            "Epoch 153/400, Batch 45/45, Loss: 0.3681026101112366\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  15.198974952101707 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  154 , Time Elapsed:  122.0837291320165  mins\n",
            "Epoch 154/400, Batch 1/45, Loss: 0.7369588017463684\n",
            "Epoch 154/400, Batch 2/45, Loss: 0.5453753471374512\n",
            "Epoch 154/400, Batch 3/45, Loss: 0.5362654328346252\n",
            "Epoch 154/400, Batch 4/45, Loss: 0.2744296193122864\n",
            "Epoch 154/400, Batch 5/45, Loss: 0.21268339455127716\n",
            "Epoch 154/400, Batch 6/45, Loss: 0.22416330873966217\n",
            "Epoch 154/400, Batch 7/45, Loss: 0.3911326229572296\n",
            "Epoch 154/400, Batch 8/45, Loss: 0.617658257484436\n",
            "Epoch 154/400, Batch 9/45, Loss: 0.8102118968963623\n",
            "Epoch 154/400, Batch 10/45, Loss: 0.26112034916877747\n",
            "Epoch 154/400, Batch 11/45, Loss: 0.15078279376029968\n",
            "Epoch 154/400, Batch 12/45, Loss: 0.49459654092788696\n",
            "Epoch 154/400, Batch 13/45, Loss: 0.5233798027038574\n",
            "Epoch 154/400, Batch 14/45, Loss: 0.6250256299972534\n",
            "Epoch 154/400, Batch 15/45, Loss: 0.11922593414783478\n",
            "Epoch 154/400, Batch 16/45, Loss: 0.35023826360702515\n",
            "Epoch 154/400, Batch 17/45, Loss: 0.43337133526802063\n",
            "Epoch 154/400, Batch 18/45, Loss: 0.6273783445358276\n",
            "Epoch 154/400, Batch 19/45, Loss: 0.45516324043273926\n",
            "Epoch 154/400, Batch 20/45, Loss: 0.5928495526313782\n",
            "Epoch 154/400, Batch 21/45, Loss: 0.28315383195877075\n",
            "Epoch 154/400, Batch 22/45, Loss: 0.44256678223609924\n",
            "Epoch 154/400, Batch 23/45, Loss: 0.142062708735466\n",
            "Epoch 154/400, Batch 24/45, Loss: 0.8544422388076782\n",
            "Epoch 154/400, Batch 25/45, Loss: 0.12379518896341324\n",
            "Epoch 154/400, Batch 26/45, Loss: 0.3299110531806946\n",
            "Epoch 154/400, Batch 27/45, Loss: 0.36411014199256897\n",
            "Epoch 154/400, Batch 28/45, Loss: 0.03383567929267883\n",
            "Epoch 154/400, Batch 29/45, Loss: 0.3616940379142761\n",
            "Epoch 154/400, Batch 30/45, Loss: 0.22651958465576172\n",
            "Epoch 154/400, Batch 31/45, Loss: 0.37678539752960205\n",
            "Epoch 154/400, Batch 32/45, Loss: 0.19913887977600098\n",
            "Epoch 154/400, Batch 33/45, Loss: 0.1368175745010376\n",
            "Epoch 154/400, Batch 34/45, Loss: 0.08166826516389847\n",
            "Epoch 154/400, Batch 35/45, Loss: 0.41044697165489197\n",
            "Epoch 154/400, Batch 36/45, Loss: 0.26332128047943115\n",
            "Epoch 154/400, Batch 37/45, Loss: 0.08935727179050446\n",
            "Epoch 154/400, Batch 38/45, Loss: 0.2628980278968811\n",
            "Epoch 154/400, Batch 39/45, Loss: 0.33265945315361023\n",
            "Epoch 154/400, Batch 40/45, Loss: 0.17136593163013458\n",
            "Epoch 154/400, Batch 41/45, Loss: 0.3594695031642914\n",
            "Epoch 154/400, Batch 42/45, Loss: 0.36300209164619446\n",
            "Epoch 154/400, Batch 43/45, Loss: 0.15839150547981262\n",
            "Epoch 154/400, Batch 44/45, Loss: 0.0597224123775959\n",
            "Epoch 154/400, Batch 45/45, Loss: 0.17038747668266296\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  20.27068005502224 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  155 , Time Elapsed:  122.88948956727981  mins\n",
            "Epoch 155/400, Batch 1/45, Loss: 0.1365329623222351\n",
            "Epoch 155/400, Batch 2/45, Loss: 0.14871051907539368\n",
            "Epoch 155/400, Batch 3/45, Loss: 0.21521171927452087\n",
            "Epoch 155/400, Batch 4/45, Loss: 1.4851675033569336\n",
            "Epoch 155/400, Batch 5/45, Loss: 0.12380871176719666\n",
            "Epoch 155/400, Batch 6/45, Loss: 0.3586730360984802\n",
            "Epoch 155/400, Batch 7/45, Loss: 0.6062613129615784\n",
            "Epoch 155/400, Batch 8/45, Loss: 0.7336838245391846\n",
            "Epoch 155/400, Batch 9/45, Loss: 0.5663433074951172\n",
            "Epoch 155/400, Batch 10/45, Loss: 0.4827467203140259\n",
            "Epoch 155/400, Batch 11/45, Loss: 0.6025431752204895\n",
            "Epoch 155/400, Batch 12/45, Loss: 0.48272404074668884\n",
            "Epoch 155/400, Batch 13/45, Loss: 0.5555160641670227\n",
            "Epoch 155/400, Batch 14/45, Loss: 0.4341995120048523\n",
            "Epoch 155/400, Batch 15/45, Loss: 0.3199312686920166\n",
            "Epoch 155/400, Batch 16/45, Loss: 0.4312063455581665\n",
            "Epoch 155/400, Batch 17/45, Loss: 0.3088352680206299\n",
            "Epoch 155/400, Batch 18/45, Loss: 0.4356868863105774\n",
            "Epoch 155/400, Batch 19/45, Loss: 0.2536488175392151\n",
            "Epoch 155/400, Batch 20/45, Loss: 0.29507577419281006\n",
            "Epoch 155/400, Batch 21/45, Loss: 0.14130765199661255\n",
            "Epoch 155/400, Batch 22/45, Loss: 0.312235563993454\n",
            "Epoch 155/400, Batch 23/45, Loss: 0.13739371299743652\n",
            "Epoch 155/400, Batch 24/45, Loss: 2.269843816757202\n",
            "Epoch 155/400, Batch 25/45, Loss: 0.17702825367450714\n",
            "Epoch 155/400, Batch 26/45, Loss: 0.30010274052619934\n",
            "Epoch 155/400, Batch 27/45, Loss: 0.3652554750442505\n",
            "Epoch 155/400, Batch 28/45, Loss: 0.09627821296453476\n",
            "Epoch 155/400, Batch 29/45, Loss: 0.21626174449920654\n",
            "Epoch 155/400, Batch 30/45, Loss: 0.5050621628761292\n",
            "Epoch 155/400, Batch 31/45, Loss: 0.6498845219612122\n",
            "Epoch 155/400, Batch 32/45, Loss: 0.6450319290161133\n",
            "Epoch 155/400, Batch 33/45, Loss: 0.5558986663818359\n",
            "Epoch 155/400, Batch 34/45, Loss: 0.5573132038116455\n",
            "Epoch 155/400, Batch 35/45, Loss: 0.6224725842475891\n",
            "Epoch 155/400, Batch 36/45, Loss: 0.5503395795822144\n",
            "Epoch 155/400, Batch 37/45, Loss: 0.2697494626045227\n",
            "Epoch 155/400, Batch 38/45, Loss: 0.422061026096344\n",
            "Epoch 155/400, Batch 39/45, Loss: 0.12013042718172073\n",
            "Epoch 155/400, Batch 40/45, Loss: 0.5308238863945007\n",
            "Epoch 155/400, Batch 41/45, Loss: 0.21792125701904297\n",
            "Epoch 155/400, Batch 42/45, Loss: 0.06529456377029419\n",
            "Epoch 155/400, Batch 43/45, Loss: 0.48619699478149414\n",
            "Epoch 155/400, Batch 44/45, Loss: 0.10422585159540176\n",
            "Epoch 155/400, Batch 45/45, Loss: 0.06020103394985199\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  9.31098136305809 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  156 , Time Elapsed:  123.67462499936421  mins\n",
            "Epoch 156/400, Batch 1/45, Loss: 0.4176759719848633\n",
            "Epoch 156/400, Batch 2/45, Loss: 0.24893933534622192\n",
            "Epoch 156/400, Batch 3/45, Loss: 0.14275583624839783\n",
            "Epoch 156/400, Batch 4/45, Loss: 0.04836554825305939\n",
            "Epoch 156/400, Batch 5/45, Loss: 0.1653231978416443\n",
            "Epoch 156/400, Batch 6/45, Loss: 0.12075057625770569\n",
            "Epoch 156/400, Batch 7/45, Loss: 0.28613975644111633\n",
            "Epoch 156/400, Batch 8/45, Loss: 0.04487281292676926\n",
            "Epoch 156/400, Batch 9/45, Loss: 0.11427145451307297\n",
            "Epoch 156/400, Batch 10/45, Loss: 0.05224868282675743\n",
            "Epoch 156/400, Batch 11/45, Loss: 0.6400434970855713\n",
            "Epoch 156/400, Batch 12/45, Loss: 0.0792568102478981\n",
            "Epoch 156/400, Batch 13/45, Loss: 0.04555819556117058\n",
            "Epoch 156/400, Batch 14/45, Loss: 0.08972346782684326\n",
            "Epoch 156/400, Batch 15/45, Loss: 0.5217738747596741\n",
            "Epoch 156/400, Batch 16/45, Loss: 0.06532017141580582\n",
            "Epoch 156/400, Batch 17/45, Loss: 0.14864064753055573\n",
            "Epoch 156/400, Batch 18/45, Loss: 0.08815956115722656\n",
            "Epoch 156/400, Batch 19/45, Loss: 0.024429364129900932\n",
            "Epoch 156/400, Batch 20/45, Loss: 0.15792402625083923\n",
            "Epoch 156/400, Batch 21/45, Loss: 0.09975774586200714\n",
            "Epoch 156/400, Batch 22/45, Loss: 0.26282891631126404\n",
            "Epoch 156/400, Batch 23/45, Loss: 0.05569087341427803\n",
            "Epoch 156/400, Batch 24/45, Loss: 0.245162233710289\n",
            "Epoch 156/400, Batch 25/45, Loss: 0.031619541347026825\n",
            "Epoch 156/400, Batch 26/45, Loss: 0.050696589052677155\n",
            "Epoch 156/400, Batch 27/45, Loss: 0.09974131733179092\n",
            "Epoch 156/400, Batch 28/45, Loss: 0.19762426614761353\n",
            "Epoch 156/400, Batch 29/45, Loss: 0.03187150880694389\n",
            "Epoch 156/400, Batch 30/45, Loss: 0.186563178896904\n",
            "Epoch 156/400, Batch 31/45, Loss: 0.0488395094871521\n",
            "Epoch 156/400, Batch 32/45, Loss: 0.12694744765758514\n",
            "Epoch 156/400, Batch 33/45, Loss: 0.05772072821855545\n",
            "Epoch 156/400, Batch 34/45, Loss: 0.040285419672727585\n",
            "Epoch 156/400, Batch 35/45, Loss: 1.5089329481124878\n",
            "Epoch 156/400, Batch 36/45, Loss: 0.13801021873950958\n",
            "Epoch 156/400, Batch 37/45, Loss: 0.2838701605796814\n",
            "Epoch 156/400, Batch 38/45, Loss: 0.19557413458824158\n",
            "Epoch 156/400, Batch 39/45, Loss: 0.42650896310806274\n",
            "Epoch 156/400, Batch 40/45, Loss: 0.32214394211769104\n",
            "Epoch 156/400, Batch 41/45, Loss: 0.23297759890556335\n",
            "Epoch 156/400, Batch 42/45, Loss: 0.46101081371307373\n",
            "Epoch 156/400, Batch 43/45, Loss: 0.17014524340629578\n",
            "Epoch 156/400, Batch 44/45, Loss: 0.2112749069929123\n",
            "Epoch 156/400, Batch 45/45, Loss: 0.3657097816467285\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  9.083559051156044 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  157 , Time Elapsed:  124.49860102732977  mins\n",
            "Epoch 157/400, Batch 1/45, Loss: 0.0914817601442337\n",
            "Epoch 157/400, Batch 2/45, Loss: 0.2876412272453308\n",
            "Epoch 157/400, Batch 3/45, Loss: 0.339582234621048\n",
            "Epoch 157/400, Batch 4/45, Loss: 0.5002046823501587\n",
            "Epoch 157/400, Batch 5/45, Loss: 0.3278612494468689\n",
            "Epoch 157/400, Batch 6/45, Loss: 0.24230699241161346\n",
            "Epoch 157/400, Batch 7/45, Loss: 0.1796312779188156\n",
            "Epoch 157/400, Batch 8/45, Loss: 0.13890954852104187\n",
            "Epoch 157/400, Batch 9/45, Loss: 0.15342389047145844\n",
            "Epoch 157/400, Batch 10/45, Loss: 0.32820478081703186\n",
            "Epoch 157/400, Batch 11/45, Loss: 0.2370375692844391\n",
            "Epoch 157/400, Batch 12/45, Loss: 0.09648563712835312\n",
            "Epoch 157/400, Batch 13/45, Loss: 0.08603828400373459\n",
            "Epoch 157/400, Batch 14/45, Loss: 0.05655476450920105\n",
            "Epoch 157/400, Batch 15/45, Loss: 0.03860759362578392\n",
            "Epoch 157/400, Batch 16/45, Loss: 0.2214323729276657\n",
            "Epoch 157/400, Batch 17/45, Loss: 0.07762689143419266\n",
            "Epoch 157/400, Batch 18/45, Loss: 0.08526333421468735\n",
            "Epoch 157/400, Batch 19/45, Loss: 0.1394716203212738\n",
            "Epoch 157/400, Batch 20/45, Loss: 0.1616450399160385\n",
            "Epoch 157/400, Batch 21/45, Loss: 0.028675120323896408\n",
            "Epoch 157/400, Batch 22/45, Loss: 0.17178817093372345\n",
            "Epoch 157/400, Batch 23/45, Loss: 0.07265671342611313\n",
            "Epoch 157/400, Batch 24/45, Loss: 0.10541348159313202\n",
            "Epoch 157/400, Batch 25/45, Loss: 0.06786862015724182\n",
            "Epoch 157/400, Batch 26/45, Loss: 0.059681665152311325\n",
            "Epoch 157/400, Batch 27/45, Loss: 0.07347320765256882\n",
            "Epoch 157/400, Batch 28/45, Loss: 0.14084352552890778\n",
            "Epoch 157/400, Batch 29/45, Loss: 0.050788868218660355\n",
            "Epoch 157/400, Batch 30/45, Loss: 0.08504174649715424\n",
            "Epoch 157/400, Batch 31/45, Loss: 0.13007092475891113\n",
            "Epoch 157/400, Batch 32/45, Loss: 0.044017937034368515\n",
            "Epoch 157/400, Batch 33/45, Loss: 0.021342573687434196\n",
            "Epoch 157/400, Batch 34/45, Loss: 0.06708784401416779\n",
            "Epoch 157/400, Batch 35/45, Loss: 0.12321855127811432\n",
            "Epoch 157/400, Batch 36/45, Loss: 0.1136283427476883\n",
            "Epoch 157/400, Batch 37/45, Loss: 0.10298538208007812\n",
            "Epoch 157/400, Batch 38/45, Loss: 0.03699517995119095\n",
            "Epoch 157/400, Batch 39/45, Loss: 0.033699825406074524\n",
            "Epoch 157/400, Batch 40/45, Loss: 0.028350751847028732\n",
            "Epoch 157/400, Batch 41/45, Loss: 0.054925814270973206\n",
            "Epoch 157/400, Batch 42/45, Loss: 0.07922051101922989\n",
            "Epoch 157/400, Batch 43/45, Loss: 0.2179562747478485\n",
            "Epoch 157/400, Batch 44/45, Loss: 0.11367981135845184\n",
            "Epoch 157/400, Batch 45/45, Loss: 0.06240534037351608\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.6756257116794586 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  158 , Time Elapsed:  125.2891060948372  mins\n",
            "Epoch 158/400, Batch 1/45, Loss: 0.03943601995706558\n",
            "Epoch 158/400, Batch 2/45, Loss: 0.04612137749791145\n",
            "Epoch 158/400, Batch 3/45, Loss: 0.07976088672876358\n",
            "Epoch 158/400, Batch 4/45, Loss: 0.042954400181770325\n",
            "Epoch 158/400, Batch 5/45, Loss: 0.2437349557876587\n",
            "Epoch 158/400, Batch 6/45, Loss: 0.13135676085948944\n",
            "Epoch 158/400, Batch 7/45, Loss: 0.15694966912269592\n",
            "Epoch 158/400, Batch 8/45, Loss: 0.05039709061384201\n",
            "Epoch 158/400, Batch 9/45, Loss: 0.13216109573841095\n",
            "Epoch 158/400, Batch 10/45, Loss: 0.09888259321451187\n",
            "Epoch 158/400, Batch 11/45, Loss: 0.19525747001171112\n",
            "Epoch 158/400, Batch 12/45, Loss: 0.21456953883171082\n",
            "Epoch 158/400, Batch 13/45, Loss: 0.20837628841400146\n",
            "Epoch 158/400, Batch 14/45, Loss: 0.196344792842865\n",
            "Epoch 158/400, Batch 15/45, Loss: 0.09352337568998337\n",
            "Epoch 158/400, Batch 16/45, Loss: 0.05776327848434448\n",
            "Epoch 158/400, Batch 17/45, Loss: 0.041520796716213226\n",
            "Epoch 158/400, Batch 18/45, Loss: 0.06416570395231247\n",
            "Epoch 158/400, Batch 19/45, Loss: 0.04276202619075775\n",
            "Epoch 158/400, Batch 20/45, Loss: 0.051540181040763855\n",
            "Epoch 158/400, Batch 21/45, Loss: 0.030214298516511917\n",
            "Epoch 158/400, Batch 22/45, Loss: 0.04751221835613251\n",
            "Epoch 158/400, Batch 23/45, Loss: 2.304495334625244\n",
            "Epoch 158/400, Batch 24/45, Loss: 0.07034511119127274\n",
            "Epoch 158/400, Batch 25/45, Loss: 0.1274770200252533\n",
            "Epoch 158/400, Batch 26/45, Loss: 0.10253388434648514\n",
            "Epoch 158/400, Batch 27/45, Loss: 0.09346567094326019\n",
            "Epoch 158/400, Batch 28/45, Loss: 0.1850852519273758\n",
            "Epoch 158/400, Batch 29/45, Loss: 0.40263959765434265\n",
            "Epoch 158/400, Batch 30/45, Loss: 0.13569201529026031\n",
            "Epoch 158/400, Batch 31/45, Loss: 0.20557788014411926\n",
            "Epoch 158/400, Batch 32/45, Loss: 0.09857356548309326\n",
            "Epoch 158/400, Batch 33/45, Loss: 0.2762763798236847\n",
            "Epoch 158/400, Batch 34/45, Loss: 0.20066002011299133\n",
            "Epoch 158/400, Batch 35/45, Loss: 0.4408285319805145\n",
            "Epoch 158/400, Batch 36/45, Loss: 0.09915430843830109\n",
            "Epoch 158/400, Batch 37/45, Loss: 0.1367887407541275\n",
            "Epoch 158/400, Batch 38/45, Loss: 0.05774378031492233\n",
            "Epoch 158/400, Batch 39/45, Loss: 0.11201397329568863\n",
            "Epoch 158/400, Batch 40/45, Loss: 0.08355762809515\n",
            "Epoch 158/400, Batch 41/45, Loss: 0.1668236404657364\n",
            "Epoch 158/400, Batch 42/45, Loss: 0.21392753720283508\n",
            "Epoch 158/400, Batch 43/45, Loss: 0.03880332037806511\n",
            "Epoch 158/400, Batch 44/45, Loss: 0.1495923548936844\n",
            "Epoch 158/400, Batch 45/45, Loss: 0.08428361266851425\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  3.190159671008587 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  159 , Time Elapsed:  126.08192729949951  mins\n",
            "Epoch 159/400, Batch 1/45, Loss: 0.053704194724559784\n",
            "Epoch 159/400, Batch 2/45, Loss: 0.031561341136693954\n",
            "Epoch 159/400, Batch 3/45, Loss: 0.1795506626367569\n",
            "Epoch 159/400, Batch 4/45, Loss: 0.040863510221242905\n",
            "Epoch 159/400, Batch 5/45, Loss: 0.05873670428991318\n",
            "Epoch 159/400, Batch 6/45, Loss: 0.013560202904045582\n",
            "Epoch 159/400, Batch 7/45, Loss: 0.16586443781852722\n",
            "Epoch 159/400, Batch 8/45, Loss: 0.09602672606706619\n",
            "Epoch 159/400, Batch 9/45, Loss: 0.009290158748626709\n",
            "Epoch 159/400, Batch 10/45, Loss: 0.10725408792495728\n",
            "Epoch 159/400, Batch 11/45, Loss: 0.11421214789152145\n",
            "Epoch 159/400, Batch 12/45, Loss: 0.035258784890174866\n",
            "Epoch 159/400, Batch 13/45, Loss: 0.02636176533997059\n",
            "Epoch 159/400, Batch 14/45, Loss: 0.056863509118556976\n",
            "Epoch 159/400, Batch 15/45, Loss: 0.03295828029513359\n",
            "Epoch 159/400, Batch 16/45, Loss: 0.08713331818580627\n",
            "Epoch 159/400, Batch 17/45, Loss: 0.4149765968322754\n",
            "Epoch 159/400, Batch 18/45, Loss: 0.07624898850917816\n",
            "Epoch 159/400, Batch 19/45, Loss: 0.11197559535503387\n",
            "Epoch 159/400, Batch 20/45, Loss: 0.034489162266254425\n",
            "Epoch 159/400, Batch 21/45, Loss: 0.049900274723768234\n",
            "Epoch 159/400, Batch 22/45, Loss: 0.028058167546987534\n",
            "Epoch 159/400, Batch 23/45, Loss: 0.10232085734605789\n",
            "Epoch 159/400, Batch 24/45, Loss: 0.12577331066131592\n",
            "Epoch 159/400, Batch 25/45, Loss: 0.05666542425751686\n",
            "Epoch 159/400, Batch 26/45, Loss: 0.11635610461235046\n",
            "Epoch 159/400, Batch 27/45, Loss: 0.37881556153297424\n",
            "Epoch 159/400, Batch 28/45, Loss: 0.054420650005340576\n",
            "Epoch 159/400, Batch 29/45, Loss: 0.04279766604304314\n",
            "Epoch 159/400, Batch 30/45, Loss: 0.05545216053724289\n",
            "Epoch 159/400, Batch 31/45, Loss: 0.05666681379079819\n",
            "Epoch 159/400, Batch 32/45, Loss: 0.37359899282455444\n",
            "Epoch 159/400, Batch 33/45, Loss: 1.1211442947387695\n",
            "Epoch 159/400, Batch 34/45, Loss: 0.051974669098854065\n",
            "Epoch 159/400, Batch 35/45, Loss: 0.1591235250234604\n",
            "Epoch 159/400, Batch 36/45, Loss: 0.0656772181391716\n",
            "Epoch 159/400, Batch 37/45, Loss: 0.24883772432804108\n",
            "Epoch 159/400, Batch 38/45, Loss: 0.27361151576042175\n",
            "Epoch 159/400, Batch 39/45, Loss: 0.25032004714012146\n",
            "Epoch 159/400, Batch 40/45, Loss: 0.3190712332725525\n",
            "Epoch 159/400, Batch 41/45, Loss: 0.22313430905342102\n",
            "Epoch 159/400, Batch 42/45, Loss: 0.3811822235584259\n",
            "Epoch 159/400, Batch 43/45, Loss: 0.11766612529754639\n",
            "Epoch 159/400, Batch 44/45, Loss: 0.2243018001317978\n",
            "Epoch 159/400, Batch 45/45, Loss: 0.23239779472351074\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  2.692711040377617 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  160 , Time Elapsed:  126.87096245288849  mins\n",
            "Epoch 160/400, Batch 1/45, Loss: 0.23808632791042328\n",
            "Epoch 160/400, Batch 2/45, Loss: 0.215204656124115\n",
            "Epoch 160/400, Batch 3/45, Loss: 0.2479936182498932\n",
            "Epoch 160/400, Batch 4/45, Loss: 0.058906130492687225\n",
            "Epoch 160/400, Batch 5/45, Loss: 0.04722137004137039\n",
            "Epoch 160/400, Batch 6/45, Loss: 0.0959157794713974\n",
            "Epoch 160/400, Batch 7/45, Loss: 0.0507374107837677\n",
            "Epoch 160/400, Batch 8/45, Loss: 0.08814091980457306\n",
            "Epoch 160/400, Batch 9/45, Loss: 0.1309637576341629\n",
            "Epoch 160/400, Batch 10/45, Loss: 0.10612136870622635\n",
            "Epoch 160/400, Batch 11/45, Loss: 0.0531509667634964\n",
            "Epoch 160/400, Batch 12/45, Loss: 0.01167931780219078\n",
            "Epoch 160/400, Batch 13/45, Loss: 0.036933887749910355\n",
            "Epoch 160/400, Batch 14/45, Loss: 0.0749831348657608\n",
            "Epoch 160/400, Batch 15/45, Loss: 0.3311307728290558\n",
            "Epoch 160/400, Batch 16/45, Loss: 0.07408012449741364\n",
            "Epoch 160/400, Batch 17/45, Loss: 0.11265295743942261\n",
            "Epoch 160/400, Batch 18/45, Loss: 0.2500283718109131\n",
            "Epoch 160/400, Batch 19/45, Loss: 0.16490669548511505\n",
            "Epoch 160/400, Batch 20/45, Loss: 0.09775112569332123\n",
            "Epoch 160/400, Batch 21/45, Loss: 0.047961633652448654\n",
            "Epoch 160/400, Batch 22/45, Loss: 0.12592706084251404\n",
            "Epoch 160/400, Batch 23/45, Loss: 0.15046310424804688\n",
            "Epoch 160/400, Batch 24/45, Loss: 0.051373470574617386\n",
            "Epoch 160/400, Batch 25/45, Loss: 0.18567942082881927\n",
            "Epoch 160/400, Batch 26/45, Loss: 0.05580376088619232\n",
            "Epoch 160/400, Batch 27/45, Loss: 0.1163237988948822\n",
            "Epoch 160/400, Batch 28/45, Loss: 0.3586078882217407\n",
            "Epoch 160/400, Batch 29/45, Loss: 0.214951753616333\n",
            "Epoch 160/400, Batch 30/45, Loss: 0.17644008994102478\n",
            "Epoch 160/400, Batch 31/45, Loss: 0.26802176237106323\n",
            "Epoch 160/400, Batch 32/45, Loss: 0.2599799335002899\n",
            "Epoch 160/400, Batch 33/45, Loss: 0.2998012602329254\n",
            "Epoch 160/400, Batch 34/45, Loss: 0.23398040235042572\n",
            "Epoch 160/400, Batch 35/45, Loss: 0.024996256455779076\n",
            "Epoch 160/400, Batch 36/45, Loss: 0.12968024611473083\n",
            "Epoch 160/400, Batch 37/45, Loss: 0.06307584047317505\n",
            "Epoch 160/400, Batch 38/45, Loss: 0.24406872689723969\n",
            "Epoch 160/400, Batch 39/45, Loss: 0.05523083359003067\n",
            "Epoch 160/400, Batch 40/45, Loss: 0.034635160118341446\n",
            "Epoch 160/400, Batch 41/45, Loss: 0.1640046387910843\n",
            "Epoch 160/400, Batch 42/45, Loss: 0.07782655954360962\n",
            "Epoch 160/400, Batch 43/45, Loss: 0.059825584292411804\n",
            "Epoch 160/400, Batch 44/45, Loss: 0.02588999830186367\n",
            "Epoch 160/400, Batch 45/45, Loss: 0.0960707738995552\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.4877672120928764 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  161 , Time Elapsed:  127.6575986901919  mins\n",
            "Epoch 161/400, Batch 1/45, Loss: 0.03228452056646347\n",
            "Epoch 161/400, Batch 2/45, Loss: 0.11328466236591339\n",
            "Epoch 161/400, Batch 3/45, Loss: 0.03351057320833206\n",
            "Epoch 161/400, Batch 4/45, Loss: 0.07481672614812851\n",
            "Epoch 161/400, Batch 5/45, Loss: 0.029434822499752045\n",
            "Epoch 161/400, Batch 6/45, Loss: 0.05790102109313011\n",
            "Epoch 161/400, Batch 7/45, Loss: 0.036804284900426865\n",
            "Epoch 161/400, Batch 8/45, Loss: 0.08800144493579865\n",
            "Epoch 161/400, Batch 9/45, Loss: 0.09076321870088577\n",
            "Epoch 161/400, Batch 10/45, Loss: 0.034798476845026016\n",
            "Epoch 161/400, Batch 11/45, Loss: 0.012157268822193146\n",
            "Epoch 161/400, Batch 12/45, Loss: 0.06077878177165985\n",
            "Epoch 161/400, Batch 13/45, Loss: 0.0898769348859787\n",
            "Epoch 161/400, Batch 14/45, Loss: 0.048247985541820526\n",
            "Epoch 161/400, Batch 15/45, Loss: 0.056445516645908356\n",
            "Epoch 161/400, Batch 16/45, Loss: 0.06144578009843826\n",
            "Epoch 161/400, Batch 17/45, Loss: 0.04579261317849159\n",
            "Epoch 161/400, Batch 18/45, Loss: 0.16193518042564392\n",
            "Epoch 161/400, Batch 19/45, Loss: 0.06523296982049942\n",
            "Epoch 161/400, Batch 20/45, Loss: 0.03467940539121628\n",
            "Epoch 161/400, Batch 21/45, Loss: 0.03379781171679497\n",
            "Epoch 161/400, Batch 22/45, Loss: 0.24593845009803772\n",
            "Epoch 161/400, Batch 23/45, Loss: 0.06844399124383926\n",
            "Epoch 161/400, Batch 24/45, Loss: 0.05275767296552658\n",
            "Epoch 161/400, Batch 25/45, Loss: 0.013033714145421982\n",
            "Epoch 161/400, Batch 26/45, Loss: 0.372886061668396\n",
            "Epoch 161/400, Batch 27/45, Loss: 0.7274529337882996\n",
            "Epoch 161/400, Batch 28/45, Loss: 0.19638754427433014\n",
            "Epoch 161/400, Batch 29/45, Loss: 0.06312034279108047\n",
            "Epoch 161/400, Batch 30/45, Loss: 0.4005151093006134\n",
            "Epoch 161/400, Batch 31/45, Loss: 0.31057050824165344\n",
            "Epoch 161/400, Batch 32/45, Loss: 0.29808124899864197\n",
            "Epoch 161/400, Batch 33/45, Loss: 0.24870948493480682\n",
            "Epoch 161/400, Batch 34/45, Loss: 0.2824835777282715\n",
            "Epoch 161/400, Batch 35/45, Loss: 0.18544146418571472\n",
            "Epoch 161/400, Batch 36/45, Loss: 0.2740496098995209\n",
            "Epoch 161/400, Batch 37/45, Loss: 0.14001567661762238\n",
            "Epoch 161/400, Batch 38/45, Loss: 0.18448960781097412\n",
            "Epoch 161/400, Batch 39/45, Loss: 0.15554918348789215\n",
            "Epoch 161/400, Batch 40/45, Loss: 0.3140329122543335\n",
            "Epoch 161/400, Batch 41/45, Loss: 0.23160868883132935\n",
            "Epoch 161/400, Batch 42/45, Loss: 0.16280536353588104\n",
            "Epoch 161/400, Batch 43/45, Loss: 0.06639397889375687\n",
            "Epoch 161/400, Batch 44/45, Loss: 0.08525074273347855\n",
            "Epoch 161/400, Batch 45/45, Loss: 0.13290977478027344\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  3.4878477677702904 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  162 , Time Elapsed:  128.46958403984706  mins\n",
            "Epoch 162/400, Batch 1/45, Loss: 0.06749920547008514\n",
            "Epoch 162/400, Batch 2/45, Loss: 0.18407630920410156\n",
            "Epoch 162/400, Batch 3/45, Loss: 0.03455962985754013\n",
            "Epoch 162/400, Batch 4/45, Loss: 0.12275759130716324\n",
            "Epoch 162/400, Batch 5/45, Loss: 0.45777514576911926\n",
            "Epoch 162/400, Batch 6/45, Loss: 0.028089040890336037\n",
            "Epoch 162/400, Batch 7/45, Loss: 0.0933450311422348\n",
            "Epoch 162/400, Batch 8/45, Loss: 0.06850690394639969\n",
            "Epoch 162/400, Batch 9/45, Loss: 0.041335009038448334\n",
            "Epoch 162/400, Batch 10/45, Loss: 0.10535205155611038\n",
            "Epoch 162/400, Batch 11/45, Loss: 0.09687988460063934\n",
            "Epoch 162/400, Batch 12/45, Loss: 0.032110609114170074\n",
            "Epoch 162/400, Batch 13/45, Loss: 0.05775102972984314\n",
            "Epoch 162/400, Batch 14/45, Loss: 0.050532203167676926\n",
            "Epoch 162/400, Batch 15/45, Loss: 0.01011220645159483\n",
            "Epoch 162/400, Batch 16/45, Loss: 0.15068350732326508\n",
            "Epoch 162/400, Batch 17/45, Loss: 0.0945068970322609\n",
            "Epoch 162/400, Batch 18/45, Loss: 0.04238663613796234\n",
            "Epoch 162/400, Batch 19/45, Loss: 0.11920669674873352\n",
            "Epoch 162/400, Batch 20/45, Loss: 0.023071780800819397\n",
            "Epoch 162/400, Batch 21/45, Loss: 0.047895461320877075\n",
            "Epoch 162/400, Batch 22/45, Loss: 0.04349528253078461\n",
            "Epoch 162/400, Batch 23/45, Loss: 0.04786529764533043\n",
            "Epoch 162/400, Batch 24/45, Loss: 0.08029104769229889\n",
            "Epoch 162/400, Batch 25/45, Loss: 0.042441077530384064\n",
            "Epoch 162/400, Batch 26/45, Loss: 0.09537496417760849\n",
            "Epoch 162/400, Batch 27/45, Loss: 0.031038708984851837\n",
            "Epoch 162/400, Batch 28/45, Loss: 0.12504920363426208\n",
            "Epoch 162/400, Batch 29/45, Loss: 0.10373145341873169\n",
            "Epoch 162/400, Batch 30/45, Loss: 0.05124477297067642\n",
            "Epoch 162/400, Batch 31/45, Loss: 0.07366164773702621\n",
            "Epoch 162/400, Batch 32/45, Loss: 0.08801192045211792\n",
            "Epoch 162/400, Batch 33/45, Loss: 0.060326263308525085\n",
            "Epoch 162/400, Batch 34/45, Loss: 0.15727025270462036\n",
            "Epoch 162/400, Batch 35/45, Loss: 0.006796699948608875\n",
            "Epoch 162/400, Batch 36/45, Loss: 0.0623093843460083\n",
            "Epoch 162/400, Batch 37/45, Loss: 0.09001252055168152\n",
            "Epoch 162/400, Batch 38/45, Loss: 0.03145002946257591\n",
            "Epoch 162/400, Batch 39/45, Loss: 0.05907987430691719\n",
            "Epoch 162/400, Batch 40/45, Loss: 0.07521456480026245\n",
            "Epoch 162/400, Batch 41/45, Loss: 0.004786485340446234\n",
            "Epoch 162/400, Batch 42/45, Loss: 0.05980248749256134\n",
            "Epoch 162/400, Batch 43/45, Loss: 0.04279845580458641\n",
            "Epoch 162/400, Batch 44/45, Loss: 0.0697145164012909\n",
            "Epoch 162/400, Batch 45/45, Loss: 0.3934822678565979\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.3107835073024035 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  163 , Time Elapsed:  129.25374898115794  mins\n",
            "Epoch 163/400, Batch 1/45, Loss: 0.018654095008969307\n",
            "Epoch 163/400, Batch 2/45, Loss: 0.1078501045703888\n",
            "Epoch 163/400, Batch 3/45, Loss: 0.04615871235728264\n",
            "Epoch 163/400, Batch 4/45, Loss: 0.03382563218474388\n",
            "Epoch 163/400, Batch 5/45, Loss: 0.03158795088529587\n",
            "Epoch 163/400, Batch 6/45, Loss: 0.026158109307289124\n",
            "Epoch 163/400, Batch 7/45, Loss: 0.06941474229097366\n",
            "Epoch 163/400, Batch 8/45, Loss: 0.10002139955759048\n",
            "Epoch 163/400, Batch 9/45, Loss: 0.06622949987649918\n",
            "Epoch 163/400, Batch 10/45, Loss: 0.10249310731887817\n",
            "Epoch 163/400, Batch 11/45, Loss: 0.016226964071393013\n",
            "Epoch 163/400, Batch 12/45, Loss: 0.0410715714097023\n",
            "Epoch 163/400, Batch 13/45, Loss: 0.018951063975691795\n",
            "Epoch 163/400, Batch 14/45, Loss: 0.026544906198978424\n",
            "Epoch 163/400, Batch 15/45, Loss: 0.07228921353816986\n",
            "Epoch 163/400, Batch 16/45, Loss: 0.07252267748117447\n",
            "Epoch 163/400, Batch 17/45, Loss: 0.13752494752407074\n",
            "Epoch 163/400, Batch 18/45, Loss: 0.024582281708717346\n",
            "Epoch 163/400, Batch 19/45, Loss: 0.03467511013150215\n",
            "Epoch 163/400, Batch 20/45, Loss: 0.07255162298679352\n",
            "Epoch 163/400, Batch 21/45, Loss: 0.03847505897283554\n",
            "Epoch 163/400, Batch 22/45, Loss: 0.015517223626375198\n",
            "Epoch 163/400, Batch 23/45, Loss: 0.041020456701517105\n",
            "Epoch 163/400, Batch 24/45, Loss: 0.04972418025135994\n",
            "Epoch 163/400, Batch 25/45, Loss: 0.03686407580971718\n",
            "Epoch 163/400, Batch 26/45, Loss: 0.04936513304710388\n",
            "Epoch 163/400, Batch 27/45, Loss: 0.041404109448194504\n",
            "Epoch 163/400, Batch 28/45, Loss: 0.13952279090881348\n",
            "Epoch 163/400, Batch 29/45, Loss: 0.07971959561109543\n",
            "Epoch 163/400, Batch 30/45, Loss: 0.05531284585595131\n",
            "Epoch 163/400, Batch 31/45, Loss: 0.05575945973396301\n",
            "Epoch 163/400, Batch 32/45, Loss: 0.055781714618206024\n",
            "Epoch 163/400, Batch 33/45, Loss: 0.06070322170853615\n",
            "Epoch 163/400, Batch 34/45, Loss: 0.02900351583957672\n",
            "Epoch 163/400, Batch 35/45, Loss: 0.018775586038827896\n",
            "Epoch 163/400, Batch 36/45, Loss: 0.03989796340465546\n",
            "Epoch 163/400, Batch 37/45, Loss: 0.02168791927397251\n",
            "Epoch 163/400, Batch 38/45, Loss: 0.12211020290851593\n",
            "Epoch 163/400, Batch 39/45, Loss: 0.12462186068296432\n",
            "Epoch 163/400, Batch 40/45, Loss: 0.1345381885766983\n",
            "Epoch 163/400, Batch 41/45, Loss: 0.0390920490026474\n",
            "Epoch 163/400, Batch 42/45, Loss: 0.07808087021112442\n",
            "Epoch 163/400, Batch 43/45, Loss: 0.09717029333114624\n",
            "Epoch 163/400, Batch 44/45, Loss: 0.041102949529886246\n",
            "Epoch 163/400, Batch 45/45, Loss: 0.0850994884967804\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.6186280138790607 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  164 , Time Elapsed:  130.03798237641652  mins\n",
            "Epoch 164/400, Batch 1/45, Loss: 0.05112428963184357\n",
            "Epoch 164/400, Batch 2/45, Loss: 0.016588350757956505\n",
            "Epoch 164/400, Batch 3/45, Loss: 0.11925916373729706\n",
            "Epoch 164/400, Batch 4/45, Loss: 0.048358432948589325\n",
            "Epoch 164/400, Batch 5/45, Loss: 0.07848616689443588\n",
            "Epoch 164/400, Batch 6/45, Loss: 0.0650256797671318\n",
            "Epoch 164/400, Batch 7/45, Loss: 0.06282225996255875\n",
            "Epoch 164/400, Batch 8/45, Loss: 0.012872040271759033\n",
            "Epoch 164/400, Batch 9/45, Loss: 0.05220659077167511\n",
            "Epoch 164/400, Batch 10/45, Loss: 0.0327017642557621\n",
            "Epoch 164/400, Batch 11/45, Loss: 0.04260491207242012\n",
            "Epoch 164/400, Batch 12/45, Loss: 0.11950929462909698\n",
            "Epoch 164/400, Batch 13/45, Loss: 0.04486527293920517\n",
            "Epoch 164/400, Batch 14/45, Loss: 0.07310396432876587\n",
            "Epoch 164/400, Batch 15/45, Loss: 0.04503246769309044\n",
            "Epoch 164/400, Batch 16/45, Loss: 0.02164093777537346\n",
            "Epoch 164/400, Batch 17/45, Loss: 0.049635615199804306\n",
            "Epoch 164/400, Batch 18/45, Loss: 0.02465773932635784\n",
            "Epoch 164/400, Batch 19/45, Loss: 0.13998745381832123\n",
            "Epoch 164/400, Batch 20/45, Loss: 0.04263388365507126\n",
            "Epoch 164/400, Batch 21/45, Loss: 0.1049715131521225\n",
            "Epoch 164/400, Batch 22/45, Loss: 0.12677982449531555\n",
            "Epoch 164/400, Batch 23/45, Loss: 0.05190059915184975\n",
            "Epoch 164/400, Batch 24/45, Loss: 0.0014621964655816555\n",
            "Epoch 164/400, Batch 25/45, Loss: 0.11027555912733078\n",
            "Epoch 164/400, Batch 26/45, Loss: 0.019146481528878212\n",
            "Epoch 164/400, Batch 27/45, Loss: 0.06087171658873558\n",
            "Epoch 164/400, Batch 28/45, Loss: 0.06648475676774979\n",
            "Epoch 164/400, Batch 29/45, Loss: 0.0447990708053112\n",
            "Epoch 164/400, Batch 30/45, Loss: 0.07653043419122696\n",
            "Epoch 164/400, Batch 31/45, Loss: 0.07890428602695465\n",
            "Epoch 164/400, Batch 32/45, Loss: 0.07328817993402481\n",
            "Epoch 164/400, Batch 33/45, Loss: 0.018193230032920837\n",
            "Epoch 164/400, Batch 34/45, Loss: 0.031157800927758217\n",
            "Epoch 164/400, Batch 35/45, Loss: 0.09860219806432724\n",
            "Epoch 164/400, Batch 36/45, Loss: 0.03279910236597061\n",
            "Epoch 164/400, Batch 37/45, Loss: 0.11825849860906601\n",
            "Epoch 164/400, Batch 38/45, Loss: 0.028237156569957733\n",
            "Epoch 164/400, Batch 39/45, Loss: 0.0641622543334961\n",
            "Epoch 164/400, Batch 40/45, Loss: 0.09985057264566422\n",
            "Epoch 164/400, Batch 41/45, Loss: 0.014089271426200867\n",
            "Epoch 164/400, Batch 42/45, Loss: 0.035392843186855316\n",
            "Epoch 164/400, Batch 43/45, Loss: 0.025578130036592484\n",
            "Epoch 164/400, Batch 44/45, Loss: 0.01586049422621727\n",
            "Epoch 164/400, Batch 45/45, Loss: 0.020023999735713005\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.3994283452630043 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  165 , Time Elapsed:  130.84261960188547  mins\n",
            "Epoch 165/400, Batch 1/45, Loss: 0.020177436992526054\n",
            "Epoch 165/400, Batch 2/45, Loss: 0.04768820106983185\n",
            "Epoch 165/400, Batch 3/45, Loss: 0.08203354477882385\n",
            "Epoch 165/400, Batch 4/45, Loss: 0.014182878658175468\n",
            "Epoch 165/400, Batch 5/45, Loss: 0.048883188515901566\n",
            "Epoch 165/400, Batch 6/45, Loss: 0.04730629920959473\n",
            "Epoch 165/400, Batch 7/45, Loss: 0.030182339251041412\n",
            "Epoch 165/400, Batch 8/45, Loss: 0.04541578143835068\n",
            "Epoch 165/400, Batch 9/45, Loss: 0.07044293731451035\n",
            "Epoch 165/400, Batch 10/45, Loss: 0.07716254889965057\n",
            "Epoch 165/400, Batch 11/45, Loss: 0.035267043858766556\n",
            "Epoch 165/400, Batch 12/45, Loss: 0.09084592759609222\n",
            "Epoch 165/400, Batch 13/45, Loss: 0.061970070004463196\n",
            "Epoch 165/400, Batch 14/45, Loss: 0.043205223977565765\n",
            "Epoch 165/400, Batch 15/45, Loss: 0.04248542711138725\n",
            "Epoch 165/400, Batch 16/45, Loss: 0.014734024181962013\n",
            "Epoch 165/400, Batch 17/45, Loss: 0.039524439722299576\n",
            "Epoch 165/400, Batch 18/45, Loss: 0.041100166738033295\n",
            "Epoch 165/400, Batch 19/45, Loss: 0.053556859493255615\n",
            "Epoch 165/400, Batch 20/45, Loss: 0.011348344385623932\n",
            "Epoch 165/400, Batch 21/45, Loss: 0.02254878543317318\n",
            "Epoch 165/400, Batch 22/45, Loss: 0.025339247658848763\n",
            "Epoch 165/400, Batch 23/45, Loss: 0.023671409115195274\n",
            "Epoch 165/400, Batch 24/45, Loss: 0.010992733761668205\n",
            "Epoch 165/400, Batch 25/45, Loss: 0.2181989848613739\n",
            "Epoch 165/400, Batch 26/45, Loss: 0.02511340007185936\n",
            "Epoch 165/400, Batch 27/45, Loss: 0.03391047567129135\n",
            "Epoch 165/400, Batch 28/45, Loss: 0.03500426933169365\n",
            "Epoch 165/400, Batch 29/45, Loss: 0.00850307010114193\n",
            "Epoch 165/400, Batch 30/45, Loss: 0.11140917986631393\n",
            "Epoch 165/400, Batch 31/45, Loss: 0.06370125710964203\n",
            "Epoch 165/400, Batch 32/45, Loss: 0.03423522785305977\n",
            "Epoch 165/400, Batch 33/45, Loss: 0.12778155505657196\n",
            "Epoch 165/400, Batch 34/45, Loss: 0.011014527641236782\n",
            "Epoch 165/400, Batch 35/45, Loss: 0.03703612834215164\n",
            "Epoch 165/400, Batch 36/45, Loss: 0.04062304645776749\n",
            "Epoch 165/400, Batch 37/45, Loss: 0.10900995880365372\n",
            "Epoch 165/400, Batch 38/45, Loss: 0.021861063316464424\n",
            "Epoch 165/400, Batch 39/45, Loss: 0.025967992842197418\n",
            "Epoch 165/400, Batch 40/45, Loss: 0.03789539262652397\n",
            "Epoch 165/400, Batch 41/45, Loss: 0.04511530324816704\n",
            "Epoch 165/400, Batch 42/45, Loss: 0.04777757450938225\n",
            "Epoch 165/400, Batch 43/45, Loss: 0.02198033779859543\n",
            "Epoch 165/400, Batch 44/45, Loss: 0.06570221483707428\n",
            "Epoch 165/400, Batch 45/45, Loss: 0.10863266885280609\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.5965589247643948 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  166 , Time Elapsed:  131.63403699795404  mins\n",
            "Epoch 166/400, Batch 1/45, Loss: 0.16317707300186157\n",
            "Epoch 166/400, Batch 2/45, Loss: 0.0639725923538208\n",
            "Epoch 166/400, Batch 3/45, Loss: 0.009269682690501213\n",
            "Epoch 166/400, Batch 4/45, Loss: 0.10298966616392136\n",
            "Epoch 166/400, Batch 5/45, Loss: 0.05467945709824562\n",
            "Epoch 166/400, Batch 6/45, Loss: 0.017810292541980743\n",
            "Epoch 166/400, Batch 7/45, Loss: 0.07078137993812561\n",
            "Epoch 166/400, Batch 8/45, Loss: 0.03293827176094055\n",
            "Epoch 166/400, Batch 9/45, Loss: 0.024138258770108223\n",
            "Epoch 166/400, Batch 10/45, Loss: 0.020365331321954727\n",
            "Epoch 166/400, Batch 11/45, Loss: 0.01446567103266716\n",
            "Epoch 166/400, Batch 12/45, Loss: 0.011899100616574287\n",
            "Epoch 166/400, Batch 13/45, Loss: 0.03283548355102539\n",
            "Epoch 166/400, Batch 14/45, Loss: 0.04456900432705879\n",
            "Epoch 166/400, Batch 15/45, Loss: 0.0804261788725853\n",
            "Epoch 166/400, Batch 16/45, Loss: 0.03033028356730938\n",
            "Epoch 166/400, Batch 17/45, Loss: 0.023652877658605576\n",
            "Epoch 166/400, Batch 18/45, Loss: 0.0665687769651413\n",
            "Epoch 166/400, Batch 19/45, Loss: 0.006920814514160156\n",
            "Epoch 166/400, Batch 20/45, Loss: 0.06132368743419647\n",
            "Epoch 166/400, Batch 21/45, Loss: 0.02463148906826973\n",
            "Epoch 166/400, Batch 22/45, Loss: 0.005474455654621124\n",
            "Epoch 166/400, Batch 23/45, Loss: 0.0423949658870697\n",
            "Epoch 166/400, Batch 24/45, Loss: 0.020234886556863785\n",
            "Epoch 166/400, Batch 25/45, Loss: 0.016971014440059662\n",
            "Epoch 166/400, Batch 26/45, Loss: 0.02946828305721283\n",
            "Epoch 166/400, Batch 27/45, Loss: 0.05638381093740463\n",
            "Epoch 166/400, Batch 28/45, Loss: 0.01215844415128231\n",
            "Epoch 166/400, Batch 29/45, Loss: 0.04763447865843773\n",
            "Epoch 166/400, Batch 30/45, Loss: 0.016932539641857147\n",
            "Epoch 166/400, Batch 31/45, Loss: 0.012490566819906235\n",
            "Epoch 166/400, Batch 32/45, Loss: 0.07043099403381348\n",
            "Epoch 166/400, Batch 33/45, Loss: 0.022657956928014755\n",
            "Epoch 166/400, Batch 34/45, Loss: 0.03244553506374359\n",
            "Epoch 166/400, Batch 35/45, Loss: 0.03516288101673126\n",
            "Epoch 166/400, Batch 36/45, Loss: 0.005227386951446533\n",
            "Epoch 166/400, Batch 37/45, Loss: 0.06367144733667374\n",
            "Epoch 166/400, Batch 38/45, Loss: 0.012047173455357552\n",
            "Epoch 166/400, Batch 39/45, Loss: 0.16013343632221222\n",
            "Epoch 166/400, Batch 40/45, Loss: 0.015541929751634598\n",
            "Epoch 166/400, Batch 41/45, Loss: 0.6352115869522095\n",
            "Epoch 166/400, Batch 42/45, Loss: 0.06300519406795502\n",
            "Epoch 166/400, Batch 43/45, Loss: 0.043147195130586624\n",
            "Epoch 166/400, Batch 44/45, Loss: 0.10038590431213379\n",
            "Epoch 166/400, Batch 45/45, Loss: 0.039318427443504333\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.5549133084714413 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  167 , Time Elapsed:  132.45350305636723  mins\n",
            "Epoch 167/400, Batch 1/45, Loss: 0.09216724336147308\n",
            "Epoch 167/400, Batch 2/45, Loss: 0.06389227509498596\n",
            "Epoch 167/400, Batch 3/45, Loss: 0.11011799424886703\n",
            "Epoch 167/400, Batch 4/45, Loss: 0.1207648292183876\n",
            "Epoch 167/400, Batch 5/45, Loss: 0.07241976261138916\n",
            "Epoch 167/400, Batch 6/45, Loss: 0.06267432868480682\n",
            "Epoch 167/400, Batch 7/45, Loss: 0.0396045483648777\n",
            "Epoch 167/400, Batch 8/45, Loss: 0.03258597478270531\n",
            "Epoch 167/400, Batch 9/45, Loss: 0.037467047572135925\n",
            "Epoch 167/400, Batch 10/45, Loss: 0.03514637425541878\n",
            "Epoch 167/400, Batch 11/45, Loss: 0.04656680300831795\n",
            "Epoch 167/400, Batch 12/45, Loss: 0.023950237780809402\n",
            "Epoch 167/400, Batch 13/45, Loss: 0.019194375723600388\n",
            "Epoch 167/400, Batch 14/45, Loss: 0.03993872180581093\n",
            "Epoch 167/400, Batch 15/45, Loss: 0.03725176677107811\n",
            "Epoch 167/400, Batch 16/45, Loss: 0.042666345834732056\n",
            "Epoch 167/400, Batch 17/45, Loss: 0.029631376266479492\n",
            "Epoch 167/400, Batch 18/45, Loss: 0.017369937151670456\n",
            "Epoch 167/400, Batch 19/45, Loss: 0.08508633822202682\n",
            "Epoch 167/400, Batch 20/45, Loss: 0.06601952761411667\n",
            "Epoch 167/400, Batch 21/45, Loss: 0.07454343885183334\n",
            "Epoch 167/400, Batch 22/45, Loss: 0.008918453939259052\n",
            "Epoch 167/400, Batch 23/45, Loss: 0.021536050364375114\n",
            "Epoch 167/400, Batch 24/45, Loss: 0.20170451700687408\n",
            "Epoch 167/400, Batch 25/45, Loss: 0.01900213025510311\n",
            "Epoch 167/400, Batch 26/45, Loss: 0.06190129369497299\n",
            "Epoch 167/400, Batch 27/45, Loss: 0.014872511848807335\n",
            "Epoch 167/400, Batch 28/45, Loss: 0.05937959626317024\n",
            "Epoch 167/400, Batch 29/45, Loss: 0.013202214613556862\n",
            "Epoch 167/400, Batch 30/45, Loss: 0.11141001433134079\n",
            "Epoch 167/400, Batch 31/45, Loss: 0.11266529560089111\n",
            "Epoch 167/400, Batch 32/45, Loss: 0.06955936551094055\n",
            "Epoch 167/400, Batch 33/45, Loss: 0.03957083821296692\n",
            "Epoch 167/400, Batch 34/45, Loss: 0.05134854093194008\n",
            "Epoch 167/400, Batch 35/45, Loss: 0.05798469856381416\n",
            "Epoch 167/400, Batch 36/45, Loss: 0.05616537481546402\n",
            "Epoch 167/400, Batch 37/45, Loss: 0.019817369058728218\n",
            "Epoch 167/400, Batch 38/45, Loss: 0.04095304012298584\n",
            "Epoch 167/400, Batch 39/45, Loss: 0.03564029932022095\n",
            "Epoch 167/400, Batch 40/45, Loss: 0.05232026055455208\n",
            "Epoch 167/400, Batch 41/45, Loss: 0.047452162951231\n",
            "Epoch 167/400, Batch 42/45, Loss: 0.05030560493469238\n",
            "Epoch 167/400, Batch 43/45, Loss: 0.020886845886707306\n",
            "Epoch 167/400, Batch 44/45, Loss: 0.06590266525745392\n",
            "Epoch 167/400, Batch 45/45, Loss: 0.03022782690823078\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.4617749359458685 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  168 , Time Elapsed:  133.24112513462703  mins\n",
            "Epoch 168/400, Batch 1/45, Loss: 0.03809104859828949\n",
            "Epoch 168/400, Batch 2/45, Loss: 0.02721327729523182\n",
            "Epoch 168/400, Batch 3/45, Loss: 0.049082979559898376\n",
            "Epoch 168/400, Batch 4/45, Loss: 0.04105347394943237\n",
            "Epoch 168/400, Batch 5/45, Loss: 0.08455504477024078\n",
            "Epoch 168/400, Batch 6/45, Loss: 0.018360411748290062\n",
            "Epoch 168/400, Batch 7/45, Loss: 0.22077617049217224\n",
            "Epoch 168/400, Batch 8/45, Loss: 0.07292462885379791\n",
            "Epoch 168/400, Batch 9/45, Loss: 0.016134705394506454\n",
            "Epoch 168/400, Batch 10/45, Loss: 0.0030860602855682373\n",
            "Epoch 168/400, Batch 11/45, Loss: 0.07905548810958862\n",
            "Epoch 168/400, Batch 12/45, Loss: 0.025524906814098358\n",
            "Epoch 168/400, Batch 13/45, Loss: 0.03618592023849487\n",
            "Epoch 168/400, Batch 14/45, Loss: 0.06442852318286896\n",
            "Epoch 168/400, Batch 15/45, Loss: 0.04898867756128311\n",
            "Epoch 168/400, Batch 16/45, Loss: 0.03628639876842499\n",
            "Epoch 168/400, Batch 17/45, Loss: 0.06817257404327393\n",
            "Epoch 168/400, Batch 18/45, Loss: 0.1198078915476799\n",
            "Epoch 168/400, Batch 19/45, Loss: 0.03772521764039993\n",
            "Epoch 168/400, Batch 20/45, Loss: 0.03536345809698105\n",
            "Epoch 168/400, Batch 21/45, Loss: 0.04820358008146286\n",
            "Epoch 168/400, Batch 22/45, Loss: 0.005861217156052589\n",
            "Epoch 168/400, Batch 23/45, Loss: 0.03439740091562271\n",
            "Epoch 168/400, Batch 24/45, Loss: 0.025129346176981926\n",
            "Epoch 168/400, Batch 25/45, Loss: 0.031703848391771317\n",
            "Epoch 168/400, Batch 26/45, Loss: 0.19622375071048737\n",
            "Epoch 168/400, Batch 27/45, Loss: 0.008384974673390388\n",
            "Epoch 168/400, Batch 28/45, Loss: 0.12088135629892349\n",
            "Epoch 168/400, Batch 29/45, Loss: 0.0797181949019432\n",
            "Epoch 168/400, Batch 30/45, Loss: 0.030408678576350212\n",
            "Epoch 168/400, Batch 31/45, Loss: 0.025495130568742752\n",
            "Epoch 168/400, Batch 32/45, Loss: 0.012715836986899376\n",
            "Epoch 168/400, Batch 33/45, Loss: 0.16671442985534668\n",
            "Epoch 168/400, Batch 34/45, Loss: 0.01803952269256115\n",
            "Epoch 168/400, Batch 35/45, Loss: 0.02307896316051483\n",
            "Epoch 168/400, Batch 36/45, Loss: 0.03510892018675804\n",
            "Epoch 168/400, Batch 37/45, Loss: 0.03259432688355446\n",
            "Epoch 168/400, Batch 38/45, Loss: 0.05504908040165901\n",
            "Epoch 168/400, Batch 39/45, Loss: 0.0339491106569767\n",
            "Epoch 168/400, Batch 40/45, Loss: 0.062217216938734055\n",
            "Epoch 168/400, Batch 41/45, Loss: 0.13804778456687927\n",
            "Epoch 168/400, Batch 42/45, Loss: 0.08000019937753677\n",
            "Epoch 168/400, Batch 43/45, Loss: 0.047856803983449936\n",
            "Epoch 168/400, Batch 44/45, Loss: 0.03126927837729454\n",
            "Epoch 168/400, Batch 45/45, Loss: 0.03919436037540436\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.6728403717279434 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  169 , Time Elapsed:  134.05421545902888  mins\n",
            "Epoch 169/400, Batch 1/45, Loss: 0.044557295739650726\n",
            "Epoch 169/400, Batch 2/45, Loss: 0.022704262286424637\n",
            "Epoch 169/400, Batch 3/45, Loss: 0.04765081778168678\n",
            "Epoch 169/400, Batch 4/45, Loss: 0.01012403890490532\n",
            "Epoch 169/400, Batch 5/45, Loss: 0.03899514302611351\n",
            "Epoch 169/400, Batch 6/45, Loss: 0.05171946808695793\n",
            "Epoch 169/400, Batch 7/45, Loss: 0.021839739754796028\n",
            "Epoch 169/400, Batch 8/45, Loss: 0.09274369478225708\n",
            "Epoch 169/400, Batch 9/45, Loss: 0.024021778255701065\n",
            "Epoch 169/400, Batch 10/45, Loss: 0.011832775548100471\n",
            "Epoch 169/400, Batch 11/45, Loss: 0.016997700557112694\n",
            "Epoch 169/400, Batch 12/45, Loss: 0.026038682088255882\n",
            "Epoch 169/400, Batch 13/45, Loss: 0.012794550508260727\n",
            "Epoch 169/400, Batch 14/45, Loss: 0.07073318958282471\n",
            "Epoch 169/400, Batch 15/45, Loss: 0.13285773992538452\n",
            "Epoch 169/400, Batch 16/45, Loss: 0.01774437353014946\n",
            "Epoch 169/400, Batch 17/45, Loss: 0.02581128105521202\n",
            "Epoch 169/400, Batch 18/45, Loss: 0.015251229517161846\n",
            "Epoch 169/400, Batch 19/45, Loss: 0.04682820290327072\n",
            "Epoch 169/400, Batch 20/45, Loss: 0.03383013606071472\n",
            "Epoch 169/400, Batch 21/45, Loss: 0.024477016180753708\n",
            "Epoch 169/400, Batch 22/45, Loss: 0.02736923098564148\n",
            "Epoch 169/400, Batch 23/45, Loss: 0.061654701828956604\n",
            "Epoch 169/400, Batch 24/45, Loss: 0.01782204955816269\n",
            "Epoch 169/400, Batch 25/45, Loss: 0.023236868903040886\n",
            "Epoch 169/400, Batch 26/45, Loss: 0.015558438375592232\n",
            "Epoch 169/400, Batch 27/45, Loss: 0.02261842042207718\n",
            "Epoch 169/400, Batch 28/45, Loss: 0.03842727467417717\n",
            "Epoch 169/400, Batch 29/45, Loss: 0.031875889748334885\n",
            "Epoch 169/400, Batch 30/45, Loss: 0.039225175976753235\n",
            "Epoch 169/400, Batch 31/45, Loss: 0.015281026251614094\n",
            "Epoch 169/400, Batch 32/45, Loss: 0.02956072986125946\n",
            "Epoch 169/400, Batch 33/45, Loss: 0.01199281681329012\n",
            "Epoch 169/400, Batch 34/45, Loss: 0.015824928879737854\n",
            "Epoch 169/400, Batch 35/45, Loss: 0.06669164448976517\n",
            "Epoch 169/400, Batch 36/45, Loss: 0.028176886960864067\n",
            "Epoch 169/400, Batch 37/45, Loss: 0.036656759679317474\n",
            "Epoch 169/400, Batch 38/45, Loss: 0.046926990151405334\n",
            "Epoch 169/400, Batch 39/45, Loss: 0.050551943480968475\n",
            "Epoch 169/400, Batch 40/45, Loss: 0.01867946796119213\n",
            "Epoch 169/400, Batch 41/45, Loss: 0.102927565574646\n",
            "Epoch 169/400, Batch 42/45, Loss: 0.02162685990333557\n",
            "Epoch 169/400, Batch 43/45, Loss: 0.03411227464675903\n",
            "Epoch 169/400, Batch 44/45, Loss: 0.04490862414240837\n",
            "Epoch 169/400, Batch 45/45, Loss: 0.03248113393783569\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.593354556709528 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  170 , Time Elapsed:  134.8393648783366  mins\n",
            "Epoch 170/400, Batch 1/45, Loss: 0.029259970411658287\n",
            "Epoch 170/400, Batch 2/45, Loss: 0.10134445130825043\n",
            "Epoch 170/400, Batch 3/45, Loss: 0.03853532299399376\n",
            "Epoch 170/400, Batch 4/45, Loss: 0.014939544722437859\n",
            "Epoch 170/400, Batch 5/45, Loss: 0.0434429757297039\n",
            "Epoch 170/400, Batch 6/45, Loss: 0.021077796816825867\n",
            "Epoch 170/400, Batch 7/45, Loss: 0.058012835681438446\n",
            "Epoch 170/400, Batch 8/45, Loss: 0.042960938066244125\n",
            "Epoch 170/400, Batch 9/45, Loss: 0.02453196421265602\n",
            "Epoch 170/400, Batch 10/45, Loss: 0.026695268228650093\n",
            "Epoch 170/400, Batch 11/45, Loss: 0.015724919736385345\n",
            "Epoch 170/400, Batch 12/45, Loss: 0.039059117436409\n",
            "Epoch 170/400, Batch 13/45, Loss: 0.04138080030679703\n",
            "Epoch 170/400, Batch 14/45, Loss: 0.036282822489738464\n",
            "Epoch 170/400, Batch 15/45, Loss: 0.07421598583459854\n",
            "Epoch 170/400, Batch 16/45, Loss: 0.013055115938186646\n",
            "Epoch 170/400, Batch 17/45, Loss: 0.06693963706493378\n",
            "Epoch 170/400, Batch 18/45, Loss: 0.00950210727751255\n",
            "Epoch 170/400, Batch 19/45, Loss: 0.03599344193935394\n",
            "Epoch 170/400, Batch 20/45, Loss: 0.09734976291656494\n",
            "Epoch 170/400, Batch 21/45, Loss: 0.04996659234166145\n",
            "Epoch 170/400, Batch 22/45, Loss: 0.019660821184515953\n",
            "Epoch 170/400, Batch 23/45, Loss: 0.0757027119398117\n",
            "Epoch 170/400, Batch 24/45, Loss: 0.0422973558306694\n",
            "Epoch 170/400, Batch 25/45, Loss: 0.02338310331106186\n",
            "Epoch 170/400, Batch 26/45, Loss: 0.048549674451351166\n",
            "Epoch 170/400, Batch 27/45, Loss: 0.04152247682213783\n",
            "Epoch 170/400, Batch 28/45, Loss: 0.04139535874128342\n",
            "Epoch 170/400, Batch 29/45, Loss: 0.30368301272392273\n",
            "Epoch 170/400, Batch 30/45, Loss: 0.018984410911798477\n",
            "Epoch 170/400, Batch 31/45, Loss: 0.05871891975402832\n",
            "Epoch 170/400, Batch 32/45, Loss: 0.030388198792934418\n",
            "Epoch 170/400, Batch 33/45, Loss: 0.17442885041236877\n",
            "Epoch 170/400, Batch 34/45, Loss: 0.03471212461590767\n",
            "Epoch 170/400, Batch 35/45, Loss: 0.08359236270189285\n",
            "Epoch 170/400, Batch 36/45, Loss: 0.026521634310483932\n",
            "Epoch 170/400, Batch 37/45, Loss: 0.02285447157919407\n",
            "Epoch 170/400, Batch 38/45, Loss: 0.05602690204977989\n",
            "Epoch 170/400, Batch 39/45, Loss: 0.030285000801086426\n",
            "Epoch 170/400, Batch 40/45, Loss: 0.0568498894572258\n",
            "Epoch 170/400, Batch 41/45, Loss: 0.03446382284164429\n",
            "Epoch 170/400, Batch 42/45, Loss: 0.020848898217082024\n",
            "Epoch 170/400, Batch 43/45, Loss: 0.06076329946517944\n",
            "Epoch 170/400, Batch 44/45, Loss: 0.06878352910280228\n",
            "Epoch 170/400, Batch 45/45, Loss: 0.042308591306209564\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.8106718361377716 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  171 , Time Elapsed:  135.63534725904464  mins\n",
            "Epoch 171/400, Batch 1/45, Loss: 0.05961872637271881\n",
            "Epoch 171/400, Batch 2/45, Loss: 0.007315881550312042\n",
            "Epoch 171/400, Batch 3/45, Loss: 0.043646641075611115\n",
            "Epoch 171/400, Batch 4/45, Loss: 0.026374295353889465\n",
            "Epoch 171/400, Batch 5/45, Loss: 0.04424627125263214\n",
            "Epoch 171/400, Batch 6/45, Loss: 0.07149935513734818\n",
            "Epoch 171/400, Batch 7/45, Loss: 0.07437819242477417\n",
            "Epoch 171/400, Batch 8/45, Loss: 0.23444752395153046\n",
            "Epoch 171/400, Batch 9/45, Loss: 0.04489175230264664\n",
            "Epoch 171/400, Batch 10/45, Loss: 0.1078118085861206\n",
            "Epoch 171/400, Batch 11/45, Loss: 0.02964998409152031\n",
            "Epoch 171/400, Batch 12/45, Loss: 0.016543952748179436\n",
            "Epoch 171/400, Batch 13/45, Loss: 0.024513941258192062\n",
            "Epoch 171/400, Batch 14/45, Loss: 0.02424631267786026\n",
            "Epoch 171/400, Batch 15/45, Loss: 0.011273534968495369\n",
            "Epoch 171/400, Batch 16/45, Loss: 0.0449969619512558\n",
            "Epoch 171/400, Batch 17/45, Loss: 0.06224703788757324\n",
            "Epoch 171/400, Batch 18/45, Loss: 0.030485566705465317\n",
            "Epoch 171/400, Batch 19/45, Loss: 0.01766301319003105\n",
            "Epoch 171/400, Batch 20/45, Loss: 0.023386742919683456\n",
            "Epoch 171/400, Batch 21/45, Loss: 0.06180670112371445\n",
            "Epoch 171/400, Batch 22/45, Loss: 0.04069361463189125\n",
            "Epoch 171/400, Batch 23/45, Loss: 0.011527560651302338\n",
            "Epoch 171/400, Batch 24/45, Loss: 0.005858581513166428\n",
            "Epoch 171/400, Batch 25/45, Loss: 0.035706475377082825\n",
            "Epoch 171/400, Batch 26/45, Loss: 0.06304521858692169\n",
            "Epoch 171/400, Batch 27/45, Loss: 0.016565144062042236\n",
            "Epoch 171/400, Batch 28/45, Loss: 0.051666732877492905\n",
            "Epoch 171/400, Batch 29/45, Loss: 0.05929150432348251\n",
            "Epoch 171/400, Batch 30/45, Loss: 0.0369776152074337\n",
            "Epoch 171/400, Batch 31/45, Loss: 0.009265266358852386\n",
            "Epoch 171/400, Batch 32/45, Loss: 0.01652269810438156\n",
            "Epoch 171/400, Batch 33/45, Loss: 0.030782550573349\n",
            "Epoch 171/400, Batch 34/45, Loss: 0.013731349259614944\n",
            "Epoch 171/400, Batch 35/45, Loss: 0.00839997734874487\n",
            "Epoch 171/400, Batch 36/45, Loss: 0.020046187564730644\n",
            "Epoch 171/400, Batch 37/45, Loss: 0.035091787576675415\n",
            "Epoch 171/400, Batch 38/45, Loss: 0.024074748158454895\n",
            "Epoch 171/400, Batch 39/45, Loss: 0.040282148867845535\n",
            "Epoch 171/400, Batch 40/45, Loss: 0.009784692898392677\n",
            "Epoch 171/400, Batch 41/45, Loss: 0.0123719722032547\n",
            "Epoch 171/400, Batch 42/45, Loss: 0.06105845049023628\n",
            "Epoch 171/400, Batch 43/45, Loss: 0.017545344308018684\n",
            "Epoch 171/400, Batch 44/45, Loss: 0.03459213301539421\n",
            "Epoch 171/400, Batch 45/45, Loss: 0.036872945725917816\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.9628793373703957 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  172 , Time Elapsed:  136.42420891920725  mins\n",
            "Epoch 172/400, Batch 1/45, Loss: 0.0157720148563385\n",
            "Epoch 172/400, Batch 2/45, Loss: 0.02928032912313938\n",
            "Epoch 172/400, Batch 3/45, Loss: 0.006868977099657059\n",
            "Epoch 172/400, Batch 4/45, Loss: 0.005630518309772015\n",
            "Epoch 172/400, Batch 5/45, Loss: 0.034571755677461624\n",
            "Epoch 172/400, Batch 6/45, Loss: 0.06499651819467545\n",
            "Epoch 172/400, Batch 7/45, Loss: 0.07442988455295563\n",
            "Epoch 172/400, Batch 8/45, Loss: 0.010327421128749847\n",
            "Epoch 172/400, Batch 9/45, Loss: 0.016870366409420967\n",
            "Epoch 172/400, Batch 10/45, Loss: 0.026254869997501373\n",
            "Epoch 172/400, Batch 11/45, Loss: 0.044893573969602585\n",
            "Epoch 172/400, Batch 12/45, Loss: 0.02021295577287674\n",
            "Epoch 172/400, Batch 13/45, Loss: 0.022600432857871056\n",
            "Epoch 172/400, Batch 14/45, Loss: 0.03907585144042969\n",
            "Epoch 172/400, Batch 15/45, Loss: 0.04070565104484558\n",
            "Epoch 172/400, Batch 16/45, Loss: 0.013280974701046944\n",
            "Epoch 172/400, Batch 17/45, Loss: 0.010223716497421265\n",
            "Epoch 172/400, Batch 18/45, Loss: 0.0912182480096817\n",
            "Epoch 172/400, Batch 19/45, Loss: 0.05610211193561554\n",
            "Epoch 172/400, Batch 20/45, Loss: 0.013141668401658535\n",
            "Epoch 172/400, Batch 21/45, Loss: 0.0220174640417099\n",
            "Epoch 172/400, Batch 22/45, Loss: 0.04150346294045448\n",
            "Epoch 172/400, Batch 23/45, Loss: 0.016651008278131485\n",
            "Epoch 172/400, Batch 24/45, Loss: 0.01727299951016903\n",
            "Epoch 172/400, Batch 25/45, Loss: 0.059087805449962616\n",
            "Epoch 172/400, Batch 26/45, Loss: 0.026302995160222054\n",
            "Epoch 172/400, Batch 27/45, Loss: 0.019654076546430588\n",
            "Epoch 172/400, Batch 28/45, Loss: 0.01474706269800663\n",
            "Epoch 172/400, Batch 29/45, Loss: 0.012824047356843948\n",
            "Epoch 172/400, Batch 30/45, Loss: 0.041082125157117844\n",
            "Epoch 172/400, Batch 31/45, Loss: 0.03461868315935135\n",
            "Epoch 172/400, Batch 32/45, Loss: 0.03980425372719765\n",
            "Epoch 172/400, Batch 33/45, Loss: 0.015259141102433205\n",
            "Epoch 172/400, Batch 34/45, Loss: 0.015554164536297321\n",
            "Epoch 172/400, Batch 35/45, Loss: 0.026144977658987045\n",
            "Epoch 172/400, Batch 36/45, Loss: 0.008212720975279808\n",
            "Epoch 172/400, Batch 37/45, Loss: 0.004800127819180489\n",
            "Epoch 172/400, Batch 38/45, Loss: 0.006769193802028894\n",
            "Epoch 172/400, Batch 39/45, Loss: 0.17000924050807953\n",
            "Epoch 172/400, Batch 40/45, Loss: 0.04804695025086403\n",
            "Epoch 172/400, Batch 41/45, Loss: 0.07859022170305252\n",
            "Epoch 172/400, Batch 42/45, Loss: 0.03883571922779083\n",
            "Epoch 172/400, Batch 43/45, Loss: 0.02691674791276455\n",
            "Epoch 172/400, Batch 44/45, Loss: 0.013556363992393017\n",
            "Epoch 172/400, Batch 45/45, Loss: 0.021927382797002792\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.1876477636396885 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  173 , Time Elapsed:  137.22008247375487  mins\n",
            "Epoch 173/400, Batch 1/45, Loss: 0.04458848759531975\n",
            "Epoch 173/400, Batch 2/45, Loss: 0.01668461784720421\n",
            "Epoch 173/400, Batch 3/45, Loss: 0.029383476823568344\n",
            "Epoch 173/400, Batch 4/45, Loss: 0.036536362022161484\n",
            "Epoch 173/400, Batch 5/45, Loss: 0.029989277943968773\n",
            "Epoch 173/400, Batch 6/45, Loss: 0.03123064897954464\n",
            "Epoch 173/400, Batch 7/45, Loss: 0.009262096136808395\n",
            "Epoch 173/400, Batch 8/45, Loss: 0.013578572310507298\n",
            "Epoch 173/400, Batch 9/45, Loss: 0.0160614512860775\n",
            "Epoch 173/400, Batch 10/45, Loss: 0.05610781908035278\n",
            "Epoch 173/400, Batch 11/45, Loss: 0.03657345473766327\n",
            "Epoch 173/400, Batch 12/45, Loss: 0.009425506927073002\n",
            "Epoch 173/400, Batch 13/45, Loss: 0.03757944330573082\n",
            "Epoch 173/400, Batch 14/45, Loss: 0.05575704574584961\n",
            "Epoch 173/400, Batch 15/45, Loss: 0.14016251266002655\n",
            "Epoch 173/400, Batch 16/45, Loss: 0.03234124556183815\n",
            "Epoch 173/400, Batch 17/45, Loss: 0.030083220452070236\n",
            "Epoch 173/400, Batch 18/45, Loss: 0.017243903130292892\n",
            "Epoch 173/400, Batch 19/45, Loss: 0.011948437429964542\n",
            "Epoch 173/400, Batch 20/45, Loss: 0.03641330450773239\n",
            "Epoch 173/400, Batch 21/45, Loss: 0.012007066048681736\n",
            "Epoch 173/400, Batch 22/45, Loss: 0.029062768444418907\n",
            "Epoch 173/400, Batch 23/45, Loss: 0.013139450922608376\n",
            "Epoch 173/400, Batch 24/45, Loss: 0.1879086196422577\n",
            "Epoch 173/400, Batch 25/45, Loss: 0.055555082857608795\n",
            "Epoch 173/400, Batch 26/45, Loss: 0.0975215882062912\n",
            "Epoch 173/400, Batch 27/45, Loss: 0.03142159432172775\n",
            "Epoch 173/400, Batch 28/45, Loss: 0.04543896019458771\n",
            "Epoch 173/400, Batch 29/45, Loss: 0.0537174716591835\n",
            "Epoch 173/400, Batch 30/45, Loss: 0.04498733580112457\n",
            "Epoch 173/400, Batch 31/45, Loss: 0.05385564640164375\n",
            "Epoch 173/400, Batch 32/45, Loss: 0.019205505028367043\n",
            "Epoch 173/400, Batch 33/45, Loss: 0.023550305515527725\n",
            "Epoch 173/400, Batch 34/45, Loss: 0.0694364607334137\n",
            "Epoch 173/400, Batch 35/45, Loss: 0.03813598304986954\n",
            "Epoch 173/400, Batch 36/45, Loss: 0.01573743298649788\n",
            "Epoch 173/400, Batch 37/45, Loss: 0.014409882947802544\n",
            "Epoch 173/400, Batch 38/45, Loss: 0.030260801315307617\n",
            "Epoch 173/400, Batch 39/45, Loss: 0.007611705921590328\n",
            "Epoch 173/400, Batch 40/45, Loss: 0.024210268631577492\n",
            "Epoch 173/400, Batch 41/45, Loss: 0.013007543049752712\n",
            "Epoch 173/400, Batch 42/45, Loss: 0.016762034967541695\n",
            "Epoch 173/400, Batch 43/45, Loss: 0.0494208037853241\n",
            "Epoch 173/400, Batch 44/45, Loss: 0.24922043085098267\n",
            "Epoch 173/400, Batch 45/45, Loss: 0.04443966597318649\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.5329520478844643 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  174 , Time Elapsed:  138.02458484570187  mins\n",
            "Epoch 174/400, Batch 1/45, Loss: 0.017700331285595894\n",
            "Epoch 174/400, Batch 2/45, Loss: 0.09150032699108124\n",
            "Epoch 174/400, Batch 3/45, Loss: 0.030859367921948433\n",
            "Epoch 174/400, Batch 4/45, Loss: 0.023971330374479294\n",
            "Epoch 174/400, Batch 5/45, Loss: 0.030635925009846687\n",
            "Epoch 174/400, Batch 6/45, Loss: 0.040469005703926086\n",
            "Epoch 174/400, Batch 7/45, Loss: 0.043779559433460236\n",
            "Epoch 174/400, Batch 8/45, Loss: 0.07246199250221252\n",
            "Epoch 174/400, Batch 9/45, Loss: 0.044455669820308685\n",
            "Epoch 174/400, Batch 10/45, Loss: 0.03866982460021973\n",
            "Epoch 174/400, Batch 11/45, Loss: 0.023230092599987984\n",
            "Epoch 174/400, Batch 12/45, Loss: 0.11363889276981354\n",
            "Epoch 174/400, Batch 13/45, Loss: 0.04910451918840408\n",
            "Epoch 174/400, Batch 14/45, Loss: 0.0444849468767643\n",
            "Epoch 174/400, Batch 15/45, Loss: 0.11151740700006485\n",
            "Epoch 174/400, Batch 16/45, Loss: 0.037484023720026016\n",
            "Epoch 174/400, Batch 17/45, Loss: 0.016983244568109512\n",
            "Epoch 174/400, Batch 18/45, Loss: 0.018241602927446365\n",
            "Epoch 174/400, Batch 19/45, Loss: 0.024855654686689377\n",
            "Epoch 174/400, Batch 20/45, Loss: 0.011757487431168556\n",
            "Epoch 174/400, Batch 21/45, Loss: 0.021531052887439728\n",
            "Epoch 174/400, Batch 22/45, Loss: 0.01106229331344366\n",
            "Epoch 174/400, Batch 23/45, Loss: 0.03148467466235161\n",
            "Epoch 174/400, Batch 24/45, Loss: 0.3483014702796936\n",
            "Epoch 174/400, Batch 25/45, Loss: 0.10097457468509674\n",
            "Epoch 174/400, Batch 26/45, Loss: 0.04721365123987198\n",
            "Epoch 174/400, Batch 27/45, Loss: 0.027937699109315872\n",
            "Epoch 174/400, Batch 28/45, Loss: 0.019749756902456284\n",
            "Epoch 174/400, Batch 29/45, Loss: 0.028379041701555252\n",
            "Epoch 174/400, Batch 30/45, Loss: 0.043962232768535614\n",
            "Epoch 174/400, Batch 31/45, Loss: 0.07423921674489975\n",
            "Epoch 174/400, Batch 32/45, Loss: 0.01002943329513073\n",
            "Epoch 174/400, Batch 33/45, Loss: 0.06320603936910629\n",
            "Epoch 174/400, Batch 34/45, Loss: 0.04979665204882622\n",
            "Epoch 174/400, Batch 35/45, Loss: 0.07093506306409836\n",
            "Epoch 174/400, Batch 36/45, Loss: 0.054751019924879074\n",
            "Epoch 174/400, Batch 37/45, Loss: 0.03479435294866562\n",
            "Epoch 174/400, Batch 38/45, Loss: 0.03004150092601776\n",
            "Epoch 174/400, Batch 39/45, Loss: 0.0398784875869751\n",
            "Epoch 174/400, Batch 40/45, Loss: 0.05501249432563782\n",
            "Epoch 174/400, Batch 41/45, Loss: 0.029921790584921837\n",
            "Epoch 174/400, Batch 42/45, Loss: 0.2358931005001068\n",
            "Epoch 174/400, Batch 43/45, Loss: 0.05452382564544678\n",
            "Epoch 174/400, Batch 44/45, Loss: 0.035701945424079895\n",
            "Epoch 174/400, Batch 45/45, Loss: 0.016712680459022522\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.4743314031511545 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  175 , Time Elapsed:  138.8099816560745  mins\n",
            "Epoch 175/400, Batch 1/45, Loss: 0.020474476739764214\n",
            "Epoch 175/400, Batch 2/45, Loss: 0.020317435264587402\n",
            "Epoch 175/400, Batch 3/45, Loss: 0.07901770621538162\n",
            "Epoch 175/400, Batch 4/45, Loss: 0.036014337092638016\n",
            "Epoch 175/400, Batch 5/45, Loss: 0.061211079359054565\n",
            "Epoch 175/400, Batch 6/45, Loss: 0.0796651542186737\n",
            "Epoch 175/400, Batch 7/45, Loss: 0.01919851079583168\n",
            "Epoch 175/400, Batch 8/45, Loss: 0.008487261831760406\n",
            "Epoch 175/400, Batch 9/45, Loss: 0.009683540090918541\n",
            "Epoch 175/400, Batch 10/45, Loss: 0.04410916194319725\n",
            "Epoch 175/400, Batch 11/45, Loss: 0.07299403846263885\n",
            "Epoch 175/400, Batch 12/45, Loss: 0.05144164711236954\n",
            "Epoch 175/400, Batch 13/45, Loss: 0.014159565791487694\n",
            "Epoch 175/400, Batch 14/45, Loss: 0.05675727128982544\n",
            "Epoch 175/400, Batch 15/45, Loss: 0.01724277064204216\n",
            "Epoch 175/400, Batch 16/45, Loss: 0.023898473009467125\n",
            "Epoch 175/400, Batch 17/45, Loss: 0.028808414936065674\n",
            "Epoch 175/400, Batch 18/45, Loss: 0.006048651412129402\n",
            "Epoch 175/400, Batch 19/45, Loss: 0.02619360387325287\n",
            "Epoch 175/400, Batch 20/45, Loss: 0.026322664692997932\n",
            "Epoch 175/400, Batch 21/45, Loss: 0.03976759314537048\n",
            "Epoch 175/400, Batch 22/45, Loss: 0.042534999549388885\n",
            "Epoch 175/400, Batch 23/45, Loss: 0.028039606288075447\n",
            "Epoch 175/400, Batch 24/45, Loss: 0.025618307292461395\n",
            "Epoch 175/400, Batch 25/45, Loss: 0.023236073553562164\n",
            "Epoch 175/400, Batch 26/45, Loss: 0.020870044827461243\n",
            "Epoch 175/400, Batch 27/45, Loss: 0.07477279752492905\n",
            "Epoch 175/400, Batch 28/45, Loss: 0.03919844329357147\n",
            "Epoch 175/400, Batch 29/45, Loss: 0.024084022268652916\n",
            "Epoch 175/400, Batch 30/45, Loss: 0.02398296818137169\n",
            "Epoch 175/400, Batch 31/45, Loss: 0.03407144919037819\n",
            "Epoch 175/400, Batch 32/45, Loss: 0.029802650213241577\n",
            "Epoch 175/400, Batch 33/45, Loss: 0.07598315179347992\n",
            "Epoch 175/400, Batch 34/45, Loss: 0.03337973356246948\n",
            "Epoch 175/400, Batch 35/45, Loss: 0.015509543940424919\n",
            "Epoch 175/400, Batch 36/45, Loss: 0.03740087151527405\n",
            "Epoch 175/400, Batch 37/45, Loss: 0.03129414841532707\n",
            "Epoch 175/400, Batch 38/45, Loss: 0.7306284308433533\n",
            "Epoch 175/400, Batch 39/45, Loss: 0.06504715979099274\n",
            "Epoch 175/400, Batch 40/45, Loss: 0.06721015274524689\n",
            "Epoch 175/400, Batch 41/45, Loss: 0.052594248205423355\n",
            "Epoch 175/400, Batch 42/45, Loss: 0.16645288467407227\n",
            "Epoch 175/400, Batch 43/45, Loss: 0.07891641557216644\n",
            "Epoch 175/400, Batch 44/45, Loss: 0.07658460736274719\n",
            "Epoch 175/400, Batch 45/45, Loss: 0.13073913753032684\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  3.6158721148967743 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  176 , Time Elapsed:  139.63361213604608  mins\n",
            "Epoch 176/400, Batch 1/45, Loss: 0.10982850193977356\n",
            "Epoch 176/400, Batch 2/45, Loss: 0.048705294728279114\n",
            "Epoch 176/400, Batch 3/45, Loss: 0.09365124255418777\n",
            "Epoch 176/400, Batch 4/45, Loss: 0.031169718131422997\n",
            "Epoch 176/400, Batch 5/45, Loss: 0.04117506742477417\n",
            "Epoch 176/400, Batch 6/45, Loss: 0.1650424748659134\n",
            "Epoch 176/400, Batch 7/45, Loss: 0.08887428045272827\n",
            "Epoch 176/400, Batch 8/45, Loss: 0.05285310745239258\n",
            "Epoch 176/400, Batch 9/45, Loss: 0.20812974870204926\n",
            "Epoch 176/400, Batch 10/45, Loss: 0.05508267134428024\n",
            "Epoch 176/400, Batch 11/45, Loss: 0.019888723269104958\n",
            "Epoch 176/400, Batch 12/45, Loss: 0.08159467577934265\n",
            "Epoch 176/400, Batch 13/45, Loss: 0.049425043165683746\n",
            "Epoch 176/400, Batch 14/45, Loss: 0.10757960379123688\n",
            "Epoch 176/400, Batch 15/45, Loss: 0.04170537367463112\n",
            "Epoch 176/400, Batch 16/45, Loss: 0.1553560048341751\n",
            "Epoch 176/400, Batch 17/45, Loss: 0.0427338145673275\n",
            "Epoch 176/400, Batch 18/45, Loss: 0.0299458559602499\n",
            "Epoch 176/400, Batch 19/45, Loss: 0.0389045812189579\n",
            "Epoch 176/400, Batch 20/45, Loss: 0.04211016744375229\n",
            "Epoch 176/400, Batch 21/45, Loss: 0.013323279097676277\n",
            "Epoch 176/400, Batch 22/45, Loss: 0.06554272770881653\n",
            "Epoch 176/400, Batch 23/45, Loss: 0.04332637041807175\n",
            "Epoch 176/400, Batch 24/45, Loss: 0.16428838670253754\n",
            "Epoch 176/400, Batch 25/45, Loss: 0.1435871720314026\n",
            "Epoch 176/400, Batch 26/45, Loss: 0.060790833085775375\n",
            "Epoch 176/400, Batch 27/45, Loss: 0.035216815769672394\n",
            "Epoch 176/400, Batch 28/45, Loss: 0.0946374163031578\n",
            "Epoch 176/400, Batch 29/45, Loss: 0.030531052500009537\n",
            "Epoch 176/400, Batch 30/45, Loss: 0.0468260757625103\n",
            "Epoch 176/400, Batch 31/45, Loss: 0.04357634112238884\n",
            "Epoch 176/400, Batch 32/45, Loss: 0.0602630190551281\n",
            "Epoch 176/400, Batch 33/45, Loss: 0.2789725065231323\n",
            "Epoch 176/400, Batch 34/45, Loss: 0.047148458659648895\n",
            "Epoch 176/400, Batch 35/45, Loss: 0.009887069463729858\n",
            "Epoch 176/400, Batch 36/45, Loss: 0.05112594738602638\n",
            "Epoch 176/400, Batch 37/45, Loss: 0.05810482054948807\n",
            "Epoch 176/400, Batch 38/45, Loss: 0.06431236863136292\n",
            "Epoch 176/400, Batch 39/45, Loss: 0.022656776010990143\n",
            "Epoch 176/400, Batch 40/45, Loss: 0.039287615567445755\n",
            "Epoch 176/400, Batch 41/45, Loss: 0.04485888406634331\n",
            "Epoch 176/400, Batch 42/45, Loss: 0.048079486936330795\n",
            "Epoch 176/400, Batch 43/45, Loss: 0.010134527459740639\n",
            "Epoch 176/400, Batch 44/45, Loss: 0.018145332112908363\n",
            "Epoch 176/400, Batch 45/45, Loss: 0.07153716683387756\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.9410652965307236 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  177 , Time Elapsed:  140.41836493810018  mins\n",
            "Epoch 177/400, Batch 1/45, Loss: 0.04439544677734375\n",
            "Epoch 177/400, Batch 2/45, Loss: 0.03725563734769821\n",
            "Epoch 177/400, Batch 3/45, Loss: 0.040592968463897705\n",
            "Epoch 177/400, Batch 4/45, Loss: 0.052004992961883545\n",
            "Epoch 177/400, Batch 5/45, Loss: 0.059489957988262177\n",
            "Epoch 177/400, Batch 6/45, Loss: 0.05408010631799698\n",
            "Epoch 177/400, Batch 7/45, Loss: 0.05078596994280815\n",
            "Epoch 177/400, Batch 8/45, Loss: 0.04115575551986694\n",
            "Epoch 177/400, Batch 9/45, Loss: 0.014365176670253277\n",
            "Epoch 177/400, Batch 10/45, Loss: 0.15463581681251526\n",
            "Epoch 177/400, Batch 11/45, Loss: 0.024218741804361343\n",
            "Epoch 177/400, Batch 12/45, Loss: 0.14234457910060883\n",
            "Epoch 177/400, Batch 13/45, Loss: 0.057077206671237946\n",
            "Epoch 177/400, Batch 14/45, Loss: 0.01947825402021408\n",
            "Epoch 177/400, Batch 15/45, Loss: 0.016314860433340073\n",
            "Epoch 177/400, Batch 16/45, Loss: 0.017818104475736618\n",
            "Epoch 177/400, Batch 17/45, Loss: 0.01840592920780182\n",
            "Epoch 177/400, Batch 18/45, Loss: 0.030311185866594315\n",
            "Epoch 177/400, Batch 19/45, Loss: 0.10344064980745316\n",
            "Epoch 177/400, Batch 20/45, Loss: 0.05523630231618881\n",
            "Epoch 177/400, Batch 21/45, Loss: 0.02887706644833088\n",
            "Epoch 177/400, Batch 22/45, Loss: 0.014230724424123764\n",
            "Epoch 177/400, Batch 23/45, Loss: 0.010825940407812595\n",
            "Epoch 177/400, Batch 24/45, Loss: 0.038255829364061356\n",
            "Epoch 177/400, Batch 25/45, Loss: 0.025230772793293\n",
            "Epoch 177/400, Batch 26/45, Loss: 0.04432139918208122\n",
            "Epoch 177/400, Batch 27/45, Loss: 0.009068166837096214\n",
            "Epoch 177/400, Batch 28/45, Loss: 0.01946616731584072\n",
            "Epoch 177/400, Batch 29/45, Loss: 0.07443678379058838\n",
            "Epoch 177/400, Batch 30/45, Loss: 0.014900799840688705\n",
            "Epoch 177/400, Batch 31/45, Loss: 0.033197544515132904\n",
            "Epoch 177/400, Batch 32/45, Loss: 0.02063523605465889\n",
            "Epoch 177/400, Batch 33/45, Loss: 0.01977732963860035\n",
            "Epoch 177/400, Batch 34/45, Loss: 0.009604213759303093\n",
            "Epoch 177/400, Batch 35/45, Loss: 0.024593370035290718\n",
            "Epoch 177/400, Batch 36/45, Loss: 0.022513993084430695\n",
            "Epoch 177/400, Batch 37/45, Loss: 0.0701417401432991\n",
            "Epoch 177/400, Batch 38/45, Loss: 0.031053710728883743\n",
            "Epoch 177/400, Batch 39/45, Loss: 0.0056847454980015755\n",
            "Epoch 177/400, Batch 40/45, Loss: 0.01415855810046196\n",
            "Epoch 177/400, Batch 41/45, Loss: 0.012119662947952747\n",
            "Epoch 177/400, Batch 42/45, Loss: 0.0703313797712326\n",
            "Epoch 177/400, Batch 43/45, Loss: 0.04091615602374077\n",
            "Epoch 177/400, Batch 44/45, Loss: 0.08967777341604233\n",
            "Epoch 177/400, Batch 45/45, Loss: 0.027147600427269936\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.766284704208374 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  178 , Time Elapsed:  141.21034748951595  mins\n",
            "Epoch 178/400, Batch 1/45, Loss: 0.021443216130137444\n",
            "Epoch 178/400, Batch 2/45, Loss: 0.03598121181130409\n",
            "Epoch 178/400, Batch 3/45, Loss: 0.08739067614078522\n",
            "Epoch 178/400, Batch 4/45, Loss: 0.017910558730363846\n",
            "Epoch 178/400, Batch 5/45, Loss: 0.02252689003944397\n",
            "Epoch 178/400, Batch 6/45, Loss: 0.02420182153582573\n",
            "Epoch 178/400, Batch 7/45, Loss: 0.018815631046891212\n",
            "Epoch 178/400, Batch 8/45, Loss: 0.03087874874472618\n",
            "Epoch 178/400, Batch 9/45, Loss: 0.035264354199171066\n",
            "Epoch 178/400, Batch 10/45, Loss: 0.0630466639995575\n",
            "Epoch 178/400, Batch 11/45, Loss: 0.00956825539469719\n",
            "Epoch 178/400, Batch 12/45, Loss: 0.01796506904065609\n",
            "Epoch 178/400, Batch 13/45, Loss: 0.0038108532316982746\n",
            "Epoch 178/400, Batch 14/45, Loss: 0.02014177478849888\n",
            "Epoch 178/400, Batch 15/45, Loss: 0.019524045288562775\n",
            "Epoch 178/400, Batch 16/45, Loss: 0.029150329530239105\n",
            "Epoch 178/400, Batch 17/45, Loss: 0.028093570843338966\n",
            "Epoch 178/400, Batch 18/45, Loss: 0.0517769530415535\n",
            "Epoch 178/400, Batch 19/45, Loss: 0.007632346823811531\n",
            "Epoch 178/400, Batch 20/45, Loss: 0.019130799919366837\n",
            "Epoch 178/400, Batch 21/45, Loss: 0.03685980662703514\n",
            "Epoch 178/400, Batch 22/45, Loss: 0.16885168850421906\n",
            "Epoch 178/400, Batch 23/45, Loss: 0.012274635955691338\n",
            "Epoch 178/400, Batch 24/45, Loss: 0.027926219627261162\n",
            "Epoch 178/400, Batch 25/45, Loss: 0.02433886006474495\n",
            "Epoch 178/400, Batch 26/45, Loss: 0.038880858570337296\n",
            "Epoch 178/400, Batch 27/45, Loss: 0.04855670779943466\n",
            "Epoch 178/400, Batch 28/45, Loss: 0.056126996874809265\n",
            "Epoch 178/400, Batch 29/45, Loss: 0.02015569619834423\n",
            "Epoch 178/400, Batch 30/45, Loss: 0.007515186909586191\n",
            "Epoch 178/400, Batch 31/45, Loss: 0.015151521191000938\n",
            "Epoch 178/400, Batch 32/45, Loss: 0.016182810068130493\n",
            "Epoch 178/400, Batch 33/45, Loss: 0.03175769001245499\n",
            "Epoch 178/400, Batch 34/45, Loss: 0.02254069782793522\n",
            "Epoch 178/400, Batch 35/45, Loss: 0.015832532197237015\n",
            "Epoch 178/400, Batch 36/45, Loss: 0.057859912514686584\n",
            "Epoch 178/400, Batch 37/45, Loss: 0.018914004787802696\n",
            "Epoch 178/400, Batch 38/45, Loss: 0.014371916651725769\n",
            "Epoch 178/400, Batch 39/45, Loss: 0.023651327937841415\n",
            "Epoch 178/400, Batch 40/45, Loss: 0.01157384179532528\n",
            "Epoch 178/400, Batch 41/45, Loss: 0.04789276048541069\n",
            "Epoch 178/400, Batch 42/45, Loss: 0.0329710878431797\n",
            "Epoch 178/400, Batch 43/45, Loss: 0.024689359590411186\n",
            "Epoch 178/400, Batch 44/45, Loss: 0.01828416995704174\n",
            "Epoch 178/400, Batch 45/45, Loss: 0.015446622855961323\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.4529484286904335 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  179 , Time Elapsed:  142.00104896227518  mins\n",
            "Epoch 179/400, Batch 1/45, Loss: 0.0242127887904644\n",
            "Epoch 179/400, Batch 2/45, Loss: 0.026340961456298828\n",
            "Epoch 179/400, Batch 3/45, Loss: 0.029999246820807457\n",
            "Epoch 179/400, Batch 4/45, Loss: 0.06545861065387726\n",
            "Epoch 179/400, Batch 5/45, Loss: 0.038476742804050446\n",
            "Epoch 179/400, Batch 6/45, Loss: 0.05766715109348297\n",
            "Epoch 179/400, Batch 7/45, Loss: 0.015345423482358456\n",
            "Epoch 179/400, Batch 8/45, Loss: 0.024075521156191826\n",
            "Epoch 179/400, Batch 9/45, Loss: 0.01046764850616455\n",
            "Epoch 179/400, Batch 10/45, Loss: 0.025633690878748894\n",
            "Epoch 179/400, Batch 11/45, Loss: 0.042230576276779175\n",
            "Epoch 179/400, Batch 12/45, Loss: 0.015886954963207245\n",
            "Epoch 179/400, Batch 13/45, Loss: 0.017875362187623978\n",
            "Epoch 179/400, Batch 14/45, Loss: 0.035971999168395996\n",
            "Epoch 179/400, Batch 15/45, Loss: 0.04081748425960541\n",
            "Epoch 179/400, Batch 16/45, Loss: 2.206378221511841\n",
            "Epoch 179/400, Batch 17/45, Loss: 0.07970762252807617\n",
            "Epoch 179/400, Batch 18/45, Loss: 0.14584724605083466\n",
            "Epoch 179/400, Batch 19/45, Loss: 0.10578122735023499\n",
            "Epoch 179/400, Batch 20/45, Loss: 0.2049456685781479\n",
            "Epoch 179/400, Batch 21/45, Loss: 0.14847968518733978\n",
            "Epoch 179/400, Batch 22/45, Loss: 0.15881317853927612\n",
            "Epoch 179/400, Batch 23/45, Loss: 0.17576931416988373\n",
            "Epoch 179/400, Batch 24/45, Loss: 0.2184470295906067\n",
            "Epoch 179/400, Batch 25/45, Loss: 0.24753808975219727\n",
            "Epoch 179/400, Batch 26/45, Loss: 0.37889355421066284\n",
            "Epoch 179/400, Batch 27/45, Loss: 0.09651883691549301\n",
            "Epoch 179/400, Batch 28/45, Loss: 0.06457580626010895\n",
            "Epoch 179/400, Batch 29/45, Loss: 0.0644112080335617\n",
            "Epoch 179/400, Batch 30/45, Loss: 0.06218734756112099\n",
            "Epoch 179/400, Batch 31/45, Loss: 0.10706953704357147\n",
            "Epoch 179/400, Batch 32/45, Loss: 0.027285585179924965\n",
            "Epoch 179/400, Batch 33/45, Loss: 0.037850480526685715\n",
            "Epoch 179/400, Batch 34/45, Loss: 0.0406031496822834\n",
            "Epoch 179/400, Batch 35/45, Loss: 0.03442755341529846\n",
            "Epoch 179/400, Batch 36/45, Loss: 0.17339691519737244\n",
            "Epoch 179/400, Batch 37/45, Loss: 0.05252765119075775\n",
            "Epoch 179/400, Batch 38/45, Loss: 0.03933822363615036\n",
            "Epoch 179/400, Batch 39/45, Loss: 0.06805147975683212\n",
            "Epoch 179/400, Batch 40/45, Loss: 0.009833669289946556\n",
            "Epoch 179/400, Batch 41/45, Loss: 0.09564933180809021\n",
            "Epoch 179/400, Batch 42/45, Loss: 0.12178632616996765\n",
            "Epoch 179/400, Batch 43/45, Loss: 0.03650035336613655\n",
            "Epoch 179/400, Batch 44/45, Loss: 0.10839743912220001\n",
            "Epoch 179/400, Batch 45/45, Loss: 0.46001869440078735\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.7276894301176071 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  180 , Time Elapsed:  142.7885523080826  mins\n",
            "Epoch 180/400, Batch 1/45, Loss: 0.011527039110660553\n",
            "Epoch 180/400, Batch 2/45, Loss: 0.12140249460935593\n",
            "Epoch 180/400, Batch 3/45, Loss: 0.066600501537323\n",
            "Epoch 180/400, Batch 4/45, Loss: 0.0872252956032753\n",
            "Epoch 180/400, Batch 5/45, Loss: 0.0679452046751976\n",
            "Epoch 180/400, Batch 6/45, Loss: 0.053114525973796844\n",
            "Epoch 180/400, Batch 7/45, Loss: 0.05796492099761963\n",
            "Epoch 180/400, Batch 8/45, Loss: 0.01439558994024992\n",
            "Epoch 180/400, Batch 9/45, Loss: 0.033286795020103455\n",
            "Epoch 180/400, Batch 10/45, Loss: 0.03374909982085228\n",
            "Epoch 180/400, Batch 11/45, Loss: 0.16434569656848907\n",
            "Epoch 180/400, Batch 12/45, Loss: 0.04834325611591339\n",
            "Epoch 180/400, Batch 13/45, Loss: 0.03190353512763977\n",
            "Epoch 180/400, Batch 14/45, Loss: 0.030037030577659607\n",
            "Epoch 180/400, Batch 15/45, Loss: 0.02331802435219288\n",
            "Epoch 180/400, Batch 16/45, Loss: 0.07819509506225586\n",
            "Epoch 180/400, Batch 17/45, Loss: 0.04543345794081688\n",
            "Epoch 180/400, Batch 18/45, Loss: 0.08650688827037811\n",
            "Epoch 180/400, Batch 19/45, Loss: 0.047008316963911057\n",
            "Epoch 180/400, Batch 20/45, Loss: 0.036804188042879105\n",
            "Epoch 180/400, Batch 21/45, Loss: 0.007662578951567411\n",
            "Epoch 180/400, Batch 22/45, Loss: 0.04441465064883232\n",
            "Epoch 180/400, Batch 23/45, Loss: 0.06832227855920792\n",
            "Epoch 180/400, Batch 24/45, Loss: 0.12735196948051453\n",
            "Epoch 180/400, Batch 25/45, Loss: 0.04406951367855072\n",
            "Epoch 180/400, Batch 26/45, Loss: 0.018145110458135605\n",
            "Epoch 180/400, Batch 27/45, Loss: 0.0419246181845665\n",
            "Epoch 180/400, Batch 28/45, Loss: 0.030138855800032616\n",
            "Epoch 180/400, Batch 29/45, Loss: 0.022224975749850273\n",
            "Epoch 180/400, Batch 30/45, Loss: 0.005650373175740242\n",
            "Epoch 180/400, Batch 31/45, Loss: 0.024422215297818184\n",
            "Epoch 180/400, Batch 32/45, Loss: 0.03310393542051315\n",
            "Epoch 180/400, Batch 33/45, Loss: 0.06338588893413544\n",
            "Epoch 180/400, Batch 34/45, Loss: 0.03416408598423004\n",
            "Epoch 180/400, Batch 35/45, Loss: 0.06627661734819412\n",
            "Epoch 180/400, Batch 36/45, Loss: 0.02242574468255043\n",
            "Epoch 180/400, Batch 37/45, Loss: 0.6810622215270996\n",
            "Epoch 180/400, Batch 38/45, Loss: 0.17321500182151794\n",
            "Epoch 180/400, Batch 39/45, Loss: 0.014098632149398327\n",
            "Epoch 180/400, Batch 40/45, Loss: 0.091813825070858\n",
            "Epoch 180/400, Batch 41/45, Loss: 0.020724492147564888\n",
            "Epoch 180/400, Batch 42/45, Loss: 0.07638806104660034\n",
            "Epoch 180/400, Batch 43/45, Loss: 0.09238694608211517\n",
            "Epoch 180/400, Batch 44/45, Loss: 0.14810509979724884\n",
            "Epoch 180/400, Batch 45/45, Loss: 0.10422508418560028\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  3.0742640793323517 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  181 , Time Elapsed:  143.59867068926494  mins\n",
            "Epoch 181/400, Batch 1/45, Loss: 0.34079939126968384\n",
            "Epoch 181/400, Batch 2/45, Loss: 0.07574939727783203\n",
            "Epoch 181/400, Batch 3/45, Loss: 0.05382535606622696\n",
            "Epoch 181/400, Batch 4/45, Loss: 0.07028798758983612\n",
            "Epoch 181/400, Batch 5/45, Loss: 0.02928030863404274\n",
            "Epoch 181/400, Batch 6/45, Loss: 0.04430726170539856\n",
            "Epoch 181/400, Batch 7/45, Loss: 0.07071065902709961\n",
            "Epoch 181/400, Batch 8/45, Loss: 0.02437542751431465\n",
            "Epoch 181/400, Batch 9/45, Loss: 0.014722375199198723\n",
            "Epoch 181/400, Batch 10/45, Loss: 0.09395302087068558\n",
            "Epoch 181/400, Batch 11/45, Loss: 0.040504395961761475\n",
            "Epoch 181/400, Batch 12/45, Loss: 0.024854134768247604\n",
            "Epoch 181/400, Batch 13/45, Loss: 0.04178560897707939\n",
            "Epoch 181/400, Batch 14/45, Loss: 0.023112542927265167\n",
            "Epoch 181/400, Batch 15/45, Loss: 0.052775099873542786\n",
            "Epoch 181/400, Batch 16/45, Loss: 0.06558903306722641\n",
            "Epoch 181/400, Batch 17/45, Loss: 0.014685694128274918\n",
            "Epoch 181/400, Batch 18/45, Loss: 0.03069276735186577\n",
            "Epoch 181/400, Batch 19/45, Loss: 0.019957685843110085\n",
            "Epoch 181/400, Batch 20/45, Loss: 0.02544291876256466\n",
            "Epoch 181/400, Batch 21/45, Loss: 0.011746738106012344\n",
            "Epoch 181/400, Batch 22/45, Loss: 0.027994852513074875\n",
            "Epoch 181/400, Batch 23/45, Loss: 0.06801314651966095\n",
            "Epoch 181/400, Batch 24/45, Loss: 0.03246091306209564\n",
            "Epoch 181/400, Batch 25/45, Loss: 0.053029246628284454\n",
            "Epoch 181/400, Batch 26/45, Loss: 0.2764660716056824\n",
            "Epoch 181/400, Batch 27/45, Loss: 0.017508050426840782\n",
            "Epoch 181/400, Batch 28/45, Loss: 0.0352819561958313\n",
            "Epoch 181/400, Batch 29/45, Loss: 0.022151285782456398\n",
            "Epoch 181/400, Batch 30/45, Loss: 0.03518228232860565\n",
            "Epoch 181/400, Batch 31/45, Loss: 0.045936644077301025\n",
            "Epoch 181/400, Batch 32/45, Loss: 0.024956660345196724\n",
            "Epoch 181/400, Batch 33/45, Loss: 0.046590812504291534\n",
            "Epoch 181/400, Batch 34/45, Loss: 0.026676230132579803\n",
            "Epoch 181/400, Batch 35/45, Loss: 0.18602508306503296\n",
            "Epoch 181/400, Batch 36/45, Loss: 0.023552000522613525\n",
            "Epoch 181/400, Batch 37/45, Loss: 0.07522899657487869\n",
            "Epoch 181/400, Batch 38/45, Loss: 0.03833536058664322\n",
            "Epoch 181/400, Batch 39/45, Loss: 0.025738563388586044\n",
            "Epoch 181/400, Batch 40/45, Loss: 0.04097171872854233\n",
            "Epoch 181/400, Batch 41/45, Loss: 0.030520742759108543\n",
            "Epoch 181/400, Batch 42/45, Loss: 0.03428620845079422\n",
            "Epoch 181/400, Batch 43/45, Loss: 0.03492741659283638\n",
            "Epoch 181/400, Batch 44/45, Loss: 0.05369936674833298\n",
            "Epoch 181/400, Batch 45/45, Loss: 0.027813220396637917\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.7448813170194626 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  182 , Time Elapsed:  144.38511241674422  mins\n",
            "Epoch 182/400, Batch 1/45, Loss: 0.03567272797226906\n",
            "Epoch 182/400, Batch 2/45, Loss: 0.02862379513680935\n",
            "Epoch 182/400, Batch 3/45, Loss: 0.03178045153617859\n",
            "Epoch 182/400, Batch 4/45, Loss: 0.031438808888196945\n",
            "Epoch 182/400, Batch 5/45, Loss: 0.01493026502430439\n",
            "Epoch 182/400, Batch 6/45, Loss: 0.03323616459965706\n",
            "Epoch 182/400, Batch 7/45, Loss: 0.046015918254852295\n",
            "Epoch 182/400, Batch 8/45, Loss: 0.02572939731180668\n",
            "Epoch 182/400, Batch 9/45, Loss: 0.02073432132601738\n",
            "Epoch 182/400, Batch 10/45, Loss: 0.3281272053718567\n",
            "Epoch 182/400, Batch 11/45, Loss: 0.0512935072183609\n",
            "Epoch 182/400, Batch 12/45, Loss: 0.003940588794648647\n",
            "Epoch 182/400, Batch 13/45, Loss: 0.019762687385082245\n",
            "Epoch 182/400, Batch 14/45, Loss: 0.04402068257331848\n",
            "Epoch 182/400, Batch 15/45, Loss: 0.015212579630315304\n",
            "Epoch 182/400, Batch 16/45, Loss: 0.05949502810835838\n",
            "Epoch 182/400, Batch 17/45, Loss: 0.07165799289941788\n",
            "Epoch 182/400, Batch 18/45, Loss: 0.042954832315444946\n",
            "Epoch 182/400, Batch 19/45, Loss: 0.03555835038423538\n",
            "Epoch 182/400, Batch 20/45, Loss: 0.02398098073899746\n",
            "Epoch 182/400, Batch 21/45, Loss: 0.02868737280368805\n",
            "Epoch 182/400, Batch 22/45, Loss: 0.039728451520204544\n",
            "Epoch 182/400, Batch 23/45, Loss: 0.051832929253578186\n",
            "Epoch 182/400, Batch 24/45, Loss: 0.08053554594516754\n",
            "Epoch 182/400, Batch 25/45, Loss: 0.013545683585107327\n",
            "Epoch 182/400, Batch 26/45, Loss: 0.2095976322889328\n",
            "Epoch 182/400, Batch 27/45, Loss: 0.06591124832630157\n",
            "Epoch 182/400, Batch 28/45, Loss: 0.0607089027762413\n",
            "Epoch 182/400, Batch 29/45, Loss: 0.013779552653431892\n",
            "Epoch 182/400, Batch 30/45, Loss: 0.023834459483623505\n",
            "Epoch 182/400, Batch 31/45, Loss: 0.024133222177624702\n",
            "Epoch 182/400, Batch 32/45, Loss: 0.02136991359293461\n",
            "Epoch 182/400, Batch 33/45, Loss: 0.04676273092627525\n",
            "Epoch 182/400, Batch 34/45, Loss: 0.03697824105620384\n",
            "Epoch 182/400, Batch 35/45, Loss: 0.023286592215299606\n",
            "Epoch 182/400, Batch 36/45, Loss: 0.03686898946762085\n",
            "Epoch 182/400, Batch 37/45, Loss: 0.07140342146158218\n",
            "Epoch 182/400, Batch 38/45, Loss: 0.0483224093914032\n",
            "Epoch 182/400, Batch 39/45, Loss: 0.04069371148943901\n",
            "Epoch 182/400, Batch 40/45, Loss: 0.05277179181575775\n",
            "Epoch 182/400, Batch 41/45, Loss: 0.0063948561437428\n",
            "Epoch 182/400, Batch 42/45, Loss: 0.0313342921435833\n",
            "Epoch 182/400, Batch 43/45, Loss: 0.03619280084967613\n",
            "Epoch 182/400, Batch 44/45, Loss: 0.030561739578843117\n",
            "Epoch 182/400, Batch 45/45, Loss: 0.009920354001224041\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.5527004711329937 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  183 , Time Elapsed:  145.20936236778894  mins\n",
            "Epoch 183/400, Batch 1/45, Loss: 0.06850200146436691\n",
            "Epoch 183/400, Batch 2/45, Loss: 0.008603259921073914\n",
            "Epoch 183/400, Batch 3/45, Loss: 0.03467271476984024\n",
            "Epoch 183/400, Batch 4/45, Loss: 0.03342654928565025\n",
            "Epoch 183/400, Batch 5/45, Loss: 0.04220826178789139\n",
            "Epoch 183/400, Batch 6/45, Loss: 0.016062967479228973\n",
            "Epoch 183/400, Batch 7/45, Loss: 0.007243361324071884\n",
            "Epoch 183/400, Batch 8/45, Loss: 0.048885077238082886\n",
            "Epoch 183/400, Batch 9/45, Loss: 0.020173072814941406\n",
            "Epoch 183/400, Batch 10/45, Loss: 0.13883677124977112\n",
            "Epoch 183/400, Batch 11/45, Loss: 0.008352340199053288\n",
            "Epoch 183/400, Batch 12/45, Loss: 0.046889565885066986\n",
            "Epoch 183/400, Batch 13/45, Loss: 0.027792084962129593\n",
            "Epoch 183/400, Batch 14/45, Loss: 0.030555278062820435\n",
            "Epoch 183/400, Batch 15/45, Loss: 0.08557053655385971\n",
            "Epoch 183/400, Batch 16/45, Loss: 0.03744615986943245\n",
            "Epoch 183/400, Batch 17/45, Loss: 0.015152892097830772\n",
            "Epoch 183/400, Batch 18/45, Loss: 0.016987372189760208\n",
            "Epoch 183/400, Batch 19/45, Loss: 0.016968635842204094\n",
            "Epoch 183/400, Batch 20/45, Loss: 0.015571177005767822\n",
            "Epoch 183/400, Batch 21/45, Loss: 0.03407252952456474\n",
            "Epoch 183/400, Batch 22/45, Loss: 0.05418648570775986\n",
            "Epoch 183/400, Batch 23/45, Loss: 0.048156797885894775\n",
            "Epoch 183/400, Batch 24/45, Loss: 0.030301397666335106\n",
            "Epoch 183/400, Batch 25/45, Loss: 0.026987258344888687\n",
            "Epoch 183/400, Batch 26/45, Loss: 0.022829271852970123\n",
            "Epoch 183/400, Batch 27/45, Loss: 0.03254956379532814\n",
            "Epoch 183/400, Batch 28/45, Loss: 0.04300354793667793\n",
            "Epoch 183/400, Batch 29/45, Loss: 0.060960981994867325\n",
            "Epoch 183/400, Batch 30/45, Loss: 0.014709509909152985\n",
            "Epoch 183/400, Batch 31/45, Loss: 0.03357890620827675\n",
            "Epoch 183/400, Batch 32/45, Loss: 0.0298677459359169\n",
            "Epoch 183/400, Batch 33/45, Loss: 0.021396715193986893\n",
            "Epoch 183/400, Batch 34/45, Loss: 0.010983249172568321\n",
            "Epoch 183/400, Batch 35/45, Loss: 0.012631809338927269\n",
            "Epoch 183/400, Batch 36/45, Loss: 0.01523337047547102\n",
            "Epoch 183/400, Batch 37/45, Loss: 0.025995653122663498\n",
            "Epoch 183/400, Batch 38/45, Loss: 0.016064852476119995\n",
            "Epoch 183/400, Batch 39/45, Loss: 0.008507458493113518\n",
            "Epoch 183/400, Batch 40/45, Loss: 0.03720122203230858\n",
            "Epoch 183/400, Batch 41/45, Loss: 0.01986546814441681\n",
            "Epoch 183/400, Batch 42/45, Loss: 0.026545431464910507\n",
            "Epoch 183/400, Batch 43/45, Loss: 0.0324171707034111\n",
            "Epoch 183/400, Batch 44/45, Loss: 0.02051701582968235\n",
            "Epoch 183/400, Batch 45/45, Loss: 0.012846022844314575\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.653266303241253 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  184 , Time Elapsed:  145.99140036503474  mins\n",
            "Epoch 184/400, Batch 1/45, Loss: 0.011952875182032585\n",
            "Epoch 184/400, Batch 2/45, Loss: 0.031119028106331825\n",
            "Epoch 184/400, Batch 3/45, Loss: 0.019007710739970207\n",
            "Epoch 184/400, Batch 4/45, Loss: 0.023917192593216896\n",
            "Epoch 184/400, Batch 5/45, Loss: 0.03214043006300926\n",
            "Epoch 184/400, Batch 6/45, Loss: 0.010548840276896954\n",
            "Epoch 184/400, Batch 7/45, Loss: 0.02769915945827961\n",
            "Epoch 184/400, Batch 8/45, Loss: 0.03650105744600296\n",
            "Epoch 184/400, Batch 9/45, Loss: 0.009903396479785442\n",
            "Epoch 184/400, Batch 10/45, Loss: 0.009510797448456287\n",
            "Epoch 184/400, Batch 11/45, Loss: 0.0543326735496521\n",
            "Epoch 184/400, Batch 12/45, Loss: 0.013943398371338844\n",
            "Epoch 184/400, Batch 13/45, Loss: 0.00909758172929287\n",
            "Epoch 184/400, Batch 14/45, Loss: 0.019624536857008934\n",
            "Epoch 184/400, Batch 15/45, Loss: 0.004355877637863159\n",
            "Epoch 184/400, Batch 16/45, Loss: 0.022808421403169632\n",
            "Epoch 184/400, Batch 17/45, Loss: 0.013883775100111961\n",
            "Epoch 184/400, Batch 18/45, Loss: 0.033686310052871704\n",
            "Epoch 184/400, Batch 19/45, Loss: 0.015147222205996513\n",
            "Epoch 184/400, Batch 20/45, Loss: 0.034109361469745636\n",
            "Epoch 184/400, Batch 21/45, Loss: 0.01822636090219021\n",
            "Epoch 184/400, Batch 22/45, Loss: 0.00765957310795784\n",
            "Epoch 184/400, Batch 23/45, Loss: 0.010859984904527664\n",
            "Epoch 184/400, Batch 24/45, Loss: 0.02913895808160305\n",
            "Epoch 184/400, Batch 25/45, Loss: 0.018667172640562057\n",
            "Epoch 184/400, Batch 26/45, Loss: 0.004714765585958958\n",
            "Epoch 184/400, Batch 27/45, Loss: 0.040912285447120667\n",
            "Epoch 184/400, Batch 28/45, Loss: 0.023220399394631386\n",
            "Epoch 184/400, Batch 29/45, Loss: 0.017718516290187836\n",
            "Epoch 184/400, Batch 30/45, Loss: 0.04895278066396713\n",
            "Epoch 184/400, Batch 31/45, Loss: 0.04007621854543686\n",
            "Epoch 184/400, Batch 32/45, Loss: 0.014163903892040253\n",
            "Epoch 184/400, Batch 33/45, Loss: 0.02417803183197975\n",
            "Epoch 184/400, Batch 34/45, Loss: 0.03357923403382301\n",
            "Epoch 184/400, Batch 35/45, Loss: 0.17154288291931152\n",
            "Epoch 184/400, Batch 36/45, Loss: 0.021093901246786118\n",
            "Epoch 184/400, Batch 37/45, Loss: 0.019139539450407028\n",
            "Epoch 184/400, Batch 38/45, Loss: 0.02917412854731083\n",
            "Epoch 184/400, Batch 39/45, Loss: 0.01589779369533062\n",
            "Epoch 184/400, Batch 40/45, Loss: 0.015155281871557236\n",
            "Epoch 184/400, Batch 41/45, Loss: 0.06564322113990784\n",
            "Epoch 184/400, Batch 42/45, Loss: 0.006219638977199793\n",
            "Epoch 184/400, Batch 43/45, Loss: 0.02537441998720169\n",
            "Epoch 184/400, Batch 44/45, Loss: 0.049952685832977295\n",
            "Epoch 184/400, Batch 45/45, Loss: 0.012854661792516708\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.3256649523973465 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  185 , Time Elapsed:  146.81657669146855  mins\n",
            "Epoch 185/400, Batch 1/45, Loss: 0.009476792067289352\n",
            "Epoch 185/400, Batch 2/45, Loss: 0.022068876773118973\n",
            "Epoch 185/400, Batch 3/45, Loss: 0.01432209461927414\n",
            "Epoch 185/400, Batch 4/45, Loss: 0.01757049933075905\n",
            "Epoch 185/400, Batch 5/45, Loss: 0.005517648998647928\n",
            "Epoch 185/400, Batch 6/45, Loss: 0.016774041578173637\n",
            "Epoch 185/400, Batch 7/45, Loss: 0.00295755616389215\n",
            "Epoch 185/400, Batch 8/45, Loss: 0.07680241763591766\n",
            "Epoch 185/400, Batch 9/45, Loss: 0.10807918012142181\n",
            "Epoch 185/400, Batch 10/45, Loss: 0.011879012919962406\n",
            "Epoch 185/400, Batch 11/45, Loss: 0.026662779971957207\n",
            "Epoch 185/400, Batch 12/45, Loss: 0.02978116273880005\n",
            "Epoch 185/400, Batch 13/45, Loss: 0.01079386193305254\n",
            "Epoch 185/400, Batch 14/45, Loss: 0.02274411730468273\n",
            "Epoch 185/400, Batch 15/45, Loss: 0.023640891537070274\n",
            "Epoch 185/400, Batch 16/45, Loss: 0.015360635705292225\n",
            "Epoch 185/400, Batch 17/45, Loss: 0.028445139527320862\n",
            "Epoch 185/400, Batch 18/45, Loss: 0.040208786725997925\n",
            "Epoch 185/400, Batch 19/45, Loss: 0.01025891862809658\n",
            "Epoch 185/400, Batch 20/45, Loss: 0.014118785038590431\n",
            "Epoch 185/400, Batch 21/45, Loss: 0.025370005518198013\n",
            "Epoch 185/400, Batch 22/45, Loss: 0.019757717847824097\n",
            "Epoch 185/400, Batch 23/45, Loss: 0.04009038582444191\n",
            "Epoch 185/400, Batch 24/45, Loss: 0.03499465063214302\n",
            "Epoch 185/400, Batch 25/45, Loss: 0.02292053773999214\n",
            "Epoch 185/400, Batch 26/45, Loss: 0.005026446655392647\n",
            "Epoch 185/400, Batch 27/45, Loss: 0.006399502046406269\n",
            "Epoch 185/400, Batch 28/45, Loss: 0.025619780644774437\n",
            "Epoch 185/400, Batch 29/45, Loss: 0.012384508736431599\n",
            "Epoch 185/400, Batch 30/45, Loss: 0.03125545382499695\n",
            "Epoch 185/400, Batch 31/45, Loss: 0.01835041679441929\n",
            "Epoch 185/400, Batch 32/45, Loss: 0.019427774474024773\n",
            "Epoch 185/400, Batch 33/45, Loss: 0.048790641129016876\n",
            "Epoch 185/400, Batch 34/45, Loss: 0.017736997455358505\n",
            "Epoch 185/400, Batch 35/45, Loss: 0.012184884399175644\n",
            "Epoch 185/400, Batch 36/45, Loss: 0.018988316878676414\n",
            "Epoch 185/400, Batch 37/45, Loss: 0.03402383625507355\n",
            "Epoch 185/400, Batch 38/45, Loss: 0.04281388595700264\n",
            "Epoch 185/400, Batch 39/45, Loss: 0.026686420664191246\n",
            "Epoch 185/400, Batch 40/45, Loss: 0.030122697353363037\n",
            "Epoch 185/400, Batch 41/45, Loss: 0.009192466735839844\n",
            "Epoch 185/400, Batch 42/45, Loss: 0.018593791872262955\n",
            "Epoch 185/400, Batch 43/45, Loss: 0.010914187878370285\n",
            "Epoch 185/400, Batch 44/45, Loss: 0.03435305505990982\n",
            "Epoch 185/400, Batch 45/45, Loss: 0.041329529136419296\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.6474439427256584 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  186 , Time Elapsed:  147.59412988821666  mins\n",
            "Epoch 186/400, Batch 1/45, Loss: 0.012765156105160713\n",
            "Epoch 186/400, Batch 2/45, Loss: 0.04652523994445801\n",
            "Epoch 186/400, Batch 3/45, Loss: 0.038374803960323334\n",
            "Epoch 186/400, Batch 4/45, Loss: 0.017580119892954826\n",
            "Epoch 186/400, Batch 5/45, Loss: 0.030361557379364967\n",
            "Epoch 186/400, Batch 6/45, Loss: 0.03523258864879608\n",
            "Epoch 186/400, Batch 7/45, Loss: 0.05806814879179001\n",
            "Epoch 186/400, Batch 8/45, Loss: 0.007954242639243603\n",
            "Epoch 186/400, Batch 9/45, Loss: 0.00721379742026329\n",
            "Epoch 186/400, Batch 10/45, Loss: 0.03508515655994415\n",
            "Epoch 186/400, Batch 11/45, Loss: 0.049646977335214615\n",
            "Epoch 186/400, Batch 12/45, Loss: 0.03857725113630295\n",
            "Epoch 186/400, Batch 13/45, Loss: 0.051211923360824585\n",
            "Epoch 186/400, Batch 14/45, Loss: 0.024818681180477142\n",
            "Epoch 186/400, Batch 15/45, Loss: 0.03908461332321167\n",
            "Epoch 186/400, Batch 16/45, Loss: 0.012527110055088997\n",
            "Epoch 186/400, Batch 17/45, Loss: 0.039346396923065186\n",
            "Epoch 186/400, Batch 18/45, Loss: 0.032672248780727386\n",
            "Epoch 186/400, Batch 19/45, Loss: 0.02595100924372673\n",
            "Epoch 186/400, Batch 20/45, Loss: 0.03348296135663986\n",
            "Epoch 186/400, Batch 21/45, Loss: 0.011383677832782269\n",
            "Epoch 186/400, Batch 22/45, Loss: 0.013096180744469166\n",
            "Epoch 186/400, Batch 23/45, Loss: 0.01630171574652195\n",
            "Epoch 186/400, Batch 24/45, Loss: 0.011394629254937172\n",
            "Epoch 186/400, Batch 25/45, Loss: 0.10394269227981567\n",
            "Epoch 186/400, Batch 26/45, Loss: 0.03828155994415283\n",
            "Epoch 186/400, Batch 27/45, Loss: 0.013045737519860268\n",
            "Epoch 186/400, Batch 28/45, Loss: 0.02079848386347294\n",
            "Epoch 186/400, Batch 29/45, Loss: 0.013756820000708103\n",
            "Epoch 186/400, Batch 30/45, Loss: 0.03780564293265343\n",
            "Epoch 186/400, Batch 31/45, Loss: 0.030304044485092163\n",
            "Epoch 186/400, Batch 32/45, Loss: 0.027700170874595642\n",
            "Epoch 186/400, Batch 33/45, Loss: 0.05687091872096062\n",
            "Epoch 186/400, Batch 34/45, Loss: 0.0383855476975441\n",
            "Epoch 186/400, Batch 35/45, Loss: 0.10113474726676941\n",
            "Epoch 186/400, Batch 36/45, Loss: 0.002304382622241974\n",
            "Epoch 186/400, Batch 37/45, Loss: 0.042392563074827194\n",
            "Epoch 186/400, Batch 38/45, Loss: 0.00906844437122345\n",
            "Epoch 186/400, Batch 39/45, Loss: 0.013732507824897766\n",
            "Epoch 186/400, Batch 40/45, Loss: 0.18549403548240662\n",
            "Epoch 186/400, Batch 41/45, Loss: 0.016868555918335915\n",
            "Epoch 186/400, Batch 42/45, Loss: 0.04253310710191727\n",
            "Epoch 186/400, Batch 43/45, Loss: 0.057228051126003265\n",
            "Epoch 186/400, Batch 44/45, Loss: 0.02751636877655983\n",
            "Epoch 186/400, Batch 45/45, Loss: 0.025887738913297653\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.4058671928942204 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  187 , Time Elapsed:  148.38202015956242  mins\n",
            "Epoch 187/400, Batch 1/45, Loss: 0.012309607118368149\n",
            "Epoch 187/400, Batch 2/45, Loss: 0.015714190900325775\n",
            "Epoch 187/400, Batch 3/45, Loss: 0.015537935309112072\n",
            "Epoch 187/400, Batch 4/45, Loss: 0.009859402664005756\n",
            "Epoch 187/400, Batch 5/45, Loss: 0.05746808648109436\n",
            "Epoch 187/400, Batch 6/45, Loss: 0.02354806289076805\n",
            "Epoch 187/400, Batch 7/45, Loss: 0.06402597576379776\n",
            "Epoch 187/400, Batch 8/45, Loss: 0.021729949861764908\n",
            "Epoch 187/400, Batch 9/45, Loss: 0.051595158874988556\n",
            "Epoch 187/400, Batch 10/45, Loss: 0.029956266283988953\n",
            "Epoch 187/400, Batch 11/45, Loss: 0.03353089094161987\n",
            "Epoch 187/400, Batch 12/45, Loss: 0.02893049456179142\n",
            "Epoch 187/400, Batch 13/45, Loss: 0.025303972885012627\n",
            "Epoch 187/400, Batch 14/45, Loss: 0.007783064618706703\n",
            "Epoch 187/400, Batch 15/45, Loss: 0.0058891307562589645\n",
            "Epoch 187/400, Batch 16/45, Loss: 0.024809136986732483\n",
            "Epoch 187/400, Batch 17/45, Loss: 0.03779210150241852\n",
            "Epoch 187/400, Batch 18/45, Loss: 0.01533000823110342\n",
            "Epoch 187/400, Batch 19/45, Loss: 0.011698379181325436\n",
            "Epoch 187/400, Batch 20/45, Loss: 0.017399242147803307\n",
            "Epoch 187/400, Batch 21/45, Loss: 0.022173235192894936\n",
            "Epoch 187/400, Batch 22/45, Loss: 0.012825660407543182\n",
            "Epoch 187/400, Batch 23/45, Loss: 0.04114552214741707\n",
            "Epoch 187/400, Batch 24/45, Loss: 0.014375261962413788\n",
            "Epoch 187/400, Batch 25/45, Loss: 0.02263060212135315\n",
            "Epoch 187/400, Batch 26/45, Loss: 0.01953360252082348\n",
            "Epoch 187/400, Batch 27/45, Loss: 0.021826524287462234\n",
            "Epoch 187/400, Batch 28/45, Loss: 0.0054189725778996944\n",
            "Epoch 187/400, Batch 29/45, Loss: 0.012163802050054073\n",
            "Epoch 187/400, Batch 30/45, Loss: 0.0608859583735466\n",
            "Epoch 187/400, Batch 31/45, Loss: 0.03976159915328026\n",
            "Epoch 187/400, Batch 32/45, Loss: 0.03511592745780945\n",
            "Epoch 187/400, Batch 33/45, Loss: 0.01578175649046898\n",
            "Epoch 187/400, Batch 34/45, Loss: 0.011632153764367104\n",
            "Epoch 187/400, Batch 35/45, Loss: 0.01712297648191452\n",
            "Epoch 187/400, Batch 36/45, Loss: 0.019057705998420715\n",
            "Epoch 187/400, Batch 37/45, Loss: 0.03621827811002731\n",
            "Epoch 187/400, Batch 38/45, Loss: 0.023013142868876457\n",
            "Epoch 187/400, Batch 39/45, Loss: 0.03412748500704765\n",
            "Epoch 187/400, Batch 40/45, Loss: 0.08655830472707748\n",
            "Epoch 187/400, Batch 41/45, Loss: 0.028766855597496033\n",
            "Epoch 187/400, Batch 42/45, Loss: 0.01696385070681572\n",
            "Epoch 187/400, Batch 43/45, Loss: 0.018098261207342148\n",
            "Epoch 187/400, Batch 44/45, Loss: 0.055180102586746216\n",
            "Epoch 187/400, Batch 45/45, Loss: 0.01589946262538433\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.6909205913543701 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  188 , Time Elapsed:  149.18038255771  mins\n",
            "Epoch 188/400, Batch 1/45, Loss: 0.051861248910427094\n",
            "Epoch 188/400, Batch 2/45, Loss: 0.013992879539728165\n",
            "Epoch 188/400, Batch 3/45, Loss: 0.01038493774831295\n",
            "Epoch 188/400, Batch 4/45, Loss: 0.01329423300921917\n",
            "Epoch 188/400, Batch 5/45, Loss: 0.02268698439002037\n",
            "Epoch 188/400, Batch 6/45, Loss: 0.06705686450004578\n",
            "Epoch 188/400, Batch 7/45, Loss: 0.006046810653060675\n",
            "Epoch 188/400, Batch 8/45, Loss: 0.05224554240703583\n",
            "Epoch 188/400, Batch 9/45, Loss: 0.013320992700755596\n",
            "Epoch 188/400, Batch 10/45, Loss: 0.03266497328877449\n",
            "Epoch 188/400, Batch 11/45, Loss: 0.03191680461168289\n",
            "Epoch 188/400, Batch 12/45, Loss: 0.013927137479186058\n",
            "Epoch 188/400, Batch 13/45, Loss: 0.042013756930828094\n",
            "Epoch 188/400, Batch 14/45, Loss: 0.00411835964769125\n",
            "Epoch 188/400, Batch 15/45, Loss: 0.03761158883571625\n",
            "Epoch 188/400, Batch 16/45, Loss: 0.03836989402770996\n",
            "Epoch 188/400, Batch 17/45, Loss: 0.06791411340236664\n",
            "Epoch 188/400, Batch 18/45, Loss: 0.018335293978452682\n",
            "Epoch 188/400, Batch 19/45, Loss: 0.04721681773662567\n",
            "Epoch 188/400, Batch 20/45, Loss: 0.029008882120251656\n",
            "Epoch 188/400, Batch 21/45, Loss: 0.014274884015321732\n",
            "Epoch 188/400, Batch 22/45, Loss: 0.01964859664440155\n",
            "Epoch 188/400, Batch 23/45, Loss: 0.0676036924123764\n",
            "Epoch 188/400, Batch 24/45, Loss: 0.024007480591535568\n",
            "Epoch 188/400, Batch 25/45, Loss: 0.018242904916405678\n",
            "Epoch 188/400, Batch 26/45, Loss: 0.012010413222014904\n",
            "Epoch 188/400, Batch 27/45, Loss: 0.014431091025471687\n",
            "Epoch 188/400, Batch 28/45, Loss: 0.010877924039959908\n",
            "Epoch 188/400, Batch 29/45, Loss: 0.016345301643013954\n",
            "Epoch 188/400, Batch 30/45, Loss: 0.022650286555290222\n",
            "Epoch 188/400, Batch 31/45, Loss: 0.005812079180032015\n",
            "Epoch 188/400, Batch 32/45, Loss: 0.013385108672082424\n",
            "Epoch 188/400, Batch 33/45, Loss: 0.014689269475638866\n",
            "Epoch 188/400, Batch 34/45, Loss: 0.009996894747018814\n",
            "Epoch 188/400, Batch 35/45, Loss: 0.01622782275080681\n",
            "Epoch 188/400, Batch 36/45, Loss: 0.018289832398295403\n",
            "Epoch 188/400, Batch 37/45, Loss: 0.014340967871248722\n",
            "Epoch 188/400, Batch 38/45, Loss: 0.03909582644701004\n",
            "Epoch 188/400, Batch 39/45, Loss: 0.04352530464529991\n",
            "Epoch 188/400, Batch 40/45, Loss: 0.09023719280958176\n",
            "Epoch 188/400, Batch 41/45, Loss: 0.022101519629359245\n",
            "Epoch 188/400, Batch 42/45, Loss: 0.08015251904726028\n",
            "Epoch 188/400, Batch 43/45, Loss: 0.011950387619435787\n",
            "Epoch 188/400, Batch 44/45, Loss: 0.05567814037203789\n",
            "Epoch 188/400, Batch 45/45, Loss: 0.05032423883676529\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.552675500512123 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  189 , Time Elapsed:  149.97027992407482  mins\n",
            "Epoch 189/400, Batch 1/45, Loss: 0.04030020534992218\n",
            "Epoch 189/400, Batch 2/45, Loss: 0.031590260565280914\n",
            "Epoch 189/400, Batch 3/45, Loss: 0.026628874242305756\n",
            "Epoch 189/400, Batch 4/45, Loss: 0.019383970648050308\n",
            "Epoch 189/400, Batch 5/45, Loss: 0.018215248361229897\n",
            "Epoch 189/400, Batch 6/45, Loss: 0.016073837876319885\n",
            "Epoch 189/400, Batch 7/45, Loss: 0.04097892343997955\n",
            "Epoch 189/400, Batch 8/45, Loss: 0.02447466365993023\n",
            "Epoch 189/400, Batch 9/45, Loss: 0.01549210213124752\n",
            "Epoch 189/400, Batch 10/45, Loss: 0.004852287005633116\n",
            "Epoch 189/400, Batch 11/45, Loss: 0.006398595403879881\n",
            "Epoch 189/400, Batch 12/45, Loss: 0.033966824412345886\n",
            "Epoch 189/400, Batch 13/45, Loss: 0.009254438802599907\n",
            "Epoch 189/400, Batch 14/45, Loss: 0.012208906933665276\n",
            "Epoch 189/400, Batch 15/45, Loss: 0.025571227073669434\n",
            "Epoch 189/400, Batch 16/45, Loss: 0.011009595356881618\n",
            "Epoch 189/400, Batch 17/45, Loss: 0.00891097728163004\n",
            "Epoch 189/400, Batch 18/45, Loss: 0.0150886420160532\n",
            "Epoch 189/400, Batch 19/45, Loss: 0.02816804312169552\n",
            "Epoch 189/400, Batch 20/45, Loss: 0.028651416301727295\n",
            "Epoch 189/400, Batch 21/45, Loss: 0.02598726935684681\n",
            "Epoch 189/400, Batch 22/45, Loss: 0.011945425532758236\n",
            "Epoch 189/400, Batch 23/45, Loss: 0.011281686834990978\n",
            "Epoch 189/400, Batch 24/45, Loss: 0.02937271073460579\n",
            "Epoch 189/400, Batch 25/45, Loss: 0.04621139168739319\n",
            "Epoch 189/400, Batch 26/45, Loss: 0.04803704842925072\n",
            "Epoch 189/400, Batch 27/45, Loss: 0.048882223665714264\n",
            "Epoch 189/400, Batch 28/45, Loss: 0.018675539642572403\n",
            "Epoch 189/400, Batch 29/45, Loss: 0.0077537791803479195\n",
            "Epoch 189/400, Batch 30/45, Loss: 0.010682224296033382\n",
            "Epoch 189/400, Batch 31/45, Loss: 0.025394439697265625\n",
            "Epoch 189/400, Batch 32/45, Loss: 0.01960885152220726\n",
            "Epoch 189/400, Batch 33/45, Loss: 0.042413581162691116\n",
            "Epoch 189/400, Batch 34/45, Loss: 0.01597318984568119\n",
            "Epoch 189/400, Batch 35/45, Loss: 0.04610271751880646\n",
            "Epoch 189/400, Batch 36/45, Loss: 0.03356980159878731\n",
            "Epoch 189/400, Batch 37/45, Loss: 0.017045900225639343\n",
            "Epoch 189/400, Batch 38/45, Loss: 0.03301462531089783\n",
            "Epoch 189/400, Batch 39/45, Loss: 0.04614405333995819\n",
            "Epoch 189/400, Batch 40/45, Loss: 0.05728433281183243\n",
            "Epoch 189/400, Batch 41/45, Loss: 0.030215168371796608\n",
            "Epoch 189/400, Batch 42/45, Loss: 0.02191944420337677\n",
            "Epoch 189/400, Batch 43/45, Loss: 0.013388004153966904\n",
            "Epoch 189/400, Batch 44/45, Loss: 0.053653694689273834\n",
            "Epoch 189/400, Batch 45/45, Loss: 0.042932700365781784\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.652920838445425 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  190 , Time Elapsed:  150.7780210296313  mins\n",
            "Epoch 190/400, Batch 1/45, Loss: 0.01838681846857071\n",
            "Epoch 190/400, Batch 2/45, Loss: 0.013464516960084438\n",
            "Epoch 190/400, Batch 3/45, Loss: 0.028975022956728935\n",
            "Epoch 190/400, Batch 4/45, Loss: 0.005095337517559528\n",
            "Epoch 190/400, Batch 5/45, Loss: 0.02850513905286789\n",
            "Epoch 190/400, Batch 6/45, Loss: 0.045809682458639145\n",
            "Epoch 190/400, Batch 7/45, Loss: 0.01159434113651514\n",
            "Epoch 190/400, Batch 8/45, Loss: 0.0233776718378067\n",
            "Epoch 190/400, Batch 9/45, Loss: 0.016180019825696945\n",
            "Epoch 190/400, Batch 10/45, Loss: 0.03356405720114708\n",
            "Epoch 190/400, Batch 11/45, Loss: 0.029497934505343437\n",
            "Epoch 190/400, Batch 12/45, Loss: 0.03184763342142105\n",
            "Epoch 190/400, Batch 13/45, Loss: 0.020201493054628372\n",
            "Epoch 190/400, Batch 14/45, Loss: 0.024884652346372604\n",
            "Epoch 190/400, Batch 15/45, Loss: 0.013145651668310165\n",
            "Epoch 190/400, Batch 16/45, Loss: 0.026862606406211853\n",
            "Epoch 190/400, Batch 17/45, Loss: 0.028698958456516266\n",
            "Epoch 190/400, Batch 18/45, Loss: 0.03793178126215935\n",
            "Epoch 190/400, Batch 19/45, Loss: 0.01572340354323387\n",
            "Epoch 190/400, Batch 20/45, Loss: 0.03959523141384125\n",
            "Epoch 190/400, Batch 21/45, Loss: 0.04423658177256584\n",
            "Epoch 190/400, Batch 22/45, Loss: 0.37556299567222595\n",
            "Epoch 190/400, Batch 23/45, Loss: 0.01131279394030571\n",
            "Epoch 190/400, Batch 24/45, Loss: 0.01692662574350834\n",
            "Epoch 190/400, Batch 25/45, Loss: 0.04550943523645401\n",
            "Epoch 190/400, Batch 26/45, Loss: 0.12459974735975266\n",
            "Epoch 190/400, Batch 27/45, Loss: 0.03614622354507446\n",
            "Epoch 190/400, Batch 28/45, Loss: 0.1491963267326355\n",
            "Epoch 190/400, Batch 29/45, Loss: 0.10221540182828903\n",
            "Epoch 190/400, Batch 30/45, Loss: 0.06645869463682175\n",
            "Epoch 190/400, Batch 31/45, Loss: 0.04612494632601738\n",
            "Epoch 190/400, Batch 32/45, Loss: 0.09312229603528976\n",
            "Epoch 190/400, Batch 33/45, Loss: 0.012925911694765091\n",
            "Epoch 190/400, Batch 34/45, Loss: 0.062445878982543945\n",
            "Epoch 190/400, Batch 35/45, Loss: 0.042782142758369446\n",
            "Epoch 190/400, Batch 36/45, Loss: 0.08042747527360916\n",
            "Epoch 190/400, Batch 37/45, Loss: 0.014701595529913902\n",
            "Epoch 190/400, Batch 38/45, Loss: 0.016525160521268845\n",
            "Epoch 190/400, Batch 39/45, Loss: 0.03240063786506653\n",
            "Epoch 190/400, Batch 40/45, Loss: 0.03156168386340141\n",
            "Epoch 190/400, Batch 41/45, Loss: 0.023739542812108994\n",
            "Epoch 190/400, Batch 42/45, Loss: 0.059381671249866486\n",
            "Epoch 190/400, Batch 43/45, Loss: 0.10137617588043213\n",
            "Epoch 190/400, Batch 44/45, Loss: 0.055644966661930084\n",
            "Epoch 190/400, Batch 45/45, Loss: 0.056653451174497604\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  2.033487021923065 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  191 , Time Elapsed:  151.56788938045503  mins\n",
            "Epoch 191/400, Batch 1/45, Loss: 0.02064937725663185\n",
            "Epoch 191/400, Batch 2/45, Loss: 0.03824331611394882\n",
            "Epoch 191/400, Batch 3/45, Loss: 0.08384324610233307\n",
            "Epoch 191/400, Batch 4/45, Loss: 0.00874275341629982\n",
            "Epoch 191/400, Batch 5/45, Loss: 0.022495465353131294\n",
            "Epoch 191/400, Batch 6/45, Loss: 0.011234188452363014\n",
            "Epoch 191/400, Batch 7/45, Loss: 0.03852745145559311\n",
            "Epoch 191/400, Batch 8/45, Loss: 0.024364108219742775\n",
            "Epoch 191/400, Batch 9/45, Loss: 0.031093379482626915\n",
            "Epoch 191/400, Batch 10/45, Loss: 0.036676906049251556\n",
            "Epoch 191/400, Batch 11/45, Loss: 0.031955309212207794\n",
            "Epoch 191/400, Batch 12/45, Loss: 0.005884298123419285\n",
            "Epoch 191/400, Batch 13/45, Loss: 0.029493069276213646\n",
            "Epoch 191/400, Batch 14/45, Loss: 0.01809466816484928\n",
            "Epoch 191/400, Batch 15/45, Loss: 0.03501976281404495\n",
            "Epoch 191/400, Batch 16/45, Loss: 0.015785615891218185\n",
            "Epoch 191/400, Batch 17/45, Loss: 0.01640559360384941\n",
            "Epoch 191/400, Batch 18/45, Loss: 0.02039307914674282\n",
            "Epoch 191/400, Batch 19/45, Loss: 0.0647725909948349\n",
            "Epoch 191/400, Batch 20/45, Loss: 0.023533102124929428\n",
            "Epoch 191/400, Batch 21/45, Loss: 0.011447956785559654\n",
            "Epoch 191/400, Batch 22/45, Loss: 0.11525101959705353\n",
            "Epoch 191/400, Batch 23/45, Loss: 0.006316530983895063\n",
            "Epoch 191/400, Batch 24/45, Loss: 0.005629948806017637\n",
            "Epoch 191/400, Batch 25/45, Loss: 0.023218784481287003\n",
            "Epoch 191/400, Batch 26/45, Loss: 0.020093999803066254\n",
            "Epoch 191/400, Batch 27/45, Loss: 0.026990527287125587\n",
            "Epoch 191/400, Batch 28/45, Loss: 0.05468250811100006\n",
            "Epoch 191/400, Batch 29/45, Loss: 0.016003400087356567\n",
            "Epoch 191/400, Batch 30/45, Loss: 0.022213943302631378\n",
            "Epoch 191/400, Batch 31/45, Loss: 0.03953208029270172\n",
            "Epoch 191/400, Batch 32/45, Loss: 0.011230943724513054\n",
            "Epoch 191/400, Batch 33/45, Loss: 0.02955310232937336\n",
            "Epoch 191/400, Batch 34/45, Loss: 0.02967597171664238\n",
            "Epoch 191/400, Batch 35/45, Loss: 0.024887198582291603\n",
            "Epoch 191/400, Batch 36/45, Loss: 0.021538881585001945\n",
            "Epoch 191/400, Batch 37/45, Loss: 0.034530945122241974\n",
            "Epoch 191/400, Batch 38/45, Loss: 0.008865518495440483\n",
            "Epoch 191/400, Batch 39/45, Loss: 0.0230081919580698\n",
            "Epoch 191/400, Batch 40/45, Loss: 0.01915431208908558\n",
            "Epoch 191/400, Batch 41/45, Loss: 0.30400440096855164\n",
            "Epoch 191/400, Batch 42/45, Loss: 0.017179550603032112\n",
            "Epoch 191/400, Batch 43/45, Loss: 0.01624608039855957\n",
            "Epoch 191/400, Batch 44/45, Loss: 0.062317438423633575\n",
            "Epoch 191/400, Batch 45/45, Loss: 0.012180138379335403\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.724102284759283 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  192 , Time Elapsed:  152.3845963915189  mins\n",
            "Epoch 192/400, Batch 1/45, Loss: 0.02343173511326313\n",
            "Epoch 192/400, Batch 2/45, Loss: 0.03669076785445213\n",
            "Epoch 192/400, Batch 3/45, Loss: 0.024987753480672836\n",
            "Epoch 192/400, Batch 4/45, Loss: 0.06075368449091911\n",
            "Epoch 192/400, Batch 5/45, Loss: 0.040150776505470276\n",
            "Epoch 192/400, Batch 6/45, Loss: 0.03174983710050583\n",
            "Epoch 192/400, Batch 7/45, Loss: 0.03455666825175285\n",
            "Epoch 192/400, Batch 8/45, Loss: 0.025095708668231964\n",
            "Epoch 192/400, Batch 9/45, Loss: 0.02086770348250866\n",
            "Epoch 192/400, Batch 10/45, Loss: 0.01472548022866249\n",
            "Epoch 192/400, Batch 11/45, Loss: 0.035949643701314926\n",
            "Epoch 192/400, Batch 12/45, Loss: 0.09242743253707886\n",
            "Epoch 192/400, Batch 13/45, Loss: 0.029757849872112274\n",
            "Epoch 192/400, Batch 14/45, Loss: 0.013110609725117683\n",
            "Epoch 192/400, Batch 15/45, Loss: 0.014983097091317177\n",
            "Epoch 192/400, Batch 16/45, Loss: 0.011867141351103783\n",
            "Epoch 192/400, Batch 17/45, Loss: 0.05554437264800072\n",
            "Epoch 192/400, Batch 18/45, Loss: 0.03236965462565422\n",
            "Epoch 192/400, Batch 19/45, Loss: 0.07265329360961914\n",
            "Epoch 192/400, Batch 20/45, Loss: 0.007517113350331783\n",
            "Epoch 192/400, Batch 21/45, Loss: 0.024137092754244804\n",
            "Epoch 192/400, Batch 22/45, Loss: 0.04002957046031952\n",
            "Epoch 192/400, Batch 23/45, Loss: 0.03298758715391159\n",
            "Epoch 192/400, Batch 24/45, Loss: 0.01434764452278614\n",
            "Epoch 192/400, Batch 25/45, Loss: 0.03559686988592148\n",
            "Epoch 192/400, Batch 26/45, Loss: 0.017774134874343872\n",
            "Epoch 192/400, Batch 27/45, Loss: 0.010977741330862045\n",
            "Epoch 192/400, Batch 28/45, Loss: 0.07401150465011597\n",
            "Epoch 192/400, Batch 29/45, Loss: 0.02298234961926937\n",
            "Epoch 192/400, Batch 30/45, Loss: 0.20537225902080536\n",
            "Epoch 192/400, Batch 31/45, Loss: 0.08775244653224945\n",
            "Epoch 192/400, Batch 32/45, Loss: 0.016114838421344757\n",
            "Epoch 192/400, Batch 33/45, Loss: 0.09287872165441513\n",
            "Epoch 192/400, Batch 34/45, Loss: 0.03273341804742813\n",
            "Epoch 192/400, Batch 35/45, Loss: 0.013466579839587212\n",
            "Epoch 192/400, Batch 36/45, Loss: 0.014807458966970444\n",
            "Epoch 192/400, Batch 37/45, Loss: 0.06352414190769196\n",
            "Epoch 192/400, Batch 38/45, Loss: 0.028033779934048653\n",
            "Epoch 192/400, Batch 39/45, Loss: 0.017191264778375626\n",
            "Epoch 192/400, Batch 40/45, Loss: 0.029234735295176506\n",
            "Epoch 192/400, Batch 41/45, Loss: 0.006369525566697121\n",
            "Epoch 192/400, Batch 42/45, Loss: 0.015622606500983238\n",
            "Epoch 192/400, Batch 43/45, Loss: 0.01258055865764618\n",
            "Epoch 192/400, Batch 44/45, Loss: 0.024155747145414352\n",
            "Epoch 192/400, Batch 45/45, Loss: 0.029866810888051987\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.4354177974164486 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  193 , Time Elapsed:  153.17086174090704  mins\n",
            "Epoch 193/400, Batch 1/45, Loss: 0.022515099495649338\n",
            "Epoch 193/400, Batch 2/45, Loss: 0.007493887096643448\n",
            "Epoch 193/400, Batch 3/45, Loss: 0.007770229130983353\n",
            "Epoch 193/400, Batch 4/45, Loss: 0.03201303258538246\n",
            "Epoch 193/400, Batch 5/45, Loss: 0.04340597987174988\n",
            "Epoch 193/400, Batch 6/45, Loss: 0.019559644162654877\n",
            "Epoch 193/400, Batch 7/45, Loss: 0.05151166021823883\n",
            "Epoch 193/400, Batch 8/45, Loss: 0.056677043437957764\n",
            "Epoch 193/400, Batch 9/45, Loss: 0.02476208284497261\n",
            "Epoch 193/400, Batch 10/45, Loss: 0.009487640112638474\n",
            "Epoch 193/400, Batch 11/45, Loss: 0.04423283413052559\n",
            "Epoch 193/400, Batch 12/45, Loss: 0.007830426096916199\n",
            "Epoch 193/400, Batch 13/45, Loss: 0.008982094004750252\n",
            "Epoch 193/400, Batch 14/45, Loss: 0.056029267609119415\n",
            "Epoch 193/400, Batch 15/45, Loss: 0.029414983466267586\n",
            "Epoch 193/400, Batch 16/45, Loss: 0.06314748525619507\n",
            "Epoch 193/400, Batch 17/45, Loss: 0.049013279378414154\n",
            "Epoch 193/400, Batch 18/45, Loss: 0.04107264429330826\n",
            "Epoch 193/400, Batch 19/45, Loss: 0.02623932808637619\n",
            "Epoch 193/400, Batch 20/45, Loss: 0.17512056231498718\n",
            "Epoch 193/400, Batch 21/45, Loss: 0.026836678385734558\n",
            "Epoch 193/400, Batch 22/45, Loss: 0.015406478196382523\n",
            "Epoch 193/400, Batch 23/45, Loss: 0.014452791772782803\n",
            "Epoch 193/400, Batch 24/45, Loss: 0.042724885046482086\n",
            "Epoch 193/400, Batch 25/45, Loss: 0.02775399386882782\n",
            "Epoch 193/400, Batch 26/45, Loss: 0.018327632918953896\n",
            "Epoch 193/400, Batch 27/45, Loss: 0.03267030045390129\n",
            "Epoch 193/400, Batch 28/45, Loss: 0.051704976707696915\n",
            "Epoch 193/400, Batch 29/45, Loss: 0.09007593989372253\n",
            "Epoch 193/400, Batch 30/45, Loss: 0.0376182422041893\n",
            "Epoch 193/400, Batch 31/45, Loss: 0.21028070151805878\n",
            "Epoch 193/400, Batch 32/45, Loss: 0.01894703134894371\n",
            "Epoch 193/400, Batch 33/45, Loss: 0.0047528063878417015\n",
            "Epoch 193/400, Batch 34/45, Loss: 0.021316101774573326\n",
            "Epoch 193/400, Batch 35/45, Loss: 0.04151684418320656\n",
            "Epoch 193/400, Batch 36/45, Loss: 0.015382676385343075\n",
            "Epoch 193/400, Batch 37/45, Loss: 0.06260077655315399\n",
            "Epoch 193/400, Batch 38/45, Loss: 0.028673015534877777\n",
            "Epoch 193/400, Batch 39/45, Loss: 0.03418286144733429\n",
            "Epoch 193/400, Batch 40/45, Loss: 0.014450367540121078\n",
            "Epoch 193/400, Batch 41/45, Loss: 0.009357831440865993\n",
            "Epoch 193/400, Batch 42/45, Loss: 0.06959941238164902\n",
            "Epoch 193/400, Batch 43/45, Loss: 0.03451702371239662\n",
            "Epoch 193/400, Batch 44/45, Loss: 0.04082273691892624\n",
            "Epoch 193/400, Batch 45/45, Loss: 0.03547239676117897\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.466111734509468 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  194 , Time Elapsed:  153.98811192909878  mins\n",
            "Epoch 194/400, Batch 1/45, Loss: 0.1133279949426651\n",
            "Epoch 194/400, Batch 2/45, Loss: 0.022094568237662315\n",
            "Epoch 194/400, Batch 3/45, Loss: 0.039410416036844254\n",
            "Epoch 194/400, Batch 4/45, Loss: 0.016518721356987953\n",
            "Epoch 194/400, Batch 5/45, Loss: 0.026406515389680862\n",
            "Epoch 194/400, Batch 6/45, Loss: 0.030806785449385643\n",
            "Epoch 194/400, Batch 7/45, Loss: 0.025268178433179855\n",
            "Epoch 194/400, Batch 8/45, Loss: 0.16619549691677094\n",
            "Epoch 194/400, Batch 9/45, Loss: 0.02264697477221489\n",
            "Epoch 194/400, Batch 10/45, Loss: 0.01007293350994587\n",
            "Epoch 194/400, Batch 11/45, Loss: 0.04580678418278694\n",
            "Epoch 194/400, Batch 12/45, Loss: 0.038839973509311676\n",
            "Epoch 194/400, Batch 13/45, Loss: 0.016270514577627182\n",
            "Epoch 194/400, Batch 14/45, Loss: 0.07856222987174988\n",
            "Epoch 194/400, Batch 15/45, Loss: 0.031227927654981613\n",
            "Epoch 194/400, Batch 16/45, Loss: 0.005734003148972988\n",
            "Epoch 194/400, Batch 17/45, Loss: 0.028750833123922348\n",
            "Epoch 194/400, Batch 18/45, Loss: 0.008868017233908176\n",
            "Epoch 194/400, Batch 19/45, Loss: 0.04514281451702118\n",
            "Epoch 194/400, Batch 20/45, Loss: 0.015800509601831436\n",
            "Epoch 194/400, Batch 21/45, Loss: 0.035370443016290665\n",
            "Epoch 194/400, Batch 22/45, Loss: 0.04741424322128296\n",
            "Epoch 194/400, Batch 23/45, Loss: 0.010770059190690517\n",
            "Epoch 194/400, Batch 24/45, Loss: 0.011445602402091026\n",
            "Epoch 194/400, Batch 25/45, Loss: 0.035567667335271835\n",
            "Epoch 194/400, Batch 26/45, Loss: 0.026188457384705544\n",
            "Epoch 194/400, Batch 27/45, Loss: 0.02331847883760929\n",
            "Epoch 194/400, Batch 28/45, Loss: 0.06166183203458786\n",
            "Epoch 194/400, Batch 29/45, Loss: 0.03558281809091568\n",
            "Epoch 194/400, Batch 30/45, Loss: 0.03066449612379074\n",
            "Epoch 194/400, Batch 31/45, Loss: 0.009305905550718307\n",
            "Epoch 194/400, Batch 32/45, Loss: 0.008566056378185749\n",
            "Epoch 194/400, Batch 33/45, Loss: 0.015299351885914803\n",
            "Epoch 194/400, Batch 34/45, Loss: 0.009248285554349422\n",
            "Epoch 194/400, Batch 35/45, Loss: 0.05342009291052818\n",
            "Epoch 194/400, Batch 36/45, Loss: 0.007008476182818413\n",
            "Epoch 194/400, Batch 37/45, Loss: 0.010427210479974747\n",
            "Epoch 194/400, Batch 38/45, Loss: 0.009733280166983604\n",
            "Epoch 194/400, Batch 39/45, Loss: 0.031612545251846313\n",
            "Epoch 194/400, Batch 40/45, Loss: 0.01378258690237999\n",
            "Epoch 194/400, Batch 41/45, Loss: 0.011908100917935371\n",
            "Epoch 194/400, Batch 42/45, Loss: 0.05921947956085205\n",
            "Epoch 194/400, Batch 43/45, Loss: 0.003185098059475422\n",
            "Epoch 194/400, Batch 44/45, Loss: 0.016231322661042213\n",
            "Epoch 194/400, Batch 45/45, Loss: 0.020164664834737778\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.5576945394277573 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  195 , Time Elapsed:  154.77457335392634  mins\n",
            "Epoch 195/400, Batch 1/45, Loss: 0.015036964789032936\n",
            "Epoch 195/400, Batch 2/45, Loss: 0.019533632323145866\n",
            "Epoch 195/400, Batch 3/45, Loss: 0.07263565063476562\n",
            "Epoch 195/400, Batch 4/45, Loss: 0.015455454587936401\n",
            "Epoch 195/400, Batch 5/45, Loss: 0.02255532331764698\n",
            "Epoch 195/400, Batch 6/45, Loss: 0.014613857492804527\n",
            "Epoch 195/400, Batch 7/45, Loss: 0.040597572922706604\n",
            "Epoch 195/400, Batch 8/45, Loss: 0.010130254551768303\n",
            "Epoch 195/400, Batch 9/45, Loss: 0.028209514915943146\n",
            "Epoch 195/400, Batch 10/45, Loss: 0.004724062047898769\n",
            "Epoch 195/400, Batch 11/45, Loss: 0.02757018804550171\n",
            "Epoch 195/400, Batch 12/45, Loss: 0.012487825937569141\n",
            "Epoch 195/400, Batch 13/45, Loss: 0.009731125086545944\n",
            "Epoch 195/400, Batch 14/45, Loss: 0.019266992807388306\n",
            "Epoch 195/400, Batch 15/45, Loss: 0.03256522864103317\n",
            "Epoch 195/400, Batch 16/45, Loss: 0.007171868346631527\n",
            "Epoch 195/400, Batch 17/45, Loss: 0.008664550259709358\n",
            "Epoch 195/400, Batch 18/45, Loss: 0.04646700248122215\n",
            "Epoch 195/400, Batch 19/45, Loss: 0.01898590847849846\n",
            "Epoch 195/400, Batch 20/45, Loss: 0.037200648337602615\n",
            "Epoch 195/400, Batch 21/45, Loss: 0.017186366021633148\n",
            "Epoch 195/400, Batch 22/45, Loss: 0.012827535159885883\n",
            "Epoch 195/400, Batch 23/45, Loss: 0.025673959404230118\n",
            "Epoch 195/400, Batch 24/45, Loss: 0.012095590122044086\n",
            "Epoch 195/400, Batch 25/45, Loss: 0.021530497819185257\n",
            "Epoch 195/400, Batch 26/45, Loss: 0.01055094599723816\n",
            "Epoch 195/400, Batch 27/45, Loss: 0.012066821567714214\n",
            "Epoch 195/400, Batch 28/45, Loss: 0.01612273044884205\n",
            "Epoch 195/400, Batch 29/45, Loss: 0.012293687090277672\n",
            "Epoch 195/400, Batch 30/45, Loss: 0.03751976042985916\n",
            "Epoch 195/400, Batch 31/45, Loss: 0.016613516956567764\n",
            "Epoch 195/400, Batch 32/45, Loss: 0.020100681111216545\n",
            "Epoch 195/400, Batch 33/45, Loss: 0.01394563727080822\n",
            "Epoch 195/400, Batch 34/45, Loss: 0.0106454873457551\n",
            "Epoch 195/400, Batch 35/45, Loss: 0.05420291796326637\n",
            "Epoch 195/400, Batch 36/45, Loss: 0.0028417096473276615\n",
            "Epoch 195/400, Batch 37/45, Loss: 0.030742105096578598\n",
            "Epoch 195/400, Batch 38/45, Loss: 0.03970026224851608\n",
            "Epoch 195/400, Batch 39/45, Loss: 0.008179002441465855\n",
            "Epoch 195/400, Batch 40/45, Loss: 0.011411110870540142\n",
            "Epoch 195/400, Batch 41/45, Loss: 0.0060555231757462025\n",
            "Epoch 195/400, Batch 42/45, Loss: 0.014095809310674667\n",
            "Epoch 195/400, Batch 43/45, Loss: 0.014934953302145004\n",
            "Epoch 195/400, Batch 44/45, Loss: 0.019018325954675674\n",
            "Epoch 195/400, Batch 45/45, Loss: 0.007396696135401726\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.2793106697499752 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  196 , Time Elapsed:  155.56262067953745  mins\n",
            "Epoch 196/400, Batch 1/45, Loss: 0.005343254655599594\n",
            "Epoch 196/400, Batch 2/45, Loss: 0.010317911393940449\n",
            "Epoch 196/400, Batch 3/45, Loss: 0.012484021484851837\n",
            "Epoch 196/400, Batch 4/45, Loss: 0.014487684704363346\n",
            "Epoch 196/400, Batch 5/45, Loss: 0.01068960689008236\n",
            "Epoch 196/400, Batch 6/45, Loss: 0.02893022447824478\n",
            "Epoch 196/400, Batch 7/45, Loss: 0.01863507181406021\n",
            "Epoch 196/400, Batch 8/45, Loss: 0.016246920451521873\n",
            "Epoch 196/400, Batch 9/45, Loss: 0.003642971394583583\n",
            "Epoch 196/400, Batch 10/45, Loss: 0.018467487767338753\n",
            "Epoch 196/400, Batch 11/45, Loss: 0.01677148975431919\n",
            "Epoch 196/400, Batch 12/45, Loss: 0.022218087688088417\n",
            "Epoch 196/400, Batch 13/45, Loss: 0.014727639965713024\n",
            "Epoch 196/400, Batch 14/45, Loss: 0.02249336987733841\n",
            "Epoch 196/400, Batch 15/45, Loss: 0.01393170841038227\n",
            "Epoch 196/400, Batch 16/45, Loss: 0.017045527696609497\n",
            "Epoch 196/400, Batch 17/45, Loss: 0.02599981427192688\n",
            "Epoch 196/400, Batch 18/45, Loss: 0.03644179925322533\n",
            "Epoch 196/400, Batch 19/45, Loss: 0.009519428014755249\n",
            "Epoch 196/400, Batch 20/45, Loss: 0.02505316585302353\n",
            "Epoch 196/400, Batch 21/45, Loss: 0.03526505455374718\n",
            "Epoch 196/400, Batch 22/45, Loss: 0.011819453909993172\n",
            "Epoch 196/400, Batch 23/45, Loss: 0.06374387443065643\n",
            "Epoch 196/400, Batch 24/45, Loss: 0.014334678649902344\n",
            "Epoch 196/400, Batch 25/45, Loss: 0.015409812331199646\n",
            "Epoch 196/400, Batch 26/45, Loss: 0.008136101067066193\n",
            "Epoch 196/400, Batch 27/45, Loss: 0.019101858139038086\n",
            "Epoch 196/400, Batch 28/45, Loss: 0.02103022299706936\n",
            "Epoch 196/400, Batch 29/45, Loss: 0.07243555784225464\n",
            "Epoch 196/400, Batch 30/45, Loss: 0.046306490898132324\n",
            "Epoch 196/400, Batch 31/45, Loss: 0.025379261001944542\n",
            "Epoch 196/400, Batch 32/45, Loss: 0.03033757582306862\n",
            "Epoch 196/400, Batch 33/45, Loss: 0.021981943398714066\n",
            "Epoch 196/400, Batch 34/45, Loss: 0.05722884088754654\n",
            "Epoch 196/400, Batch 35/45, Loss: 0.029566509649157524\n",
            "Epoch 196/400, Batch 36/45, Loss: 0.018642306327819824\n",
            "Epoch 196/400, Batch 37/45, Loss: 0.01819896511733532\n",
            "Epoch 196/400, Batch 38/45, Loss: 0.009970721788704395\n",
            "Epoch 196/400, Batch 39/45, Loss: 0.029808837920427322\n",
            "Epoch 196/400, Batch 40/45, Loss: 0.09890592843294144\n",
            "Epoch 196/400, Batch 41/45, Loss: 0.018557310104370117\n",
            "Epoch 196/400, Batch 42/45, Loss: 0.009648652747273445\n",
            "Epoch 196/400, Batch 43/45, Loss: 0.005594782996922731\n",
            "Epoch 196/400, Batch 44/45, Loss: 0.00507845776155591\n",
            "Epoch 196/400, Batch 45/45, Loss: 0.022852778434753418\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.327061451971531 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  197 , Time Elapsed:  156.38277221123377  mins\n",
            "Epoch 197/400, Batch 1/45, Loss: 0.012581865303218365\n",
            "Epoch 197/400, Batch 2/45, Loss: 0.018029529601335526\n",
            "Epoch 197/400, Batch 3/45, Loss: 0.02462989278137684\n",
            "Epoch 197/400, Batch 4/45, Loss: 0.019405588507652283\n",
            "Epoch 197/400, Batch 5/45, Loss: 0.02477971464395523\n",
            "Epoch 197/400, Batch 6/45, Loss: 0.07435265183448792\n",
            "Epoch 197/400, Batch 7/45, Loss: 0.017212336882948875\n",
            "Epoch 197/400, Batch 8/45, Loss: 0.041992805898189545\n",
            "Epoch 197/400, Batch 9/45, Loss: 0.021619850769639015\n",
            "Epoch 197/400, Batch 10/45, Loss: 0.02819267101585865\n",
            "Epoch 197/400, Batch 11/45, Loss: 0.03899702429771423\n",
            "Epoch 197/400, Batch 12/45, Loss: 0.012879034504294395\n",
            "Epoch 197/400, Batch 13/45, Loss: 0.010882481932640076\n",
            "Epoch 197/400, Batch 14/45, Loss: 0.008747732266783714\n",
            "Epoch 197/400, Batch 15/45, Loss: 0.02999308332800865\n",
            "Epoch 197/400, Batch 16/45, Loss: 0.014238068833947182\n",
            "Epoch 197/400, Batch 17/45, Loss: 0.026494476944208145\n",
            "Epoch 197/400, Batch 18/45, Loss: 0.0420522466301918\n",
            "Epoch 197/400, Batch 19/45, Loss: 0.04160335659980774\n",
            "Epoch 197/400, Batch 20/45, Loss: 0.019083481281995773\n",
            "Epoch 197/400, Batch 21/45, Loss: 0.02080787532031536\n",
            "Epoch 197/400, Batch 22/45, Loss: 0.016821371391415596\n",
            "Epoch 197/400, Batch 23/45, Loss: 0.007802354171872139\n",
            "Epoch 197/400, Batch 24/45, Loss: 0.01833387091755867\n",
            "Epoch 197/400, Batch 25/45, Loss: 0.0091678686439991\n",
            "Epoch 197/400, Batch 26/45, Loss: 0.02355070225894451\n",
            "Epoch 197/400, Batch 27/45, Loss: 0.01466376893222332\n",
            "Epoch 197/400, Batch 28/45, Loss: 0.01978212408721447\n",
            "Epoch 197/400, Batch 29/45, Loss: 0.006714142858982086\n",
            "Epoch 197/400, Batch 30/45, Loss: 0.14742301404476166\n",
            "Epoch 197/400, Batch 31/45, Loss: 0.019984181970357895\n",
            "Epoch 197/400, Batch 32/45, Loss: 0.03785913065075874\n",
            "Epoch 197/400, Batch 33/45, Loss: 0.024428846314549446\n",
            "Epoch 197/400, Batch 34/45, Loss: 0.03603042662143707\n",
            "Epoch 197/400, Batch 35/45, Loss: 0.01139657199382782\n",
            "Epoch 197/400, Batch 36/45, Loss: 0.054930076003074646\n",
            "Epoch 197/400, Batch 37/45, Loss: 0.021328046917915344\n",
            "Epoch 197/400, Batch 38/45, Loss: 0.027390049770474434\n",
            "Epoch 197/400, Batch 39/45, Loss: 0.03519120812416077\n",
            "Epoch 197/400, Batch 40/45, Loss: 0.018088966608047485\n",
            "Epoch 197/400, Batch 41/45, Loss: 0.01326222624629736\n",
            "Epoch 197/400, Batch 42/45, Loss: 0.016828104853630066\n",
            "Epoch 197/400, Batch 43/45, Loss: 0.06795245409011841\n",
            "Epoch 197/400, Batch 44/45, Loss: 0.05380299687385559\n",
            "Epoch 197/400, Batch 45/45, Loss: 0.04458222538232803\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.2646711058914661 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  198 , Time Elapsed:  157.16661823590596  mins\n",
            "Epoch 198/400, Batch 1/45, Loss: 0.004246749449521303\n",
            "Epoch 198/400, Batch 2/45, Loss: 0.011762956157326698\n",
            "Epoch 198/400, Batch 3/45, Loss: 0.08963142335414886\n",
            "Epoch 198/400, Batch 4/45, Loss: 0.032667845487594604\n",
            "Epoch 198/400, Batch 5/45, Loss: 0.027193864807486534\n",
            "Epoch 198/400, Batch 6/45, Loss: 0.0321219302713871\n",
            "Epoch 198/400, Batch 7/45, Loss: 0.08244533091783524\n",
            "Epoch 198/400, Batch 8/45, Loss: 0.033732086420059204\n",
            "Epoch 198/400, Batch 9/45, Loss: 0.056702181696891785\n",
            "Epoch 198/400, Batch 10/45, Loss: 0.033940188586711884\n",
            "Epoch 198/400, Batch 11/45, Loss: 0.009316754527390003\n",
            "Epoch 198/400, Batch 12/45, Loss: 0.012136642821133137\n",
            "Epoch 198/400, Batch 13/45, Loss: 0.029816314578056335\n",
            "Epoch 198/400, Batch 14/45, Loss: 0.06601381301879883\n",
            "Epoch 198/400, Batch 15/45, Loss: 0.025278646498918533\n",
            "Epoch 198/400, Batch 16/45, Loss: 0.035036638379096985\n",
            "Epoch 198/400, Batch 17/45, Loss: 0.01822296902537346\n",
            "Epoch 198/400, Batch 18/45, Loss: 0.005190775264054537\n",
            "Epoch 198/400, Batch 19/45, Loss: 0.02152581326663494\n",
            "Epoch 198/400, Batch 20/45, Loss: 0.02115027979016304\n",
            "Epoch 198/400, Batch 21/45, Loss: 0.013374709524214268\n",
            "Epoch 198/400, Batch 22/45, Loss: 0.02031046152114868\n",
            "Epoch 198/400, Batch 23/45, Loss: 0.0474114827811718\n",
            "Epoch 198/400, Batch 24/45, Loss: 0.01127404160797596\n",
            "Epoch 198/400, Batch 25/45, Loss: 0.008118555881083012\n",
            "Epoch 198/400, Batch 26/45, Loss: 0.030413534492254257\n",
            "Epoch 198/400, Batch 27/45, Loss: 0.005857617594301701\n",
            "Epoch 198/400, Batch 28/45, Loss: 0.0028296750970184803\n",
            "Epoch 198/400, Batch 29/45, Loss: 0.006937723606824875\n",
            "Epoch 198/400, Batch 30/45, Loss: 0.03895583003759384\n",
            "Epoch 198/400, Batch 31/45, Loss: 0.028942717239260674\n",
            "Epoch 198/400, Batch 32/45, Loss: 0.004738013260066509\n",
            "Epoch 198/400, Batch 33/45, Loss: 0.03695803880691528\n",
            "Epoch 198/400, Batch 34/45, Loss: 0.02842545695602894\n",
            "Epoch 198/400, Batch 35/45, Loss: 0.021200470626354218\n",
            "Epoch 198/400, Batch 36/45, Loss: 0.011479301378130913\n",
            "Epoch 198/400, Batch 37/45, Loss: 0.022637128829956055\n",
            "Epoch 198/400, Batch 38/45, Loss: 0.03619353845715523\n",
            "Epoch 198/400, Batch 39/45, Loss: 0.026642784476280212\n",
            "Epoch 198/400, Batch 40/45, Loss: 0.06338752806186676\n",
            "Epoch 198/400, Batch 41/45, Loss: 0.03551873192191124\n",
            "Epoch 198/400, Batch 42/45, Loss: 0.011436411179602146\n",
            "Epoch 198/400, Batch 43/45, Loss: 0.029774794355034828\n",
            "Epoch 198/400, Batch 44/45, Loss: 0.03207024931907654\n",
            "Epoch 198/400, Batch 45/45, Loss: 0.0785093754529953\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.1922289989888668 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  199 , Time Elapsed:  157.9712558110555  mins\n",
            "Epoch 199/400, Batch 1/45, Loss: 0.009776236489415169\n",
            "Epoch 199/400, Batch 2/45, Loss: 0.0182733666151762\n",
            "Epoch 199/400, Batch 3/45, Loss: 0.08164595812559128\n",
            "Epoch 199/400, Batch 4/45, Loss: 0.02152976021170616\n",
            "Epoch 199/400, Batch 5/45, Loss: 0.01047256588935852\n",
            "Epoch 199/400, Batch 6/45, Loss: 0.057090625166893005\n",
            "Epoch 199/400, Batch 7/45, Loss: 0.03901306539773941\n",
            "Epoch 199/400, Batch 8/45, Loss: 0.012642836198210716\n",
            "Epoch 199/400, Batch 9/45, Loss: 0.048396505415439606\n",
            "Epoch 199/400, Batch 10/45, Loss: 0.009065333753824234\n",
            "Epoch 199/400, Batch 11/45, Loss: 0.03035098873078823\n",
            "Epoch 199/400, Batch 12/45, Loss: 0.008968044072389603\n",
            "Epoch 199/400, Batch 13/45, Loss: 0.003571279812604189\n",
            "Epoch 199/400, Batch 14/45, Loss: 0.016759580001235008\n",
            "Epoch 199/400, Batch 15/45, Loss: 0.01009398978203535\n",
            "Epoch 199/400, Batch 16/45, Loss: 0.017445433884859085\n",
            "Epoch 199/400, Batch 17/45, Loss: 0.07702936232089996\n",
            "Epoch 199/400, Batch 18/45, Loss: 0.019124317914247513\n",
            "Epoch 199/400, Batch 19/45, Loss: 0.046709924936294556\n",
            "Epoch 199/400, Batch 20/45, Loss: 0.046500157564878464\n",
            "Epoch 199/400, Batch 21/45, Loss: 0.009402913972735405\n",
            "Epoch 199/400, Batch 22/45, Loss: 0.033537838608026505\n",
            "Epoch 199/400, Batch 23/45, Loss: 0.05676352232694626\n",
            "Epoch 199/400, Batch 24/45, Loss: 0.013812223449349403\n",
            "Epoch 199/400, Batch 25/45, Loss: 0.012224511243402958\n",
            "Epoch 199/400, Batch 26/45, Loss: 0.017800353467464447\n",
            "Epoch 199/400, Batch 27/45, Loss: 0.011939269490540028\n",
            "Epoch 199/400, Batch 28/45, Loss: 0.01874716766178608\n",
            "Epoch 199/400, Batch 29/45, Loss: 0.010595245286822319\n",
            "Epoch 199/400, Batch 30/45, Loss: 0.018405158072710037\n",
            "Epoch 199/400, Batch 31/45, Loss: 0.01291779987514019\n",
            "Epoch 199/400, Batch 32/45, Loss: 0.024375755339860916\n",
            "Epoch 199/400, Batch 33/45, Loss: 0.021600130945444107\n",
            "Epoch 199/400, Batch 34/45, Loss: 0.01932455599308014\n",
            "Epoch 199/400, Batch 35/45, Loss: 0.04799051582813263\n",
            "Epoch 199/400, Batch 36/45, Loss: 0.03376780077815056\n",
            "Epoch 199/400, Batch 37/45, Loss: 0.011980943381786346\n",
            "Epoch 199/400, Batch 38/45, Loss: 0.008172614499926567\n",
            "Epoch 199/400, Batch 39/45, Loss: 0.018527964130043983\n",
            "Epoch 199/400, Batch 40/45, Loss: 0.012612009420990944\n",
            "Epoch 199/400, Batch 41/45, Loss: 0.049498774111270905\n",
            "Epoch 199/400, Batch 42/45, Loss: 0.03140893578529358\n",
            "Epoch 199/400, Batch 43/45, Loss: 0.006325975991785526\n",
            "Epoch 199/400, Batch 44/45, Loss: 0.02516614831984043\n",
            "Epoch 199/400, Batch 45/45, Loss: 0.01713484525680542\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.3536262139678001 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  200 , Time Elapsed:  158.75495698451996  mins\n",
            "Epoch 200/400, Batch 1/45, Loss: 0.026042133569717407\n",
            "Epoch 200/400, Batch 2/45, Loss: 0.013938723132014275\n",
            "Epoch 200/400, Batch 3/45, Loss: 0.013292038813233376\n",
            "Epoch 200/400, Batch 4/45, Loss: 0.022700462490320206\n",
            "Epoch 200/400, Batch 5/45, Loss: 0.011326073668897152\n",
            "Epoch 200/400, Batch 6/45, Loss: 0.057025834918022156\n",
            "Epoch 200/400, Batch 7/45, Loss: 0.03000166267156601\n",
            "Epoch 200/400, Batch 8/45, Loss: 0.025110406801104546\n",
            "Epoch 200/400, Batch 9/45, Loss: 0.029522869735956192\n",
            "Epoch 200/400, Batch 10/45, Loss: 0.025725848972797394\n",
            "Epoch 200/400, Batch 11/45, Loss: 0.033364422619342804\n",
            "Epoch 200/400, Batch 12/45, Loss: 0.008568797260522842\n",
            "Epoch 200/400, Batch 13/45, Loss: 0.023895151913166046\n",
            "Epoch 200/400, Batch 14/45, Loss: 0.008873638696968555\n",
            "Epoch 200/400, Batch 15/45, Loss: 0.043159257620573044\n",
            "Epoch 200/400, Batch 16/45, Loss: 0.03959030658006668\n",
            "Epoch 200/400, Batch 17/45, Loss: 0.012433527037501335\n",
            "Epoch 200/400, Batch 18/45, Loss: 0.01927357167005539\n",
            "Epoch 200/400, Batch 19/45, Loss: 0.008037085644900799\n",
            "Epoch 200/400, Batch 20/45, Loss: 0.016606558114290237\n",
            "Epoch 200/400, Batch 21/45, Loss: 0.03199271485209465\n",
            "Epoch 200/400, Batch 22/45, Loss: 0.015312351286411285\n",
            "Epoch 200/400, Batch 23/45, Loss: 0.007517016492784023\n",
            "Epoch 200/400, Batch 24/45, Loss: 0.025534195825457573\n",
            "Epoch 200/400, Batch 25/45, Loss: 0.008826330304145813\n",
            "Epoch 200/400, Batch 26/45, Loss: 0.017988577485084534\n",
            "Epoch 200/400, Batch 27/45, Loss: 0.02196187525987625\n",
            "Epoch 200/400, Batch 28/45, Loss: 0.01093076542019844\n",
            "Epoch 200/400, Batch 29/45, Loss: 0.02737480215728283\n",
            "Epoch 200/400, Batch 30/45, Loss: 0.014786339364945889\n",
            "Epoch 200/400, Batch 31/45, Loss: 0.052972517907619476\n",
            "Epoch 200/400, Batch 32/45, Loss: 0.016145706176757812\n",
            "Epoch 200/400, Batch 33/45, Loss: 0.02264818549156189\n",
            "Epoch 200/400, Batch 34/45, Loss: 0.05359630286693573\n",
            "Epoch 200/400, Batch 35/45, Loss: 0.03223996236920357\n",
            "Epoch 200/400, Batch 36/45, Loss: 0.0360051766037941\n",
            "Epoch 200/400, Batch 37/45, Loss: 0.008952082134783268\n",
            "Epoch 200/400, Batch 38/45, Loss: 0.012829474173486233\n",
            "Epoch 200/400, Batch 39/45, Loss: 0.06447293609380722\n",
            "Epoch 200/400, Batch 40/45, Loss: 0.020434025675058365\n",
            "Epoch 200/400, Batch 41/45, Loss: 0.048583485186100006\n",
            "Epoch 200/400, Batch 42/45, Loss: 0.006154812406748533\n",
            "Epoch 200/400, Batch 43/45, Loss: 0.014721480198204517\n",
            "Epoch 200/400, Batch 44/45, Loss: 0.007725678384304047\n",
            "Epoch 200/400, Batch 45/45, Loss: 0.01199888065457344\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.8781075738370419 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  201 , Time Elapsed:  159.5459163546562  mins\n",
            "Epoch 201/400, Batch 1/45, Loss: 0.008566869422793388\n",
            "Epoch 201/400, Batch 2/45, Loss: 0.06628930568695068\n",
            "Epoch 201/400, Batch 3/45, Loss: 0.02384747564792633\n",
            "Epoch 201/400, Batch 4/45, Loss: 0.023134995251893997\n",
            "Epoch 201/400, Batch 5/45, Loss: 0.03336649015545845\n",
            "Epoch 201/400, Batch 6/45, Loss: 0.03709904104471207\n",
            "Epoch 201/400, Batch 7/45, Loss: 0.019547468051314354\n",
            "Epoch 201/400, Batch 8/45, Loss: 0.004305381793528795\n",
            "Epoch 201/400, Batch 9/45, Loss: 0.012647799216210842\n",
            "Epoch 201/400, Batch 10/45, Loss: 0.016279328614473343\n",
            "Epoch 201/400, Batch 11/45, Loss: 0.027095098048448563\n",
            "Epoch 201/400, Batch 12/45, Loss: 0.014426706358790398\n",
            "Epoch 201/400, Batch 13/45, Loss: 0.012965608388185501\n",
            "Epoch 201/400, Batch 14/45, Loss: 0.013729473575949669\n",
            "Epoch 201/400, Batch 15/45, Loss: 0.03136160224676132\n",
            "Epoch 201/400, Batch 16/45, Loss: 0.015077258460223675\n",
            "Epoch 201/400, Batch 17/45, Loss: 0.035711079835891724\n",
            "Epoch 201/400, Batch 18/45, Loss: 0.008616894483566284\n",
            "Epoch 201/400, Batch 19/45, Loss: 0.05232187360525131\n",
            "Epoch 201/400, Batch 20/45, Loss: 0.01618572510778904\n",
            "Epoch 201/400, Batch 21/45, Loss: 0.026991233229637146\n",
            "Epoch 201/400, Batch 22/45, Loss: 0.01894989423453808\n",
            "Epoch 201/400, Batch 23/45, Loss: 0.015080330893397331\n",
            "Epoch 201/400, Batch 24/45, Loss: 0.059552356600761414\n",
            "Epoch 201/400, Batch 25/45, Loss: 0.013744859024882317\n",
            "Epoch 201/400, Batch 26/45, Loss: 0.009305665269494057\n",
            "Epoch 201/400, Batch 27/45, Loss: 0.04056528955698013\n",
            "Epoch 201/400, Batch 28/45, Loss: 0.04275062680244446\n",
            "Epoch 201/400, Batch 29/45, Loss: 0.01686442270874977\n",
            "Epoch 201/400, Batch 30/45, Loss: 0.03296806290745735\n",
            "Epoch 201/400, Batch 31/45, Loss: 0.005861552432179451\n",
            "Epoch 201/400, Batch 32/45, Loss: 0.011350935325026512\n",
            "Epoch 201/400, Batch 33/45, Loss: 0.013716969639062881\n",
            "Epoch 201/400, Batch 34/45, Loss: 0.02503267675638199\n",
            "Epoch 201/400, Batch 35/45, Loss: 0.03881976008415222\n",
            "Epoch 201/400, Batch 36/45, Loss: 0.02147359773516655\n",
            "Epoch 201/400, Batch 37/45, Loss: 0.04868752136826515\n",
            "Epoch 201/400, Batch 38/45, Loss: 0.009940487332642078\n",
            "Epoch 201/400, Batch 39/45, Loss: 0.006288700271397829\n",
            "Epoch 201/400, Batch 40/45, Loss: 0.017529252916574478\n",
            "Epoch 201/400, Batch 41/45, Loss: 0.022339632734656334\n",
            "Epoch 201/400, Batch 42/45, Loss: 0.0095302639529109\n",
            "Epoch 201/400, Batch 43/45, Loss: 0.019573017954826355\n",
            "Epoch 201/400, Batch 44/45, Loss: 0.035366542637348175\n",
            "Epoch 201/400, Batch 45/45, Loss: 0.03563905507326126\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.2530754655599594 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  202 , Time Elapsed:  160.35698427756628  mins\n",
            "Epoch 202/400, Batch 1/45, Loss: 0.0086783766746521\n",
            "Epoch 202/400, Batch 2/45, Loss: 0.0087079256772995\n",
            "Epoch 202/400, Batch 3/45, Loss: 0.011341884732246399\n",
            "Epoch 202/400, Batch 4/45, Loss: 0.019216567277908325\n",
            "Epoch 202/400, Batch 5/45, Loss: 0.04564797878265381\n",
            "Epoch 202/400, Batch 6/45, Loss: 0.026484835892915726\n",
            "Epoch 202/400, Batch 7/45, Loss: 0.032234493643045425\n",
            "Epoch 202/400, Batch 8/45, Loss: 0.014945671893656254\n",
            "Epoch 202/400, Batch 9/45, Loss: 0.009986317716538906\n",
            "Epoch 202/400, Batch 10/45, Loss: 0.036227207630872726\n",
            "Epoch 202/400, Batch 11/45, Loss: 0.0342327356338501\n",
            "Epoch 202/400, Batch 12/45, Loss: 0.04113495349884033\n",
            "Epoch 202/400, Batch 13/45, Loss: 0.02301674522459507\n",
            "Epoch 202/400, Batch 14/45, Loss: 0.009763561189174652\n",
            "Epoch 202/400, Batch 15/45, Loss: 0.0465792752802372\n",
            "Epoch 202/400, Batch 16/45, Loss: 0.02497176080942154\n",
            "Epoch 202/400, Batch 17/45, Loss: 0.005580786149948835\n",
            "Epoch 202/400, Batch 18/45, Loss: 0.038636572659015656\n",
            "Epoch 202/400, Batch 19/45, Loss: 0.015198839828372002\n",
            "Epoch 202/400, Batch 20/45, Loss: 0.0100784320384264\n",
            "Epoch 202/400, Batch 21/45, Loss: 0.06443067640066147\n",
            "Epoch 202/400, Batch 22/45, Loss: 0.023908890783786774\n",
            "Epoch 202/400, Batch 23/45, Loss: 0.007585028652101755\n",
            "Epoch 202/400, Batch 24/45, Loss: 0.021726131439208984\n",
            "Epoch 202/400, Batch 25/45, Loss: 0.01618276722729206\n",
            "Epoch 202/400, Batch 26/45, Loss: 0.013254117220640182\n",
            "Epoch 202/400, Batch 27/45, Loss: 0.01628417894244194\n",
            "Epoch 202/400, Batch 28/45, Loss: 0.006921442225575447\n",
            "Epoch 202/400, Batch 29/45, Loss: 0.010964710265398026\n",
            "Epoch 202/400, Batch 30/45, Loss: 0.0244990736246109\n",
            "Epoch 202/400, Batch 31/45, Loss: 0.015130128711462021\n",
            "Epoch 202/400, Batch 32/45, Loss: 0.005566546693444252\n",
            "Epoch 202/400, Batch 33/45, Loss: 0.010598829947412014\n",
            "Epoch 202/400, Batch 34/45, Loss: 0.03471854329109192\n",
            "Epoch 202/400, Batch 35/45, Loss: 0.01172645390033722\n",
            "Epoch 202/400, Batch 36/45, Loss: 0.014520103111863136\n",
            "Epoch 202/400, Batch 37/45, Loss: 0.004858468659222126\n",
            "Epoch 202/400, Batch 38/45, Loss: 0.02215237356722355\n",
            "Epoch 202/400, Batch 39/45, Loss: 0.0036531672812998295\n",
            "Epoch 202/400, Batch 40/45, Loss: 0.012238290160894394\n",
            "Epoch 202/400, Batch 41/45, Loss: 0.02600649744272232\n",
            "Epoch 202/400, Batch 42/45, Loss: 0.026674827560782433\n",
            "Epoch 202/400, Batch 43/45, Loss: 0.009842222556471825\n",
            "Epoch 202/400, Batch 44/45, Loss: 0.01257054042071104\n",
            "Epoch 202/400, Batch 45/45, Loss: 0.05623144656419754\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.3480559885501862 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  203 , Time Elapsed:  161.13693609237671  mins\n",
            "Epoch 203/400, Batch 1/45, Loss: 0.019627053290605545\n",
            "Epoch 203/400, Batch 2/45, Loss: 0.026987778022885323\n",
            "Epoch 203/400, Batch 3/45, Loss: 0.015519503504037857\n",
            "Epoch 203/400, Batch 4/45, Loss: 0.011260200291872025\n",
            "Epoch 203/400, Batch 5/45, Loss: 0.00522992480546236\n",
            "Epoch 203/400, Batch 6/45, Loss: 0.02495710179209709\n",
            "Epoch 203/400, Batch 7/45, Loss: 0.008831795305013657\n",
            "Epoch 203/400, Batch 8/45, Loss: 0.029265757650136948\n",
            "Epoch 203/400, Batch 9/45, Loss: 0.012814449146389961\n",
            "Epoch 203/400, Batch 10/45, Loss: 0.007509206421673298\n",
            "Epoch 203/400, Batch 11/45, Loss: 0.014317408204078674\n",
            "Epoch 203/400, Batch 12/45, Loss: 0.014599634334445\n",
            "Epoch 203/400, Batch 13/45, Loss: 0.015941565856337547\n",
            "Epoch 203/400, Batch 14/45, Loss: 0.04241218790411949\n",
            "Epoch 203/400, Batch 15/45, Loss: 0.029597971588373184\n",
            "Epoch 203/400, Batch 16/45, Loss: 0.00521424226462841\n",
            "Epoch 203/400, Batch 17/45, Loss: 0.007389439735561609\n",
            "Epoch 203/400, Batch 18/45, Loss: 0.010260451585054398\n",
            "Epoch 203/400, Batch 19/45, Loss: 0.01942552626132965\n",
            "Epoch 203/400, Batch 20/45, Loss: 0.0249156653881073\n",
            "Epoch 203/400, Batch 21/45, Loss: 0.03798742964863777\n",
            "Epoch 203/400, Batch 22/45, Loss: 0.01356025505810976\n",
            "Epoch 203/400, Batch 23/45, Loss: 0.012792432680726051\n",
            "Epoch 203/400, Batch 24/45, Loss: 0.023736918345093727\n",
            "Epoch 203/400, Batch 25/45, Loss: 0.09152138233184814\n",
            "Epoch 203/400, Batch 26/45, Loss: 0.028191961348056793\n",
            "Epoch 203/400, Batch 27/45, Loss: 0.042085517197847366\n",
            "Epoch 203/400, Batch 28/45, Loss: 0.020133022218942642\n",
            "Epoch 203/400, Batch 29/45, Loss: 0.04255415499210358\n",
            "Epoch 203/400, Batch 30/45, Loss: 0.024536775425076485\n",
            "Epoch 203/400, Batch 31/45, Loss: 0.02139139175415039\n",
            "Epoch 203/400, Batch 32/45, Loss: 0.010128541849553585\n",
            "Epoch 203/400, Batch 33/45, Loss: 0.015728961676359177\n",
            "Epoch 203/400, Batch 34/45, Loss: 0.02383275330066681\n",
            "Epoch 203/400, Batch 35/45, Loss: 0.01484335120767355\n",
            "Epoch 203/400, Batch 36/45, Loss: 0.01737333834171295\n",
            "Epoch 203/400, Batch 37/45, Loss: 0.011046348139643669\n",
            "Epoch 203/400, Batch 38/45, Loss: 0.09606272727251053\n",
            "Epoch 203/400, Batch 39/45, Loss: 0.022498348727822304\n",
            "Epoch 203/400, Batch 40/45, Loss: 0.010968632996082306\n",
            "Epoch 203/400, Batch 41/45, Loss: 0.0075513869524002075\n",
            "Epoch 203/400, Batch 42/45, Loss: 0.005849613808095455\n",
            "Epoch 203/400, Batch 43/45, Loss: 0.01592966727912426\n",
            "Epoch 203/400, Batch 44/45, Loss: 0.01809389516711235\n",
            "Epoch 203/400, Batch 45/45, Loss: 0.03296181932091713\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.2375027984380722 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  204 , Time Elapsed:  161.95734261671703  mins\n",
            "Epoch 204/400, Batch 1/45, Loss: 0.016586633399128914\n",
            "Epoch 204/400, Batch 2/45, Loss: 0.010703070089221\n",
            "Epoch 204/400, Batch 3/45, Loss: 0.004980012774467468\n",
            "Epoch 204/400, Batch 4/45, Loss: 0.02069598250091076\n",
            "Epoch 204/400, Batch 5/45, Loss: 0.032202623784542084\n",
            "Epoch 204/400, Batch 6/45, Loss: 0.04345080628991127\n",
            "Epoch 204/400, Batch 7/45, Loss: 0.030059389770030975\n",
            "Epoch 204/400, Batch 8/45, Loss: 0.004630258306860924\n",
            "Epoch 204/400, Batch 9/45, Loss: 0.013246657326817513\n",
            "Epoch 204/400, Batch 10/45, Loss: 0.021055499091744423\n",
            "Epoch 204/400, Batch 11/45, Loss: 0.024034570902585983\n",
            "Epoch 204/400, Batch 12/45, Loss: 0.03910387307405472\n",
            "Epoch 204/400, Batch 13/45, Loss: 0.032536447048187256\n",
            "Epoch 204/400, Batch 14/45, Loss: 0.030417412519454956\n",
            "Epoch 204/400, Batch 15/45, Loss: 0.046944886445999146\n",
            "Epoch 204/400, Batch 16/45, Loss: 0.05454845726490021\n",
            "Epoch 204/400, Batch 17/45, Loss: 0.04429665952920914\n",
            "Epoch 204/400, Batch 18/45, Loss: 0.045051392167806625\n",
            "Epoch 204/400, Batch 19/45, Loss: 0.02527008205652237\n",
            "Epoch 204/400, Batch 20/45, Loss: 0.056207235902547836\n",
            "Epoch 204/400, Batch 21/45, Loss: 0.010457459837198257\n",
            "Epoch 204/400, Batch 22/45, Loss: 0.011527546681463718\n",
            "Epoch 204/400, Batch 23/45, Loss: 0.015241618268191814\n",
            "Epoch 204/400, Batch 24/45, Loss: 0.007337119430303574\n",
            "Epoch 204/400, Batch 25/45, Loss: 0.011498186737298965\n",
            "Epoch 204/400, Batch 26/45, Loss: 0.08423668146133423\n",
            "Epoch 204/400, Batch 27/45, Loss: 0.08337565511465073\n",
            "Epoch 204/400, Batch 28/45, Loss: 0.0068457722663879395\n",
            "Epoch 204/400, Batch 29/45, Loss: 0.026302093639969826\n",
            "Epoch 204/400, Batch 30/45, Loss: 0.012869995087385178\n",
            "Epoch 204/400, Batch 31/45, Loss: 0.041381701827049255\n",
            "Epoch 204/400, Batch 32/45, Loss: 0.05259639024734497\n",
            "Epoch 204/400, Batch 33/45, Loss: 0.014491354115307331\n",
            "Epoch 204/400, Batch 34/45, Loss: 0.00487543735653162\n",
            "Epoch 204/400, Batch 35/45, Loss: 0.03687608614563942\n",
            "Epoch 204/400, Batch 36/45, Loss: 0.00984133966267109\n",
            "Epoch 204/400, Batch 37/45, Loss: 0.016253985464572906\n",
            "Epoch 204/400, Batch 38/45, Loss: 0.02036439999938011\n",
            "Epoch 204/400, Batch 39/45, Loss: 0.005038519389927387\n",
            "Epoch 204/400, Batch 40/45, Loss: 0.03230281174182892\n",
            "Epoch 204/400, Batch 41/45, Loss: 0.004299733322113752\n",
            "Epoch 204/400, Batch 42/45, Loss: 0.04213994741439819\n",
            "Epoch 204/400, Batch 43/45, Loss: 0.01012401282787323\n",
            "Epoch 204/400, Batch 44/45, Loss: 0.006711904890835285\n",
            "Epoch 204/400, Batch 45/45, Loss: 0.022516541182994843\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.4699129164218903 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  205 , Time Elapsed:  162.74691844383875  mins\n",
            "Epoch 205/400, Batch 1/45, Loss: 0.04954192414879799\n",
            "Epoch 205/400, Batch 2/45, Loss: 0.008461438119411469\n",
            "Epoch 205/400, Batch 3/45, Loss: 0.02067812904715538\n",
            "Epoch 205/400, Batch 4/45, Loss: 0.005142987705767155\n",
            "Epoch 205/400, Batch 5/45, Loss: 0.00974505115300417\n",
            "Epoch 205/400, Batch 6/45, Loss: 0.01306108757853508\n",
            "Epoch 205/400, Batch 7/45, Loss: 0.019669733941555023\n",
            "Epoch 205/400, Batch 8/45, Loss: 0.018426019698381424\n",
            "Epoch 205/400, Batch 9/45, Loss: 0.01052190363407135\n",
            "Epoch 205/400, Batch 10/45, Loss: 0.017041321843862534\n",
            "Epoch 205/400, Batch 11/45, Loss: 0.0050835805013775826\n",
            "Epoch 205/400, Batch 12/45, Loss: 0.01853831671178341\n",
            "Epoch 205/400, Batch 13/45, Loss: 0.01878104731440544\n",
            "Epoch 205/400, Batch 14/45, Loss: 0.01531287096440792\n",
            "Epoch 205/400, Batch 15/45, Loss: 0.005401796195656061\n",
            "Epoch 205/400, Batch 16/45, Loss: 0.02321009524166584\n",
            "Epoch 205/400, Batch 17/45, Loss: 0.0034697377122938633\n",
            "Epoch 205/400, Batch 18/45, Loss: 0.006452053785324097\n",
            "Epoch 205/400, Batch 19/45, Loss: 0.004025098402053118\n",
            "Epoch 205/400, Batch 20/45, Loss: 0.005951786879450083\n",
            "Epoch 205/400, Batch 21/45, Loss: 0.0373622365295887\n",
            "Epoch 205/400, Batch 22/45, Loss: 0.007240195292979479\n",
            "Epoch 205/400, Batch 23/45, Loss: 0.009928420186042786\n",
            "Epoch 205/400, Batch 24/45, Loss: 0.010466507636010647\n",
            "Epoch 205/400, Batch 25/45, Loss: 0.014941729605197906\n",
            "Epoch 205/400, Batch 26/45, Loss: 0.012557435780763626\n",
            "Epoch 205/400, Batch 27/45, Loss: 0.011411050334572792\n",
            "Epoch 205/400, Batch 28/45, Loss: 0.008501151576638222\n",
            "Epoch 205/400, Batch 29/45, Loss: 0.053870782256126404\n",
            "Epoch 205/400, Batch 30/45, Loss: 0.02483571320772171\n",
            "Epoch 205/400, Batch 31/45, Loss: 0.0129661550745368\n",
            "Epoch 205/400, Batch 32/45, Loss: 0.008272812701761723\n",
            "Epoch 205/400, Batch 33/45, Loss: 0.020679283887147903\n",
            "Epoch 205/400, Batch 34/45, Loss: 0.02029605396091938\n",
            "Epoch 205/400, Batch 35/45, Loss: 0.04262585937976837\n",
            "Epoch 205/400, Batch 36/45, Loss: 0.03360246121883392\n",
            "Epoch 205/400, Batch 37/45, Loss: 0.011122310534119606\n",
            "Epoch 205/400, Batch 38/45, Loss: 0.01566055789589882\n",
            "Epoch 205/400, Batch 39/45, Loss: 0.012666603550314903\n",
            "Epoch 205/400, Batch 40/45, Loss: 0.01895783841609955\n",
            "Epoch 205/400, Batch 41/45, Loss: 0.0074760448187589645\n",
            "Epoch 205/400, Batch 42/45, Loss: 0.008563278242945671\n",
            "Epoch 205/400, Batch 43/45, Loss: 0.007716461084783077\n",
            "Epoch 205/400, Batch 44/45, Loss: 0.009072544053196907\n",
            "Epoch 205/400, Batch 45/45, Loss: 0.016901763156056404\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.4595093913376331 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  206 , Time Elapsed:  163.54190022150675  mins\n",
            "Epoch 206/400, Batch 1/45, Loss: 0.007646530866622925\n",
            "Epoch 206/400, Batch 2/45, Loss: 0.0019403949845582247\n",
            "Epoch 206/400, Batch 3/45, Loss: 0.022487681359052658\n",
            "Epoch 206/400, Batch 4/45, Loss: 0.02296426333487034\n",
            "Epoch 206/400, Batch 5/45, Loss: 0.012154869735240936\n",
            "Epoch 206/400, Batch 6/45, Loss: 0.01650623232126236\n",
            "Epoch 206/400, Batch 7/45, Loss: 0.01977512612938881\n",
            "Epoch 206/400, Batch 8/45, Loss: 0.0388200469315052\n",
            "Epoch 206/400, Batch 9/45, Loss: 0.027283290401101112\n",
            "Epoch 206/400, Batch 10/45, Loss: 0.012656094506382942\n",
            "Epoch 206/400, Batch 11/45, Loss: 0.005825522821396589\n",
            "Epoch 206/400, Batch 12/45, Loss: 0.004200570750981569\n",
            "Epoch 206/400, Batch 13/45, Loss: 0.011772248893976212\n",
            "Epoch 206/400, Batch 14/45, Loss: 0.005480564199388027\n",
            "Epoch 206/400, Batch 15/45, Loss: 0.0060989283956587315\n",
            "Epoch 206/400, Batch 16/45, Loss: 0.03287959843873978\n",
            "Epoch 206/400, Batch 17/45, Loss: 0.02298646979033947\n",
            "Epoch 206/400, Batch 18/45, Loss: 0.011427465826272964\n",
            "Epoch 206/400, Batch 19/45, Loss: 0.01482165977358818\n",
            "Epoch 206/400, Batch 20/45, Loss: 0.02526954375207424\n",
            "Epoch 206/400, Batch 21/45, Loss: 0.006147509440779686\n",
            "Epoch 206/400, Batch 22/45, Loss: 0.009968509897589684\n",
            "Epoch 206/400, Batch 23/45, Loss: 0.0283278226852417\n",
            "Epoch 206/400, Batch 24/45, Loss: 0.009946215897798538\n",
            "Epoch 206/400, Batch 25/45, Loss: 0.02675718441605568\n",
            "Epoch 206/400, Batch 26/45, Loss: 0.028041541576385498\n",
            "Epoch 206/400, Batch 27/45, Loss: 0.04533015936613083\n",
            "Epoch 206/400, Batch 28/45, Loss: 0.010316561907529831\n",
            "Epoch 206/400, Batch 29/45, Loss: 0.03175788000226021\n",
            "Epoch 206/400, Batch 30/45, Loss: 0.021379979327321053\n",
            "Epoch 206/400, Batch 31/45, Loss: 0.012137366458773613\n",
            "Epoch 206/400, Batch 32/45, Loss: 0.013518307358026505\n",
            "Epoch 206/400, Batch 33/45, Loss: 0.019852854311466217\n",
            "Epoch 206/400, Batch 34/45, Loss: 0.01274094358086586\n",
            "Epoch 206/400, Batch 35/45, Loss: 0.018969926983118057\n",
            "Epoch 206/400, Batch 36/45, Loss: 0.010389404371380806\n",
            "Epoch 206/400, Batch 37/45, Loss: 0.027045397087931633\n",
            "Epoch 206/400, Batch 38/45, Loss: 0.028471073135733604\n",
            "Epoch 206/400, Batch 39/45, Loss: 0.07603625953197479\n",
            "Epoch 206/400, Batch 40/45, Loss: 0.011436098255217075\n",
            "Epoch 206/400, Batch 41/45, Loss: 0.0034237562213093042\n",
            "Epoch 206/400, Batch 42/45, Loss: 0.025393910706043243\n",
            "Epoch 206/400, Batch 43/45, Loss: 0.013101376593112946\n",
            "Epoch 206/400, Batch 44/45, Loss: 0.04279865324497223\n",
            "Epoch 206/400, Batch 45/45, Loss: 0.01266867108643055\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.3703988119959831 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  207 , Time Elapsed:  164.33612829844157  mins\n",
            "Epoch 207/400, Batch 1/45, Loss: 0.06743119657039642\n",
            "Epoch 207/400, Batch 2/45, Loss: 0.024746734648942947\n",
            "Epoch 207/400, Batch 3/45, Loss: 0.025458019226789474\n",
            "Epoch 207/400, Batch 4/45, Loss: 0.005861510988324881\n",
            "Epoch 207/400, Batch 5/45, Loss: 0.012437357567250729\n",
            "Epoch 207/400, Batch 6/45, Loss: 0.004569264128804207\n",
            "Epoch 207/400, Batch 7/45, Loss: 0.01647581346333027\n",
            "Epoch 207/400, Batch 8/45, Loss: 0.0125014279037714\n",
            "Epoch 207/400, Batch 9/45, Loss: 0.01624232716858387\n",
            "Epoch 207/400, Batch 10/45, Loss: 0.01159360259771347\n",
            "Epoch 207/400, Batch 11/45, Loss: 0.008981741033494473\n",
            "Epoch 207/400, Batch 12/45, Loss: 0.00836963951587677\n",
            "Epoch 207/400, Batch 13/45, Loss: 0.03332170099020004\n",
            "Epoch 207/400, Batch 14/45, Loss: 0.05778110399842262\n",
            "Epoch 207/400, Batch 15/45, Loss: 0.011383112519979477\n",
            "Epoch 207/400, Batch 16/45, Loss: 0.015768324956297874\n",
            "Epoch 207/400, Batch 17/45, Loss: 0.013891998678445816\n",
            "Epoch 207/400, Batch 18/45, Loss: 0.006537484936416149\n",
            "Epoch 207/400, Batch 19/45, Loss: 0.032555460929870605\n",
            "Epoch 207/400, Batch 20/45, Loss: 0.01445472240447998\n",
            "Epoch 207/400, Batch 21/45, Loss: 0.023435162380337715\n",
            "Epoch 207/400, Batch 22/45, Loss: 0.01225836668163538\n",
            "Epoch 207/400, Batch 23/45, Loss: 0.02279057167470455\n",
            "Epoch 207/400, Batch 24/45, Loss: 0.17253561317920685\n",
            "Epoch 207/400, Batch 25/45, Loss: 0.011594610288739204\n",
            "Epoch 207/400, Batch 26/45, Loss: 0.009144162759184837\n",
            "Epoch 207/400, Batch 27/45, Loss: 0.02035796269774437\n",
            "Epoch 207/400, Batch 28/45, Loss: 0.019864920526742935\n",
            "Epoch 207/400, Batch 29/45, Loss: 0.08302207291126251\n",
            "Epoch 207/400, Batch 30/45, Loss: 0.029567724093794823\n",
            "Epoch 207/400, Batch 31/45, Loss: 0.020655963569879532\n",
            "Epoch 207/400, Batch 32/45, Loss: 0.020108845084905624\n",
            "Epoch 207/400, Batch 33/45, Loss: 0.0550873801112175\n",
            "Epoch 207/400, Batch 34/45, Loss: 0.020303841680288315\n",
            "Epoch 207/400, Batch 35/45, Loss: 0.015856433659791946\n",
            "Epoch 207/400, Batch 36/45, Loss: 0.012000576592981815\n",
            "Epoch 207/400, Batch 37/45, Loss: 0.014511069282889366\n",
            "Epoch 207/400, Batch 38/45, Loss: 0.032304201275110245\n",
            "Epoch 207/400, Batch 39/45, Loss: 0.00850222073495388\n",
            "Epoch 207/400, Batch 40/45, Loss: 0.07268556207418442\n",
            "Epoch 207/400, Batch 41/45, Loss: 0.05677869915962219\n",
            "Epoch 207/400, Batch 42/45, Loss: 0.0034446176141500473\n",
            "Epoch 207/400, Batch 43/45, Loss: 0.010715260170400143\n",
            "Epoch 207/400, Batch 44/45, Loss: 0.02112773060798645\n",
            "Epoch 207/400, Batch 45/45, Loss: 0.012070012278854847\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.5893232077360153 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  208 , Time Elapsed:  165.12571717898052  mins\n",
            "Epoch 208/400, Batch 1/45, Loss: 0.008521594107151031\n",
            "Epoch 208/400, Batch 2/45, Loss: 0.013006458058953285\n",
            "Epoch 208/400, Batch 3/45, Loss: 0.07869641482830048\n",
            "Epoch 208/400, Batch 4/45, Loss: 0.02952801063656807\n",
            "Epoch 208/400, Batch 5/45, Loss: 0.023421473801136017\n",
            "Epoch 208/400, Batch 6/45, Loss: 0.013446616008877754\n",
            "Epoch 208/400, Batch 7/45, Loss: 0.02367262728512287\n",
            "Epoch 208/400, Batch 8/45, Loss: 0.015436708927154541\n",
            "Epoch 208/400, Batch 9/45, Loss: 0.020785238593816757\n",
            "Epoch 208/400, Batch 10/45, Loss: 0.022444553673267365\n",
            "Epoch 208/400, Batch 11/45, Loss: 0.005347319412976503\n",
            "Epoch 208/400, Batch 12/45, Loss: 0.05178940296173096\n",
            "Epoch 208/400, Batch 13/45, Loss: 0.008592204190790653\n",
            "Epoch 208/400, Batch 14/45, Loss: 0.004905179142951965\n",
            "Epoch 208/400, Batch 15/45, Loss: 0.015103420242667198\n",
            "Epoch 208/400, Batch 16/45, Loss: 0.010854640044271946\n",
            "Epoch 208/400, Batch 17/45, Loss: 0.012173252180218697\n",
            "Epoch 208/400, Batch 18/45, Loss: 0.009668654762208462\n",
            "Epoch 208/400, Batch 19/45, Loss: 0.009178782813251019\n",
            "Epoch 208/400, Batch 20/45, Loss: 0.01281278021633625\n",
            "Epoch 208/400, Batch 21/45, Loss: 0.02608170546591282\n",
            "Epoch 208/400, Batch 22/45, Loss: 0.01318602729588747\n",
            "Epoch 208/400, Batch 23/45, Loss: 0.019640490412712097\n",
            "Epoch 208/400, Batch 24/45, Loss: 0.0287859458476305\n",
            "Epoch 208/400, Batch 25/45, Loss: 0.026251666247844696\n",
            "Epoch 208/400, Batch 26/45, Loss: 0.008443916216492653\n",
            "Epoch 208/400, Batch 27/45, Loss: 0.004100087098777294\n",
            "Epoch 208/400, Batch 28/45, Loss: 0.006723693571984768\n",
            "Epoch 208/400, Batch 29/45, Loss: 0.005028036423027515\n",
            "Epoch 208/400, Batch 30/45, Loss: 0.010448993183672428\n",
            "Epoch 208/400, Batch 31/45, Loss: 0.017698563635349274\n",
            "Epoch 208/400, Batch 32/45, Loss: 0.014151493087410927\n",
            "Epoch 208/400, Batch 33/45, Loss: 0.029181912541389465\n",
            "Epoch 208/400, Batch 34/45, Loss: 0.00904025137424469\n",
            "Epoch 208/400, Batch 35/45, Loss: 0.011588139459490776\n",
            "Epoch 208/400, Batch 36/45, Loss: 0.034340377897024155\n",
            "Epoch 208/400, Batch 37/45, Loss: 0.002709477674216032\n",
            "Epoch 208/400, Batch 38/45, Loss: 0.014271926134824753\n",
            "Epoch 208/400, Batch 39/45, Loss: 0.01254282332956791\n",
            "Epoch 208/400, Batch 40/45, Loss: 0.06105557456612587\n",
            "Epoch 208/400, Batch 41/45, Loss: 0.014896601438522339\n",
            "Epoch 208/400, Batch 42/45, Loss: 0.010434973984956741\n",
            "Epoch 208/400, Batch 43/45, Loss: 0.023986412212252617\n",
            "Epoch 208/400, Batch 44/45, Loss: 0.05840490385890007\n",
            "Epoch 208/400, Batch 45/45, Loss: 0.011602601036429405\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.3314295709133148 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  209 , Time Elapsed:  165.94252139727274  mins\n",
            "Epoch 209/400, Batch 1/45, Loss: 0.010907945223152637\n",
            "Epoch 209/400, Batch 2/45, Loss: 0.014231143519282341\n",
            "Epoch 209/400, Batch 3/45, Loss: 0.008167736232280731\n",
            "Epoch 209/400, Batch 4/45, Loss: 0.010191479697823524\n",
            "Epoch 209/400, Batch 5/45, Loss: 0.026616886258125305\n",
            "Epoch 209/400, Batch 6/45, Loss: 0.005957098677754402\n",
            "Epoch 209/400, Batch 7/45, Loss: 0.021825741976499557\n",
            "Epoch 209/400, Batch 8/45, Loss: 0.007708781398832798\n",
            "Epoch 209/400, Batch 9/45, Loss: 0.0600733757019043\n",
            "Epoch 209/400, Batch 10/45, Loss: 0.011459830217063427\n",
            "Epoch 209/400, Batch 11/45, Loss: 0.008948070928454399\n",
            "Epoch 209/400, Batch 12/45, Loss: 0.015288433991372585\n",
            "Epoch 209/400, Batch 13/45, Loss: 0.004795966669917107\n",
            "Epoch 209/400, Batch 14/45, Loss: 0.010376947931945324\n",
            "Epoch 209/400, Batch 15/45, Loss: 0.005930677056312561\n",
            "Epoch 209/400, Batch 16/45, Loss: 0.008737193420529366\n",
            "Epoch 209/400, Batch 17/45, Loss: 0.007506749592721462\n",
            "Epoch 209/400, Batch 18/45, Loss: 0.015708575025200844\n",
            "Epoch 209/400, Batch 19/45, Loss: 0.023218221962451935\n",
            "Epoch 209/400, Batch 20/45, Loss: 0.010796589776873589\n",
            "Epoch 209/400, Batch 21/45, Loss: 0.010358604602515697\n",
            "Epoch 209/400, Batch 22/45, Loss: 0.024463020265102386\n",
            "Epoch 209/400, Batch 23/45, Loss: 0.01754428818821907\n",
            "Epoch 209/400, Batch 24/45, Loss: 0.01565956324338913\n",
            "Epoch 209/400, Batch 25/45, Loss: 0.026016006246209145\n",
            "Epoch 209/400, Batch 26/45, Loss: 0.0092765549197793\n",
            "Epoch 209/400, Batch 27/45, Loss: 0.012099027633666992\n",
            "Epoch 209/400, Batch 28/45, Loss: 0.008000214584171772\n",
            "Epoch 209/400, Batch 29/45, Loss: 0.008117696270346642\n",
            "Epoch 209/400, Batch 30/45, Loss: 0.04193615913391113\n",
            "Epoch 209/400, Batch 31/45, Loss: 0.0072491709142923355\n",
            "Epoch 209/400, Batch 32/45, Loss: 0.03267035633325577\n",
            "Epoch 209/400, Batch 33/45, Loss: 0.03731299936771393\n",
            "Epoch 209/400, Batch 34/45, Loss: 0.013813303783535957\n",
            "Epoch 209/400, Batch 35/45, Loss: 0.011454078368842602\n",
            "Epoch 209/400, Batch 36/45, Loss: 0.019204970449209213\n",
            "Epoch 209/400, Batch 37/45, Loss: 0.026427708566188812\n",
            "Epoch 209/400, Batch 38/45, Loss: 0.03317172825336456\n",
            "Epoch 209/400, Batch 39/45, Loss: 0.010527776554226875\n",
            "Epoch 209/400, Batch 40/45, Loss: 0.008893877267837524\n",
            "Epoch 209/400, Batch 41/45, Loss: 0.010656935162842274\n",
            "Epoch 209/400, Batch 42/45, Loss: 0.05797658860683441\n",
            "Epoch 209/400, Batch 43/45, Loss: 0.05481445789337158\n",
            "Epoch 209/400, Batch 44/45, Loss: 0.010412229225039482\n",
            "Epoch 209/400, Batch 45/45, Loss: 0.013367483392357826\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.5854163989424706 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  210 , Time Elapsed:  166.72944338321685  mins\n",
            "Epoch 210/400, Batch 1/45, Loss: 0.020312828943133354\n",
            "Epoch 210/400, Batch 2/45, Loss: 0.014618887566030025\n",
            "Epoch 210/400, Batch 3/45, Loss: 0.015064781531691551\n",
            "Epoch 210/400, Batch 4/45, Loss: 0.019875947386026382\n",
            "Epoch 210/400, Batch 5/45, Loss: 0.01233860943466425\n",
            "Epoch 210/400, Batch 6/45, Loss: 0.003992632031440735\n",
            "Epoch 210/400, Batch 7/45, Loss: 0.014638211578130722\n",
            "Epoch 210/400, Batch 8/45, Loss: 0.026226352900266647\n",
            "Epoch 210/400, Batch 9/45, Loss: 0.014670966193079948\n",
            "Epoch 210/400, Batch 10/45, Loss: 0.011233117431402206\n",
            "Epoch 210/400, Batch 11/45, Loss: 0.030838720500469208\n",
            "Epoch 210/400, Batch 12/45, Loss: 0.01772175170481205\n",
            "Epoch 210/400, Batch 13/45, Loss: 0.015327946282923222\n",
            "Epoch 210/400, Batch 14/45, Loss: 0.029428616166114807\n",
            "Epoch 210/400, Batch 15/45, Loss: 0.031768765300512314\n",
            "Epoch 210/400, Batch 16/45, Loss: 0.03518976643681526\n",
            "Epoch 210/400, Batch 17/45, Loss: 0.022326700389385223\n",
            "Epoch 210/400, Batch 18/45, Loss: 0.016251640394330025\n",
            "Epoch 210/400, Batch 19/45, Loss: 0.00729728490114212\n",
            "Epoch 210/400, Batch 20/45, Loss: 0.02298368513584137\n",
            "Epoch 210/400, Batch 21/45, Loss: 0.005754418671131134\n",
            "Epoch 210/400, Batch 22/45, Loss: 0.011266203597187996\n",
            "Epoch 210/400, Batch 23/45, Loss: 0.021321842446923256\n",
            "Epoch 210/400, Batch 24/45, Loss: 0.03745946288108826\n",
            "Epoch 210/400, Batch 25/45, Loss: 0.015107715502381325\n",
            "Epoch 210/400, Batch 26/45, Loss: 0.011790531687438488\n",
            "Epoch 210/400, Batch 27/45, Loss: 0.006716747768223286\n",
            "Epoch 210/400, Batch 28/45, Loss: 0.010051548480987549\n",
            "Epoch 210/400, Batch 29/45, Loss: 0.011822696775197983\n",
            "Epoch 210/400, Batch 30/45, Loss: 0.007865642197430134\n",
            "Epoch 210/400, Batch 31/45, Loss: 0.013210201635956764\n",
            "Epoch 210/400, Batch 32/45, Loss: 0.003570706117898226\n",
            "Epoch 210/400, Batch 33/45, Loss: 0.0066431863233447075\n",
            "Epoch 210/400, Batch 34/45, Loss: 0.016566473990678787\n",
            "Epoch 210/400, Batch 35/45, Loss: 0.02925192192196846\n",
            "Epoch 210/400, Batch 36/45, Loss: 0.01744014024734497\n",
            "Epoch 210/400, Batch 37/45, Loss: 0.008034621365368366\n",
            "Epoch 210/400, Batch 38/45, Loss: 0.029218463227152824\n",
            "Epoch 210/400, Batch 39/45, Loss: 0.049341365694999695\n",
            "Epoch 210/400, Batch 40/45, Loss: 0.0667983889579773\n",
            "Epoch 210/400, Batch 41/45, Loss: 0.10562853515148163\n",
            "Epoch 210/400, Batch 42/45, Loss: 0.010488082654774189\n",
            "Epoch 210/400, Batch 43/45, Loss: 0.016427557915449142\n",
            "Epoch 210/400, Batch 44/45, Loss: 0.004178449511528015\n",
            "Epoch 210/400, Batch 45/45, Loss: 0.03377924859523773\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.342630561441183 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  211 , Time Elapsed:  167.54486442804335  mins\n",
            "Epoch 211/400, Batch 1/45, Loss: 0.00706664752215147\n",
            "Epoch 211/400, Batch 2/45, Loss: 0.02339441329240799\n",
            "Epoch 211/400, Batch 3/45, Loss: 0.028334589675068855\n",
            "Epoch 211/400, Batch 4/45, Loss: 0.0016111586010083556\n",
            "Epoch 211/400, Batch 5/45, Loss: 0.009994613006711006\n",
            "Epoch 211/400, Batch 6/45, Loss: 0.005518053658306599\n",
            "Epoch 211/400, Batch 7/45, Loss: 0.20680178701877594\n",
            "Epoch 211/400, Batch 8/45, Loss: 0.007758021354675293\n",
            "Epoch 211/400, Batch 9/45, Loss: 0.03760292008519173\n",
            "Epoch 211/400, Batch 10/45, Loss: 0.03822600096464157\n",
            "Epoch 211/400, Batch 11/45, Loss: 0.04005758836865425\n",
            "Epoch 211/400, Batch 12/45, Loss: 0.08757564425468445\n",
            "Epoch 211/400, Batch 13/45, Loss: 0.0388060100376606\n",
            "Epoch 211/400, Batch 14/45, Loss: 0.07009901851415634\n",
            "Epoch 211/400, Batch 15/45, Loss: 0.009124732576310635\n",
            "Epoch 211/400, Batch 16/45, Loss: 0.041997287422418594\n",
            "Epoch 211/400, Batch 17/45, Loss: 0.052482690662145615\n",
            "Epoch 211/400, Batch 18/45, Loss: 0.03848849982023239\n",
            "Epoch 211/400, Batch 19/45, Loss: 0.012563155964016914\n",
            "Epoch 211/400, Batch 20/45, Loss: 0.04083393141627312\n",
            "Epoch 211/400, Batch 21/45, Loss: 0.007295601535588503\n",
            "Epoch 211/400, Batch 22/45, Loss: 0.005557442083954811\n",
            "Epoch 211/400, Batch 23/45, Loss: 0.025620436295866966\n",
            "Epoch 211/400, Batch 24/45, Loss: 0.022004302591085434\n",
            "Epoch 211/400, Batch 25/45, Loss: 0.014097388833761215\n",
            "Epoch 211/400, Batch 26/45, Loss: 0.03133438155055046\n",
            "Epoch 211/400, Batch 27/45, Loss: 0.03617144376039505\n",
            "Epoch 211/400, Batch 28/45, Loss: 0.0193046722561121\n",
            "Epoch 211/400, Batch 29/45, Loss: 0.02152145281434059\n",
            "Epoch 211/400, Batch 30/45, Loss: 0.013352636247873306\n",
            "Epoch 211/400, Batch 31/45, Loss: 0.005255531053990126\n",
            "Epoch 211/400, Batch 32/45, Loss: 0.027811389416456223\n",
            "Epoch 211/400, Batch 33/45, Loss: 0.02151457779109478\n",
            "Epoch 211/400, Batch 34/45, Loss: 0.035642076283693314\n",
            "Epoch 211/400, Batch 35/45, Loss: 0.0025079059414565563\n",
            "Epoch 211/400, Batch 36/45, Loss: 0.0107019217684865\n",
            "Epoch 211/400, Batch 37/45, Loss: 0.03809072822332382\n",
            "Epoch 211/400, Batch 38/45, Loss: 0.01946788653731346\n",
            "Epoch 211/400, Batch 39/45, Loss: 0.01246290560811758\n",
            "Epoch 211/400, Batch 40/45, Loss: 0.029171211645007133\n",
            "Epoch 211/400, Batch 41/45, Loss: 0.028125539422035217\n",
            "Epoch 211/400, Batch 42/45, Loss: 0.03933525085449219\n",
            "Epoch 211/400, Batch 43/45, Loss: 0.03308587893843651\n",
            "Epoch 211/400, Batch 44/45, Loss: 0.018134374171495438\n",
            "Epoch 211/400, Batch 45/45, Loss: 0.053677886724472046\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.8011343069374561 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  212 , Time Elapsed:  168.3256211121877  mins\n",
            "Epoch 212/400, Batch 1/45, Loss: 0.040714018046855927\n",
            "Epoch 212/400, Batch 2/45, Loss: 0.009602319449186325\n",
            "Epoch 212/400, Batch 3/45, Loss: 0.016159040853381157\n",
            "Epoch 212/400, Batch 4/45, Loss: 0.02440023235976696\n",
            "Epoch 212/400, Batch 5/45, Loss: 0.015388009138405323\n",
            "Epoch 212/400, Batch 6/45, Loss: 0.02913944609463215\n",
            "Epoch 212/400, Batch 7/45, Loss: 0.013406260870397091\n",
            "Epoch 212/400, Batch 8/45, Loss: 0.05527520552277565\n",
            "Epoch 212/400, Batch 9/45, Loss: 0.013980727642774582\n",
            "Epoch 212/400, Batch 10/45, Loss: 0.034898288547992706\n",
            "Epoch 212/400, Batch 11/45, Loss: 0.027750322595238686\n",
            "Epoch 212/400, Batch 12/45, Loss: 0.019341105595231056\n",
            "Epoch 212/400, Batch 13/45, Loss: 0.024726666510105133\n",
            "Epoch 212/400, Batch 14/45, Loss: 0.01638469286262989\n",
            "Epoch 212/400, Batch 15/45, Loss: 0.01535535417497158\n",
            "Epoch 212/400, Batch 16/45, Loss: 0.004315794911235571\n",
            "Epoch 212/400, Batch 17/45, Loss: 0.0259380079805851\n",
            "Epoch 212/400, Batch 18/45, Loss: 0.007816558703780174\n",
            "Epoch 212/400, Batch 19/45, Loss: 0.007365749217569828\n",
            "Epoch 212/400, Batch 20/45, Loss: 0.007760262116789818\n",
            "Epoch 212/400, Batch 21/45, Loss: 0.01871766522526741\n",
            "Epoch 212/400, Batch 22/45, Loss: 0.01232738234102726\n",
            "Epoch 212/400, Batch 23/45, Loss: 0.004323085304349661\n",
            "Epoch 212/400, Batch 24/45, Loss: 0.039300307631492615\n",
            "Epoch 212/400, Batch 25/45, Loss: 0.01587846875190735\n",
            "Epoch 212/400, Batch 26/45, Loss: 0.006189114414155483\n",
            "Epoch 212/400, Batch 27/45, Loss: 0.01828259602189064\n",
            "Epoch 212/400, Batch 28/45, Loss: 0.009011948481202126\n",
            "Epoch 212/400, Batch 29/45, Loss: 0.0020867029670625925\n",
            "Epoch 212/400, Batch 30/45, Loss: 0.01977047696709633\n",
            "Epoch 212/400, Batch 31/45, Loss: 0.008640294894576073\n",
            "Epoch 212/400, Batch 32/45, Loss: 0.018128827214241028\n",
            "Epoch 212/400, Batch 33/45, Loss: 0.008911361917853355\n",
            "Epoch 212/400, Batch 34/45, Loss: 0.015453286468982697\n",
            "Epoch 212/400, Batch 35/45, Loss: 0.025453370064496994\n",
            "Epoch 212/400, Batch 36/45, Loss: 0.014422234147787094\n",
            "Epoch 212/400, Batch 37/45, Loss: 0.010962531901896\n",
            "Epoch 212/400, Batch 38/45, Loss: 0.004127216525375843\n",
            "Epoch 212/400, Batch 39/45, Loss: 0.008535956963896751\n",
            "Epoch 212/400, Batch 40/45, Loss: 0.02079925127327442\n",
            "Epoch 212/400, Batch 41/45, Loss: 0.013972067274153233\n",
            "Epoch 212/400, Batch 42/45, Loss: 0.003725187387317419\n",
            "Epoch 212/400, Batch 43/45, Loss: 0.013572131283581257\n",
            "Epoch 212/400, Batch 44/45, Loss: 0.00552018079906702\n",
            "Epoch 212/400, Batch 45/45, Loss: 0.019324880093336105\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.2494888976216316 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  213 , Time Elapsed:  169.1447575132052  mins\n",
            "Epoch 213/400, Batch 1/45, Loss: 0.0237794890999794\n",
            "Epoch 213/400, Batch 2/45, Loss: 0.008647309616208076\n",
            "Epoch 213/400, Batch 3/45, Loss: 0.04175490513443947\n",
            "Epoch 213/400, Batch 4/45, Loss: 0.01169001404196024\n",
            "Epoch 213/400, Batch 5/45, Loss: 0.028942517936229706\n",
            "Epoch 213/400, Batch 6/45, Loss: 0.012967568822205067\n",
            "Epoch 213/400, Batch 7/45, Loss: 0.006398152559995651\n",
            "Epoch 213/400, Batch 8/45, Loss: 0.019746338948607445\n",
            "Epoch 213/400, Batch 9/45, Loss: 0.025127116590738297\n",
            "Epoch 213/400, Batch 10/45, Loss: 0.009143028408288956\n",
            "Epoch 213/400, Batch 11/45, Loss: 0.016916878521442413\n",
            "Epoch 213/400, Batch 12/45, Loss: 0.004409691318869591\n",
            "Epoch 213/400, Batch 13/45, Loss: 0.017911799252033234\n",
            "Epoch 213/400, Batch 14/45, Loss: 0.02505088597536087\n",
            "Epoch 213/400, Batch 15/45, Loss: 0.035915300250053406\n",
            "Epoch 213/400, Batch 16/45, Loss: 0.025492297485470772\n",
            "Epoch 213/400, Batch 17/45, Loss: 0.025889672338962555\n",
            "Epoch 213/400, Batch 18/45, Loss: 0.007781034801155329\n",
            "Epoch 213/400, Batch 19/45, Loss: 0.006436222232878208\n",
            "Epoch 213/400, Batch 20/45, Loss: 0.013844880275428295\n",
            "Epoch 213/400, Batch 21/45, Loss: 0.01658843830227852\n",
            "Epoch 213/400, Batch 22/45, Loss: 0.08654971420764923\n",
            "Epoch 213/400, Batch 23/45, Loss: 0.013742933981120586\n",
            "Epoch 213/400, Batch 24/45, Loss: 0.0034485384821891785\n",
            "Epoch 213/400, Batch 25/45, Loss: 0.011303103528916836\n",
            "Epoch 213/400, Batch 26/45, Loss: 0.043904080986976624\n",
            "Epoch 213/400, Batch 27/45, Loss: 0.048513103276491165\n",
            "Epoch 213/400, Batch 28/45, Loss: 0.019973229616880417\n",
            "Epoch 213/400, Batch 29/45, Loss: 0.014671338722109795\n",
            "Epoch 213/400, Batch 30/45, Loss: 0.006011879071593285\n",
            "Epoch 213/400, Batch 31/45, Loss: 0.028233058750629425\n",
            "Epoch 213/400, Batch 32/45, Loss: 0.010393915697932243\n",
            "Epoch 213/400, Batch 33/45, Loss: 0.029291614890098572\n",
            "Epoch 213/400, Batch 34/45, Loss: 0.0021636178717017174\n",
            "Epoch 213/400, Batch 35/45, Loss: 0.014599988237023354\n",
            "Epoch 213/400, Batch 36/45, Loss: 0.012108988128602505\n",
            "Epoch 213/400, Batch 37/45, Loss: 0.013188662007451057\n",
            "Epoch 213/400, Batch 38/45, Loss: 0.04269527643918991\n",
            "Epoch 213/400, Batch 39/45, Loss: 0.01924665831029415\n",
            "Epoch 213/400, Batch 40/45, Loss: 0.010530531406402588\n",
            "Epoch 213/400, Batch 41/45, Loss: 0.03798746317625046\n",
            "Epoch 213/400, Batch 42/45, Loss: 0.011215968057513237\n",
            "Epoch 213/400, Batch 43/45, Loss: 0.011458557099103928\n",
            "Epoch 213/400, Batch 44/45, Loss: 0.017566360533237457\n",
            "Epoch 213/400, Batch 45/45, Loss: 0.03411566838622093\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.2483800686895847 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  214 , Time Elapsed:  169.92887970209122  mins\n",
            "Epoch 214/400, Batch 1/45, Loss: 0.03047497570514679\n",
            "Epoch 214/400, Batch 2/45, Loss: 0.012923182919621468\n",
            "Epoch 214/400, Batch 3/45, Loss: 0.006757813505828381\n",
            "Epoch 214/400, Batch 4/45, Loss: 0.0075834207236766815\n",
            "Epoch 214/400, Batch 5/45, Loss: 0.018850700929760933\n",
            "Epoch 214/400, Batch 6/45, Loss: 0.01039858814328909\n",
            "Epoch 214/400, Batch 7/45, Loss: 0.013071139343082905\n",
            "Epoch 214/400, Batch 8/45, Loss: 0.013877389952540398\n",
            "Epoch 214/400, Batch 9/45, Loss: 0.01803925260901451\n",
            "Epoch 214/400, Batch 10/45, Loss: 0.0212035421282053\n",
            "Epoch 214/400, Batch 11/45, Loss: 0.021250680088996887\n",
            "Epoch 214/400, Batch 12/45, Loss: 0.002574125537648797\n",
            "Epoch 214/400, Batch 13/45, Loss: 0.019925901666283607\n",
            "Epoch 214/400, Batch 14/45, Loss: 0.012069574557244778\n",
            "Epoch 214/400, Batch 15/45, Loss: 0.020866841077804565\n",
            "Epoch 214/400, Batch 16/45, Loss: 0.03090033307671547\n",
            "Epoch 214/400, Batch 17/45, Loss: 0.14520777761936188\n",
            "Epoch 214/400, Batch 18/45, Loss: 0.02291952446103096\n",
            "Epoch 214/400, Batch 19/45, Loss: 0.017577778548002243\n",
            "Epoch 214/400, Batch 20/45, Loss: 0.03203505277633667\n",
            "Epoch 214/400, Batch 21/45, Loss: 0.022983668372035027\n",
            "Epoch 214/400, Batch 22/45, Loss: 0.04283323884010315\n",
            "Epoch 214/400, Batch 23/45, Loss: 0.13750991225242615\n",
            "Epoch 214/400, Batch 24/45, Loss: 0.010420664213597775\n",
            "Epoch 214/400, Batch 25/45, Loss: 0.03551610931754112\n",
            "Epoch 214/400, Batch 26/45, Loss: 0.043460413813591\n",
            "Epoch 214/400, Batch 27/45, Loss: 0.016826128587126732\n",
            "Epoch 214/400, Batch 28/45, Loss: 0.01410087663680315\n",
            "Epoch 214/400, Batch 29/45, Loss: 0.023243557661771774\n",
            "Epoch 214/400, Batch 30/45, Loss: 0.0422973595559597\n",
            "Epoch 214/400, Batch 31/45, Loss: 0.0068552130833268166\n",
            "Epoch 214/400, Batch 32/45, Loss: 0.026432067155838013\n",
            "Epoch 214/400, Batch 33/45, Loss: 0.005366744473576546\n",
            "Epoch 214/400, Batch 34/45, Loss: 0.004420737735927105\n",
            "Epoch 214/400, Batch 35/45, Loss: 0.01719997636973858\n",
            "Epoch 214/400, Batch 36/45, Loss: 0.006012182682752609\n",
            "Epoch 214/400, Batch 37/45, Loss: 0.01691029779613018\n",
            "Epoch 214/400, Batch 38/45, Loss: 0.01938173547387123\n",
            "Epoch 214/400, Batch 39/45, Loss: 0.01161887589842081\n",
            "Epoch 214/400, Batch 40/45, Loss: 0.00886303186416626\n",
            "Epoch 214/400, Batch 41/45, Loss: 0.026788288727402687\n",
            "Epoch 214/400, Batch 42/45, Loss: 0.018990879878401756\n",
            "Epoch 214/400, Batch 43/45, Loss: 0.004740132950246334\n",
            "Epoch 214/400, Batch 44/45, Loss: 0.01175111997872591\n",
            "Epoch 214/400, Batch 45/45, Loss: 0.011864181607961655\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.3650387823581696 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  215 , Time Elapsed:  170.7202910542488  mins\n",
            "Epoch 215/400, Batch 1/45, Loss: 0.008547618053853512\n",
            "Epoch 215/400, Batch 2/45, Loss: 0.03460598364472389\n",
            "Epoch 215/400, Batch 3/45, Loss: 0.004776429384946823\n",
            "Epoch 215/400, Batch 4/45, Loss: 0.004121830686926842\n",
            "Epoch 215/400, Batch 5/45, Loss: 0.014388532377779484\n",
            "Epoch 215/400, Batch 6/45, Loss: 0.02105354517698288\n",
            "Epoch 215/400, Batch 7/45, Loss: 0.035193026065826416\n",
            "Epoch 215/400, Batch 8/45, Loss: 0.011779162101447582\n",
            "Epoch 215/400, Batch 9/45, Loss: 0.026159094646573067\n",
            "Epoch 215/400, Batch 10/45, Loss: 0.015555487014353275\n",
            "Epoch 215/400, Batch 11/45, Loss: 0.029797211289405823\n",
            "Epoch 215/400, Batch 12/45, Loss: 0.030589686706662178\n",
            "Epoch 215/400, Batch 13/45, Loss: 0.012592203915119171\n",
            "Epoch 215/400, Batch 14/45, Loss: 0.03289593756198883\n",
            "Epoch 215/400, Batch 15/45, Loss: 0.004860226530581713\n",
            "Epoch 215/400, Batch 16/45, Loss: 0.009897037409245968\n",
            "Epoch 215/400, Batch 17/45, Loss: 0.005228173453360796\n",
            "Epoch 215/400, Batch 18/45, Loss: 0.008293296210467815\n",
            "Epoch 215/400, Batch 19/45, Loss: 0.054382048547267914\n",
            "Epoch 215/400, Batch 20/45, Loss: 0.0178664643317461\n",
            "Epoch 215/400, Batch 21/45, Loss: 0.023905238136649132\n",
            "Epoch 215/400, Batch 22/45, Loss: 0.006986930035054684\n",
            "Epoch 215/400, Batch 23/45, Loss: 0.04456254094839096\n",
            "Epoch 215/400, Batch 24/45, Loss: 0.006681483704596758\n",
            "Epoch 215/400, Batch 25/45, Loss: 0.0026709772646427155\n",
            "Epoch 215/400, Batch 26/45, Loss: 0.027494903653860092\n",
            "Epoch 215/400, Batch 27/45, Loss: 0.01971573941409588\n",
            "Epoch 215/400, Batch 28/45, Loss: 0.013727888464927673\n",
            "Epoch 215/400, Batch 29/45, Loss: 0.03612687811255455\n",
            "Epoch 215/400, Batch 30/45, Loss: 0.008652747608721256\n",
            "Epoch 215/400, Batch 31/45, Loss: 0.012608209624886513\n",
            "Epoch 215/400, Batch 32/45, Loss: 0.007135582156479359\n",
            "Epoch 215/400, Batch 33/45, Loss: 0.060970380902290344\n",
            "Epoch 215/400, Batch 34/45, Loss: 0.026130836457014084\n",
            "Epoch 215/400, Batch 35/45, Loss: 0.010417848825454712\n",
            "Epoch 215/400, Batch 36/45, Loss: 0.033167146146297455\n",
            "Epoch 215/400, Batch 37/45, Loss: 0.007318862713873386\n",
            "Epoch 215/400, Batch 38/45, Loss: 0.0128420265391469\n",
            "Epoch 215/400, Batch 39/45, Loss: 0.016056638211011887\n",
            "Epoch 215/400, Batch 40/45, Loss: 0.04878005385398865\n",
            "Epoch 215/400, Batch 41/45, Loss: 0.01147287804633379\n",
            "Epoch 215/400, Batch 42/45, Loss: 0.03027104213833809\n",
            "Epoch 215/400, Batch 43/45, Loss: 0.03871355950832367\n",
            "Epoch 215/400, Batch 44/45, Loss: 0.017895031720399857\n",
            "Epoch 215/400, Batch 45/45, Loss: 0.016514243558049202\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.3490597568452358 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  216 , Time Elapsed:  171.51240926186244  mins\n",
            "Epoch 216/400, Batch 1/45, Loss: 0.01823781244456768\n",
            "Epoch 216/400, Batch 2/45, Loss: 0.012545343488454819\n",
            "Epoch 216/400, Batch 3/45, Loss: 0.02327081188559532\n",
            "Epoch 216/400, Batch 4/45, Loss: 0.09061401337385178\n",
            "Epoch 216/400, Batch 5/45, Loss: 0.006511721760034561\n",
            "Epoch 216/400, Batch 6/45, Loss: 0.009389732033014297\n",
            "Epoch 216/400, Batch 7/45, Loss: 0.006889969110488892\n",
            "Epoch 216/400, Batch 8/45, Loss: 0.0225398950278759\n",
            "Epoch 216/400, Batch 9/45, Loss: 0.01226792298257351\n",
            "Epoch 216/400, Batch 10/45, Loss: 0.00812380202114582\n",
            "Epoch 216/400, Batch 11/45, Loss: 0.011375011876225471\n",
            "Epoch 216/400, Batch 12/45, Loss: 0.0039377654902637005\n",
            "Epoch 216/400, Batch 13/45, Loss: 0.02892281673848629\n",
            "Epoch 216/400, Batch 14/45, Loss: 0.0016384406480938196\n",
            "Epoch 216/400, Batch 15/45, Loss: 0.019480818882584572\n",
            "Epoch 216/400, Batch 16/45, Loss: 0.007735060527920723\n",
            "Epoch 216/400, Batch 17/45, Loss: 0.007278162986040115\n",
            "Epoch 216/400, Batch 18/45, Loss: 0.009229285642504692\n",
            "Epoch 216/400, Batch 19/45, Loss: 0.011238306760787964\n",
            "Epoch 216/400, Batch 20/45, Loss: 0.05275190621614456\n",
            "Epoch 216/400, Batch 21/45, Loss: 0.005238522309809923\n",
            "Epoch 216/400, Batch 22/45, Loss: 0.018497444689273834\n",
            "Epoch 216/400, Batch 23/45, Loss: 0.020865850150585175\n",
            "Epoch 216/400, Batch 24/45, Loss: 0.019389577209949493\n",
            "Epoch 216/400, Batch 25/45, Loss: 0.013501527719199657\n",
            "Epoch 216/400, Batch 26/45, Loss: 0.008504532277584076\n",
            "Epoch 216/400, Batch 27/45, Loss: 0.02091716043651104\n",
            "Epoch 216/400, Batch 28/45, Loss: 0.056673090904951096\n",
            "Epoch 216/400, Batch 29/45, Loss: 0.012754000723361969\n",
            "Epoch 216/400, Batch 30/45, Loss: 0.012849658727645874\n",
            "Epoch 216/400, Batch 31/45, Loss: 0.016387825831770897\n",
            "Epoch 216/400, Batch 32/45, Loss: 0.006640209816396236\n",
            "Epoch 216/400, Batch 33/45, Loss: 0.016233619302511215\n",
            "Epoch 216/400, Batch 34/45, Loss: 0.0294989962130785\n",
            "Epoch 216/400, Batch 35/45, Loss: 0.019900282844901085\n",
            "Epoch 216/400, Batch 36/45, Loss: 0.015815494582057\n",
            "Epoch 216/400, Batch 37/45, Loss: 0.00899171270430088\n",
            "Epoch 216/400, Batch 38/45, Loss: 0.02902560494840145\n",
            "Epoch 216/400, Batch 39/45, Loss: 0.008766958490014076\n",
            "Epoch 216/400, Batch 40/45, Loss: 0.011619972996413708\n",
            "Epoch 216/400, Batch 41/45, Loss: 0.02002839557826519\n",
            "Epoch 216/400, Batch 42/45, Loss: 0.006952276453375816\n",
            "Epoch 216/400, Batch 43/45, Loss: 0.008125048130750656\n",
            "Epoch 216/400, Batch 44/45, Loss: 0.008275127038359642\n",
            "Epoch 216/400, Batch 45/45, Loss: 0.00791187584400177\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.2802502326667309 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  217 , Time Elapsed:  172.29634404182434  mins\n",
            "Epoch 217/400, Batch 1/45, Loss: 0.006923642009496689\n",
            "Epoch 217/400, Batch 2/45, Loss: 0.009772399440407753\n",
            "Epoch 217/400, Batch 3/45, Loss: 0.028919177129864693\n",
            "Epoch 217/400, Batch 4/45, Loss: 0.013998260721564293\n",
            "Epoch 217/400, Batch 5/45, Loss: 0.012757200747728348\n",
            "Epoch 217/400, Batch 6/45, Loss: 0.007685414515435696\n",
            "Epoch 217/400, Batch 7/45, Loss: 0.019761882722377777\n",
            "Epoch 217/400, Batch 8/45, Loss: 0.035194285213947296\n",
            "Epoch 217/400, Batch 9/45, Loss: 0.04943358153104782\n",
            "Epoch 217/400, Batch 10/45, Loss: 0.013572212308645248\n",
            "Epoch 217/400, Batch 11/45, Loss: 0.012317217886447906\n",
            "Epoch 217/400, Batch 12/45, Loss: 0.15898287296295166\n",
            "Epoch 217/400, Batch 13/45, Loss: 0.010940246284008026\n",
            "Epoch 217/400, Batch 14/45, Loss: 0.0193194430321455\n",
            "Epoch 217/400, Batch 15/45, Loss: 0.03509774059057236\n",
            "Epoch 217/400, Batch 16/45, Loss: 0.08753609657287598\n",
            "Epoch 217/400, Batch 17/45, Loss: 0.012818368151783943\n",
            "Epoch 217/400, Batch 18/45, Loss: 0.02402706816792488\n",
            "Epoch 217/400, Batch 19/45, Loss: 0.021842923015356064\n",
            "Epoch 217/400, Batch 20/45, Loss: 0.009294765070080757\n",
            "Epoch 217/400, Batch 21/45, Loss: 0.0028566750697791576\n",
            "Epoch 217/400, Batch 22/45, Loss: 0.006489647086709738\n",
            "Epoch 217/400, Batch 23/45, Loss: 0.009341695345938206\n",
            "Epoch 217/400, Batch 24/45, Loss: 0.02557562105357647\n",
            "Epoch 217/400, Batch 25/45, Loss: 0.00559112336486578\n",
            "Epoch 217/400, Batch 26/45, Loss: 0.016642361879348755\n",
            "Epoch 217/400, Batch 27/45, Loss: 0.04415754973888397\n",
            "Epoch 217/400, Batch 28/45, Loss: 0.010365771129727364\n",
            "Epoch 217/400, Batch 29/45, Loss: 0.008392399176955223\n",
            "Epoch 217/400, Batch 30/45, Loss: 0.013409565202891827\n",
            "Epoch 217/400, Batch 31/45, Loss: 0.013895992189645767\n",
            "Epoch 217/400, Batch 32/45, Loss: 0.014110938645899296\n",
            "Epoch 217/400, Batch 33/45, Loss: 0.022159814834594727\n",
            "Epoch 217/400, Batch 34/45, Loss: 0.029286514967679977\n",
            "Epoch 217/400, Batch 35/45, Loss: 0.01245504803955555\n",
            "Epoch 217/400, Batch 36/45, Loss: 0.034822478890419006\n",
            "Epoch 217/400, Batch 37/45, Loss: 0.00607530539855361\n",
            "Epoch 217/400, Batch 38/45, Loss: 0.017793159931898117\n",
            "Epoch 217/400, Batch 39/45, Loss: 0.01029748935252428\n",
            "Epoch 217/400, Batch 40/45, Loss: 0.020329946652054787\n",
            "Epoch 217/400, Batch 41/45, Loss: 0.07318670302629471\n",
            "Epoch 217/400, Batch 42/45, Loss: 0.019817937165498734\n",
            "Epoch 217/400, Batch 43/45, Loss: 0.0737261027097702\n",
            "Epoch 217/400, Batch 44/45, Loss: 0.020748592913150787\n",
            "Epoch 217/400, Batch 45/45, Loss: 0.011947765946388245\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.2102991081774235 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  218 , Time Elapsed:  173.1043297290802  mins\n",
            "Epoch 218/400, Batch 1/45, Loss: 0.008743708953261375\n",
            "Epoch 218/400, Batch 2/45, Loss: 0.007612877059727907\n",
            "Epoch 218/400, Batch 3/45, Loss: 0.027001645416021347\n",
            "Epoch 218/400, Batch 4/45, Loss: 0.007485399022698402\n",
            "Epoch 218/400, Batch 5/45, Loss: 0.03924231976270676\n",
            "Epoch 218/400, Batch 6/45, Loss: 0.0195651613175869\n",
            "Epoch 218/400, Batch 7/45, Loss: 0.022207707166671753\n",
            "Epoch 218/400, Batch 8/45, Loss: 0.02060791850090027\n",
            "Epoch 218/400, Batch 9/45, Loss: 0.052752748131752014\n",
            "Epoch 218/400, Batch 10/45, Loss: 0.04805953800678253\n",
            "Epoch 218/400, Batch 11/45, Loss: 0.017851706594228745\n",
            "Epoch 218/400, Batch 12/45, Loss: 0.007089025340974331\n",
            "Epoch 218/400, Batch 13/45, Loss: 0.01802806928753853\n",
            "Epoch 218/400, Batch 14/45, Loss: 0.024201765656471252\n",
            "Epoch 218/400, Batch 15/45, Loss: 0.008440947160124779\n",
            "Epoch 218/400, Batch 16/45, Loss: 0.009731815196573734\n",
            "Epoch 218/400, Batch 17/45, Loss: 0.01050548441708088\n",
            "Epoch 218/400, Batch 18/45, Loss: 0.008103220723569393\n",
            "Epoch 218/400, Batch 19/45, Loss: 0.04765801876783371\n",
            "Epoch 218/400, Batch 20/45, Loss: 0.011137837544083595\n",
            "Epoch 218/400, Batch 21/45, Loss: 0.03974004089832306\n",
            "Epoch 218/400, Batch 22/45, Loss: 0.01087212935090065\n",
            "Epoch 218/400, Batch 23/45, Loss: 0.023617474362254143\n",
            "Epoch 218/400, Batch 24/45, Loss: 0.012034077197313309\n",
            "Epoch 218/400, Batch 25/45, Loss: 0.009012446738779545\n",
            "Epoch 218/400, Batch 26/45, Loss: 0.008117817342281342\n",
            "Epoch 218/400, Batch 27/45, Loss: 0.04777451977133751\n",
            "Epoch 218/400, Batch 28/45, Loss: 0.009279626421630383\n",
            "Epoch 218/400, Batch 29/45, Loss: 0.04029924049973488\n",
            "Epoch 218/400, Batch 30/45, Loss: 0.05591512471437454\n",
            "Epoch 218/400, Batch 31/45, Loss: 0.010939630679786205\n",
            "Epoch 218/400, Batch 32/45, Loss: 0.0228048637509346\n",
            "Epoch 218/400, Batch 33/45, Loss: 0.028642818331718445\n",
            "Epoch 218/400, Batch 34/45, Loss: 0.01690080016851425\n",
            "Epoch 218/400, Batch 35/45, Loss: 0.027055460959672928\n",
            "Epoch 218/400, Batch 36/45, Loss: 0.0021842303685843945\n",
            "Epoch 218/400, Batch 37/45, Loss: 0.07795020937919617\n",
            "Epoch 218/400, Batch 38/45, Loss: 0.024181492626667023\n",
            "Epoch 218/400, Batch 39/45, Loss: 0.021661126986145973\n",
            "Epoch 218/400, Batch 40/45, Loss: 0.016340848058462143\n",
            "Epoch 218/400, Batch 41/45, Loss: 0.023550482466816902\n",
            "Epoch 218/400, Batch 42/45, Loss: 0.0060998862609267235\n",
            "Epoch 218/400, Batch 43/45, Loss: 0.01294250600039959\n",
            "Epoch 218/400, Batch 44/45, Loss: 0.020639892667531967\n",
            "Epoch 218/400, Batch 45/45, Loss: 0.021655965596437454\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.6296868361532688 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  219 , Time Elapsed:  173.89212256272634  mins\n",
            "Epoch 219/400, Batch 1/45, Loss: 0.012643462046980858\n",
            "Epoch 219/400, Batch 2/45, Loss: 0.02808590792119503\n",
            "Epoch 219/400, Batch 3/45, Loss: 0.01187173929065466\n",
            "Epoch 219/400, Batch 4/45, Loss: 0.008128642104566097\n",
            "Epoch 219/400, Batch 5/45, Loss: 0.03667624667286873\n",
            "Epoch 219/400, Batch 6/45, Loss: 0.029136279597878456\n",
            "Epoch 219/400, Batch 7/45, Loss: 0.016415627673268318\n",
            "Epoch 219/400, Batch 8/45, Loss: 0.015679575502872467\n",
            "Epoch 219/400, Batch 9/45, Loss: 0.011197943240404129\n",
            "Epoch 219/400, Batch 10/45, Loss: 0.016151240095496178\n",
            "Epoch 219/400, Batch 11/45, Loss: 0.036390990018844604\n",
            "Epoch 219/400, Batch 12/45, Loss: 0.013404077850282192\n",
            "Epoch 219/400, Batch 13/45, Loss: 0.02760017290711403\n",
            "Epoch 219/400, Batch 14/45, Loss: 0.0144082335755229\n",
            "Epoch 219/400, Batch 15/45, Loss: 0.02317790873348713\n",
            "Epoch 219/400, Batch 16/45, Loss: 0.03663564845919609\n",
            "Epoch 219/400, Batch 17/45, Loss: 0.02606929838657379\n",
            "Epoch 219/400, Batch 18/45, Loss: 0.02385813370347023\n",
            "Epoch 219/400, Batch 19/45, Loss: 0.015469731763005257\n",
            "Epoch 219/400, Batch 20/45, Loss: 0.018178589642047882\n",
            "Epoch 219/400, Batch 21/45, Loss: 0.022452907636761665\n",
            "Epoch 219/400, Batch 22/45, Loss: 0.030295105651021004\n",
            "Epoch 219/400, Batch 23/45, Loss: 0.01980595290660858\n",
            "Epoch 219/400, Batch 24/45, Loss: 0.04381590336561203\n",
            "Epoch 219/400, Batch 25/45, Loss: 0.03727050870656967\n",
            "Epoch 219/400, Batch 26/45, Loss: 0.02509870007634163\n",
            "Epoch 219/400, Batch 27/45, Loss: 0.011158912442624569\n",
            "Epoch 219/400, Batch 28/45, Loss: 0.014201651327311993\n",
            "Epoch 219/400, Batch 29/45, Loss: 0.01107492484152317\n",
            "Epoch 219/400, Batch 30/45, Loss: 0.012733953073620796\n",
            "Epoch 219/400, Batch 31/45, Loss: 0.007649315055459738\n",
            "Epoch 219/400, Batch 32/45, Loss: 0.008409983478486538\n",
            "Epoch 219/400, Batch 33/45, Loss: 0.0203306432813406\n",
            "Epoch 219/400, Batch 34/45, Loss: 0.025099284946918488\n",
            "Epoch 219/400, Batch 35/45, Loss: 0.012783199548721313\n",
            "Epoch 219/400, Batch 36/45, Loss: 0.022641386836767197\n",
            "Epoch 219/400, Batch 37/45, Loss: 0.018377970904111862\n",
            "Epoch 219/400, Batch 38/45, Loss: 0.008636079728603363\n",
            "Epoch 219/400, Batch 39/45, Loss: 0.008596937172114849\n",
            "Epoch 219/400, Batch 40/45, Loss: 0.028930597007274628\n",
            "Epoch 219/400, Batch 41/45, Loss: 0.04701962694525719\n",
            "Epoch 219/400, Batch 42/45, Loss: 0.03321027010679245\n",
            "Epoch 219/400, Batch 43/45, Loss: 0.04300978034734726\n",
            "Epoch 219/400, Batch 44/45, Loss: 0.02760561741888523\n",
            "Epoch 219/400, Batch 45/45, Loss: 0.015066366642713547\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.5599112138152122 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  220 , Time Elapsed:  174.70877132813135  mins\n",
            "Epoch 220/400, Batch 1/45, Loss: 0.027718177065253258\n",
            "Epoch 220/400, Batch 2/45, Loss: 0.013128131628036499\n",
            "Epoch 220/400, Batch 3/45, Loss: 0.04334339126944542\n",
            "Epoch 220/400, Batch 4/45, Loss: 0.034485749900341034\n",
            "Epoch 220/400, Batch 5/45, Loss: 0.05272476375102997\n",
            "Epoch 220/400, Batch 6/45, Loss: 0.028805596753954887\n",
            "Epoch 220/400, Batch 7/45, Loss: 0.008111526258289814\n",
            "Epoch 220/400, Batch 8/45, Loss: 0.02947651408612728\n",
            "Epoch 220/400, Batch 9/45, Loss: 0.04858022183179855\n",
            "Epoch 220/400, Batch 10/45, Loss: 0.01882605440914631\n",
            "Epoch 220/400, Batch 11/45, Loss: 0.027587173506617546\n",
            "Epoch 220/400, Batch 12/45, Loss: 0.021388769149780273\n",
            "Epoch 220/400, Batch 13/45, Loss: 0.028357885777950287\n",
            "Epoch 220/400, Batch 14/45, Loss: 0.015913650393486023\n",
            "Epoch 220/400, Batch 15/45, Loss: 0.6083301901817322\n",
            "Epoch 220/400, Batch 16/45, Loss: 0.020946882665157318\n",
            "Epoch 220/400, Batch 17/45, Loss: 0.049769558012485504\n",
            "Epoch 220/400, Batch 18/45, Loss: 0.052458882331848145\n",
            "Epoch 220/400, Batch 19/45, Loss: 0.06834035366773605\n",
            "Epoch 220/400, Batch 20/45, Loss: 0.20425908267498016\n",
            "Epoch 220/400, Batch 21/45, Loss: 0.10958141833543777\n",
            "Epoch 220/400, Batch 22/45, Loss: 0.04039449244737625\n",
            "Epoch 220/400, Batch 23/45, Loss: 0.09797735512256622\n",
            "Epoch 220/400, Batch 24/45, Loss: 0.02975875325500965\n",
            "Epoch 220/400, Batch 25/45, Loss: 0.05199331045150757\n",
            "Epoch 220/400, Batch 26/45, Loss: 0.0969545990228653\n",
            "Epoch 220/400, Batch 27/45, Loss: 0.024762321263551712\n",
            "Epoch 220/400, Batch 28/45, Loss: 0.05449207127094269\n",
            "Epoch 220/400, Batch 29/45, Loss: 0.05236823111772537\n",
            "Epoch 220/400, Batch 30/45, Loss: 0.03797724097967148\n",
            "Epoch 220/400, Batch 31/45, Loss: 0.017487235367298126\n",
            "Epoch 220/400, Batch 32/45, Loss: 0.11989549547433853\n",
            "Epoch 220/400, Batch 33/45, Loss: 0.033871766179800034\n",
            "Epoch 220/400, Batch 34/45, Loss: 0.021413253620266914\n",
            "Epoch 220/400, Batch 35/45, Loss: 0.040431272238492966\n",
            "Epoch 220/400, Batch 36/45, Loss: 0.057145267724990845\n",
            "Epoch 220/400, Batch 37/45, Loss: 0.046175505965948105\n",
            "Epoch 220/400, Batch 38/45, Loss: 0.0917113721370697\n",
            "Epoch 220/400, Batch 39/45, Loss: 0.041976943612098694\n",
            "Epoch 220/400, Batch 40/45, Loss: 0.1580863744020462\n",
            "Epoch 220/400, Batch 41/45, Loss: 0.07118333131074905\n",
            "Epoch 220/400, Batch 42/45, Loss: 0.07475171983242035\n",
            "Epoch 220/400, Batch 43/45, Loss: 0.042388543486595154\n",
            "Epoch 220/400, Batch 44/45, Loss: 0.02376123145222664\n",
            "Epoch 220/400, Batch 45/45, Loss: 0.014831523410975933\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  2.2059199661016464 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  221 , Time Elapsed:  175.49394855499267  mins\n",
            "Epoch 221/400, Batch 1/45, Loss: 0.009031467139720917\n",
            "Epoch 221/400, Batch 2/45, Loss: 0.0112730348482728\n",
            "Epoch 221/400, Batch 3/45, Loss: 0.019704537466168404\n",
            "Epoch 221/400, Batch 4/45, Loss: 0.08748289942741394\n",
            "Epoch 221/400, Batch 5/45, Loss: 0.026335394009947777\n",
            "Epoch 221/400, Batch 6/45, Loss: 0.03734763339161873\n",
            "Epoch 221/400, Batch 7/45, Loss: 0.027977973222732544\n",
            "Epoch 221/400, Batch 8/45, Loss: 0.015558739192783833\n",
            "Epoch 221/400, Batch 9/45, Loss: 0.00725835096091032\n",
            "Epoch 221/400, Batch 10/45, Loss: 0.044867560267448425\n",
            "Epoch 221/400, Batch 11/45, Loss: 0.021857496351003647\n",
            "Epoch 221/400, Batch 12/45, Loss: 0.03615843504667282\n",
            "Epoch 221/400, Batch 13/45, Loss: 0.016742179170250893\n",
            "Epoch 221/400, Batch 14/45, Loss: 0.015350034460425377\n",
            "Epoch 221/400, Batch 15/45, Loss: 0.017781876027584076\n",
            "Epoch 221/400, Batch 16/45, Loss: 0.008113769814372063\n",
            "Epoch 221/400, Batch 17/45, Loss: 0.013172781094908714\n",
            "Epoch 221/400, Batch 18/45, Loss: 0.018227536231279373\n",
            "Epoch 221/400, Batch 19/45, Loss: 0.05375022441148758\n",
            "Epoch 221/400, Batch 20/45, Loss: 0.018828846514225006\n",
            "Epoch 221/400, Batch 21/45, Loss: 0.04276657849550247\n",
            "Epoch 221/400, Batch 22/45, Loss: 0.014940145425498486\n",
            "Epoch 221/400, Batch 23/45, Loss: 0.041446786373853683\n",
            "Epoch 221/400, Batch 24/45, Loss: 0.015285924077033997\n",
            "Epoch 221/400, Batch 25/45, Loss: 0.010039614513516426\n",
            "Epoch 221/400, Batch 26/45, Loss: 0.0596618726849556\n",
            "Epoch 221/400, Batch 27/45, Loss: 0.03167634457349777\n",
            "Epoch 221/400, Batch 28/45, Loss: 0.030784277245402336\n",
            "Epoch 221/400, Batch 29/45, Loss: 0.0701395571231842\n",
            "Epoch 221/400, Batch 30/45, Loss: 0.049752671271562576\n",
            "Epoch 221/400, Batch 31/45, Loss: 0.0230731088668108\n",
            "Epoch 221/400, Batch 32/45, Loss: 0.021328264847397804\n",
            "Epoch 221/400, Batch 33/45, Loss: 0.025250239297747612\n",
            "Epoch 221/400, Batch 34/45, Loss: 0.0587347075343132\n",
            "Epoch 221/400, Batch 35/45, Loss: 0.08573325723409653\n",
            "Epoch 221/400, Batch 36/45, Loss: 0.01670937053859234\n",
            "Epoch 221/400, Batch 37/45, Loss: 0.017943095415830612\n",
            "Epoch 221/400, Batch 38/45, Loss: 0.02702545002102852\n",
            "Epoch 221/400, Batch 39/45, Loss: 0.013240132480859756\n",
            "Epoch 221/400, Batch 40/45, Loss: 0.016625478863716125\n",
            "Epoch 221/400, Batch 41/45, Loss: 0.04382893443107605\n",
            "Epoch 221/400, Batch 42/45, Loss: 0.008808672428131104\n",
            "Epoch 221/400, Batch 43/45, Loss: 0.06215489283204079\n",
            "Epoch 221/400, Batch 44/45, Loss: 0.06089702993631363\n",
            "Epoch 221/400, Batch 45/45, Loss: 0.028196239843964577\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.7087753303349018 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  222 , Time Elapsed:  176.3156804005305  mins\n",
            "Epoch 222/400, Batch 1/45, Loss: 0.02606215700507164\n",
            "Epoch 222/400, Batch 2/45, Loss: 0.027026310563087463\n",
            "Epoch 222/400, Batch 3/45, Loss: 0.02385551854968071\n",
            "Epoch 222/400, Batch 4/45, Loss: 0.04868548735976219\n",
            "Epoch 222/400, Batch 5/45, Loss: 0.022891171276569366\n",
            "Epoch 222/400, Batch 6/45, Loss: 0.03989630937576294\n",
            "Epoch 222/400, Batch 7/45, Loss: 0.14812642335891724\n",
            "Epoch 222/400, Batch 8/45, Loss: 0.026272907853126526\n",
            "Epoch 222/400, Batch 9/45, Loss: 0.007382135838270187\n",
            "Epoch 222/400, Batch 10/45, Loss: 0.015707112848758698\n",
            "Epoch 222/400, Batch 11/45, Loss: 0.012394021265208721\n",
            "Epoch 222/400, Batch 12/45, Loss: 0.028125904500484467\n",
            "Epoch 222/400, Batch 13/45, Loss: 0.007057069335132837\n",
            "Epoch 222/400, Batch 14/45, Loss: 0.011818869970738888\n",
            "Epoch 222/400, Batch 15/45, Loss: 0.009901179000735283\n",
            "Epoch 222/400, Batch 16/45, Loss: 0.0034404254984110594\n",
            "Epoch 222/400, Batch 17/45, Loss: 0.013920633122324944\n",
            "Epoch 222/400, Batch 18/45, Loss: 0.024242941290140152\n",
            "Epoch 222/400, Batch 19/45, Loss: 0.0030420618131756783\n",
            "Epoch 222/400, Batch 20/45, Loss: 0.007020196877419949\n",
            "Epoch 222/400, Batch 21/45, Loss: 0.03779595345258713\n",
            "Epoch 222/400, Batch 22/45, Loss: 0.02139737270772457\n",
            "Epoch 222/400, Batch 23/45, Loss: 0.009740774519741535\n",
            "Epoch 222/400, Batch 24/45, Loss: 0.029059475287795067\n",
            "Epoch 222/400, Batch 25/45, Loss: 0.010634835809469223\n",
            "Epoch 222/400, Batch 26/45, Loss: 0.02712208963930607\n",
            "Epoch 222/400, Batch 27/45, Loss: 0.016688108444213867\n",
            "Epoch 222/400, Batch 28/45, Loss: 0.03172494098544121\n",
            "Epoch 222/400, Batch 29/45, Loss: 0.008229595609009266\n",
            "Epoch 222/400, Batch 30/45, Loss: 0.0259377621114254\n",
            "Epoch 222/400, Batch 31/45, Loss: 0.009259846061468124\n",
            "Epoch 222/400, Batch 32/45, Loss: 0.06201639026403427\n",
            "Epoch 222/400, Batch 33/45, Loss: 0.007910791784524918\n",
            "Epoch 222/400, Batch 34/45, Loss: 0.0311516672372818\n",
            "Epoch 222/400, Batch 35/45, Loss: 0.010409106500446796\n",
            "Epoch 222/400, Batch 36/45, Loss: 0.0029459286015480757\n",
            "Epoch 222/400, Batch 37/45, Loss: 0.012974961660802364\n",
            "Epoch 222/400, Batch 38/45, Loss: 0.06519508361816406\n",
            "Epoch 222/400, Batch 39/45, Loss: 0.008281951770186424\n",
            "Epoch 222/400, Batch 40/45, Loss: 0.014580685645341873\n",
            "Epoch 222/400, Batch 41/45, Loss: 0.012341469526290894\n",
            "Epoch 222/400, Batch 42/45, Loss: 0.026733912527561188\n",
            "Epoch 222/400, Batch 43/45, Loss: 0.031441256403923035\n",
            "Epoch 222/400, Batch 44/45, Loss: 0.029904121533036232\n",
            "Epoch 222/400, Batch 45/45, Loss: 0.013126354664564133\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.4905919916927814 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  223 , Time Elapsed:  177.10379664500553  mins\n",
            "Epoch 223/400, Batch 1/45, Loss: 0.013731454499065876\n",
            "Epoch 223/400, Batch 2/45, Loss: 0.04586871713399887\n",
            "Epoch 223/400, Batch 3/45, Loss: 0.025336753576993942\n",
            "Epoch 223/400, Batch 4/45, Loss: 0.011590557172894478\n",
            "Epoch 223/400, Batch 5/45, Loss: 0.006834010593593121\n",
            "Epoch 223/400, Batch 6/45, Loss: 0.05332855507731438\n",
            "Epoch 223/400, Batch 7/45, Loss: 0.023339450359344482\n",
            "Epoch 223/400, Batch 8/45, Loss: 0.04109644144773483\n",
            "Epoch 223/400, Batch 9/45, Loss: 0.028139138594269753\n",
            "Epoch 223/400, Batch 10/45, Loss: 0.03084919974207878\n",
            "Epoch 223/400, Batch 11/45, Loss: 0.011905249208211899\n",
            "Epoch 223/400, Batch 12/45, Loss: 0.03821489214897156\n",
            "Epoch 223/400, Batch 13/45, Loss: 0.05492695793509483\n",
            "Epoch 223/400, Batch 14/45, Loss: 0.005176527425646782\n",
            "Epoch 223/400, Batch 15/45, Loss: 0.02665201760828495\n",
            "Epoch 223/400, Batch 16/45, Loss: 0.054743822664022446\n",
            "Epoch 223/400, Batch 17/45, Loss: 0.021132854744791985\n",
            "Epoch 223/400, Batch 18/45, Loss: 0.04213261604309082\n",
            "Epoch 223/400, Batch 19/45, Loss: 0.015821922570466995\n",
            "Epoch 223/400, Batch 20/45, Loss: 0.0147714177146554\n",
            "Epoch 223/400, Batch 21/45, Loss: 0.015504496172070503\n",
            "Epoch 223/400, Batch 22/45, Loss: 0.007833993062376976\n",
            "Epoch 223/400, Batch 23/45, Loss: 0.02711401879787445\n",
            "Epoch 223/400, Batch 24/45, Loss: 0.014061982743442059\n",
            "Epoch 223/400, Batch 25/45, Loss: 0.018758457154035568\n",
            "Epoch 223/400, Batch 26/45, Loss: 0.010920601896941662\n",
            "Epoch 223/400, Batch 27/45, Loss: 0.028308790177106857\n",
            "Epoch 223/400, Batch 28/45, Loss: 0.020216427743434906\n",
            "Epoch 223/400, Batch 29/45, Loss: 0.014564558863639832\n",
            "Epoch 223/400, Batch 30/45, Loss: 0.04921744018793106\n",
            "Epoch 223/400, Batch 31/45, Loss: 0.011193491518497467\n",
            "Epoch 223/400, Batch 32/45, Loss: 0.010197192430496216\n",
            "Epoch 223/400, Batch 33/45, Loss: 0.017139369621872902\n",
            "Epoch 223/400, Batch 34/45, Loss: 0.018896376714110374\n",
            "Epoch 223/400, Batch 35/45, Loss: 0.02898956462740898\n",
            "Epoch 223/400, Batch 36/45, Loss: 0.016864662989974022\n",
            "Epoch 223/400, Batch 37/45, Loss: 0.03598945215344429\n",
            "Epoch 223/400, Batch 38/45, Loss: 0.034653302282094955\n",
            "Epoch 223/400, Batch 39/45, Loss: 0.032349877059459686\n",
            "Epoch 223/400, Batch 40/45, Loss: 0.0076941088773310184\n",
            "Epoch 223/400, Batch 41/45, Loss: 0.014189036563038826\n",
            "Epoch 223/400, Batch 42/45, Loss: 0.021428842097520828\n",
            "Epoch 223/400, Batch 43/45, Loss: 0.021034544333815575\n",
            "Epoch 223/400, Batch 44/45, Loss: 0.008139969781041145\n",
            "Epoch 223/400, Batch 45/45, Loss: 0.01147373579442501\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.4369576200842857 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  224 , Time Elapsed:  177.92861385345458  mins\n",
            "Epoch 224/400, Batch 1/45, Loss: 0.007075358647853136\n",
            "Epoch 224/400, Batch 2/45, Loss: 0.022075342014431953\n",
            "Epoch 224/400, Batch 3/45, Loss: 0.011238886043429375\n",
            "Epoch 224/400, Batch 4/45, Loss: 0.010878234170377254\n",
            "Epoch 224/400, Batch 5/45, Loss: 0.01131033431738615\n",
            "Epoch 224/400, Batch 6/45, Loss: 0.024372873827815056\n",
            "Epoch 224/400, Batch 7/45, Loss: 0.017221838235855103\n",
            "Epoch 224/400, Batch 8/45, Loss: 0.006694052834063768\n",
            "Epoch 224/400, Batch 9/45, Loss: 0.02789541706442833\n",
            "Epoch 224/400, Batch 10/45, Loss: 0.009930944070219994\n",
            "Epoch 224/400, Batch 11/45, Loss: 0.06638486683368683\n",
            "Epoch 224/400, Batch 12/45, Loss: 0.017387155443429947\n",
            "Epoch 224/400, Batch 13/45, Loss: 0.02129329927265644\n",
            "Epoch 224/400, Batch 14/45, Loss: 0.01549480203539133\n",
            "Epoch 224/400, Batch 15/45, Loss: 0.048830945044755936\n",
            "Epoch 224/400, Batch 16/45, Loss: 0.00459035811945796\n",
            "Epoch 224/400, Batch 17/45, Loss: 0.017728451639413834\n",
            "Epoch 224/400, Batch 18/45, Loss: 0.024246791377663612\n",
            "Epoch 224/400, Batch 19/45, Loss: 0.016820359975099564\n",
            "Epoch 224/400, Batch 20/45, Loss: 0.01365442294627428\n",
            "Epoch 224/400, Batch 21/45, Loss: 0.008449653163552284\n",
            "Epoch 224/400, Batch 22/45, Loss: 0.014307517558336258\n",
            "Epoch 224/400, Batch 23/45, Loss: 0.023628471419215202\n",
            "Epoch 224/400, Batch 24/45, Loss: 0.010911006480455399\n",
            "Epoch 224/400, Batch 25/45, Loss: 0.008028794080018997\n",
            "Epoch 224/400, Batch 26/45, Loss: 0.012392892502248287\n",
            "Epoch 224/400, Batch 27/45, Loss: 0.005273597780615091\n",
            "Epoch 224/400, Batch 28/45, Loss: 0.013275021687150002\n",
            "Epoch 224/400, Batch 29/45, Loss: 0.006631471682339907\n",
            "Epoch 224/400, Batch 30/45, Loss: 0.023111635819077492\n",
            "Epoch 224/400, Batch 31/45, Loss: 0.044626615941524506\n",
            "Epoch 224/400, Batch 32/45, Loss: 0.04987835884094238\n",
            "Epoch 224/400, Batch 33/45, Loss: 0.020919550210237503\n",
            "Epoch 224/400, Batch 34/45, Loss: 0.02759394608438015\n",
            "Epoch 224/400, Batch 35/45, Loss: 0.01703691855072975\n",
            "Epoch 224/400, Batch 36/45, Loss: 0.03032442182302475\n",
            "Epoch 224/400, Batch 37/45, Loss: 0.018167397007346153\n",
            "Epoch 224/400, Batch 38/45, Loss: 0.02112772688269615\n",
            "Epoch 224/400, Batch 39/45, Loss: 0.014511093497276306\n",
            "Epoch 224/400, Batch 40/45, Loss: 0.01892906054854393\n",
            "Epoch 224/400, Batch 41/45, Loss: 0.0209523756057024\n",
            "Epoch 224/400, Batch 42/45, Loss: 0.01769164763391018\n",
            "Epoch 224/400, Batch 43/45, Loss: 0.009800702333450317\n",
            "Epoch 224/400, Batch 44/45, Loss: 0.06563112139701843\n",
            "Epoch 224/400, Batch 45/45, Loss: 0.01719677448272705\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.524004004895687 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  225 , Time Elapsed:  178.71654092073442  mins\n",
            "Epoch 225/400, Batch 1/45, Loss: 0.012687739916145802\n",
            "Epoch 225/400, Batch 2/45, Loss: 0.016254574060440063\n",
            "Epoch 225/400, Batch 3/45, Loss: 0.011200914159417152\n",
            "Epoch 225/400, Batch 4/45, Loss: 0.01762470044195652\n",
            "Epoch 225/400, Batch 5/45, Loss: 0.013826906681060791\n",
            "Epoch 225/400, Batch 6/45, Loss: 0.011583943851292133\n",
            "Epoch 225/400, Batch 7/45, Loss: 0.016624854877591133\n",
            "Epoch 225/400, Batch 8/45, Loss: 0.012389468029141426\n",
            "Epoch 225/400, Batch 9/45, Loss: 0.01353251188993454\n",
            "Epoch 225/400, Batch 10/45, Loss: 0.014708414673805237\n",
            "Epoch 225/400, Batch 11/45, Loss: 0.040548939257860184\n",
            "Epoch 225/400, Batch 12/45, Loss: 0.02620098367333412\n",
            "Epoch 225/400, Batch 13/45, Loss: 0.017077403143048286\n",
            "Epoch 225/400, Batch 14/45, Loss: 0.008684419095516205\n",
            "Epoch 225/400, Batch 15/45, Loss: 0.021258529275655746\n",
            "Epoch 225/400, Batch 16/45, Loss: 0.012501344084739685\n",
            "Epoch 225/400, Batch 17/45, Loss: 0.01890774443745613\n",
            "Epoch 225/400, Batch 18/45, Loss: 0.0067739044316112995\n",
            "Epoch 225/400, Batch 19/45, Loss: 0.013208329677581787\n",
            "Epoch 225/400, Batch 20/45, Loss: 0.141971156001091\n",
            "Epoch 225/400, Batch 21/45, Loss: 0.01583443209528923\n",
            "Epoch 225/400, Batch 22/45, Loss: 0.015462277457118034\n",
            "Epoch 225/400, Batch 23/45, Loss: 0.01590503379702568\n",
            "Epoch 225/400, Batch 24/45, Loss: 0.022956714034080505\n",
            "Epoch 225/400, Batch 25/45, Loss: 0.02154579386115074\n",
            "Epoch 225/400, Batch 26/45, Loss: 0.03380724787712097\n",
            "Epoch 225/400, Batch 27/45, Loss: 0.005106458440423012\n",
            "Epoch 225/400, Batch 28/45, Loss: 0.007278005592525005\n",
            "Epoch 225/400, Batch 29/45, Loss: 0.009287628345191479\n",
            "Epoch 225/400, Batch 30/45, Loss: 0.014840653166174889\n",
            "Epoch 225/400, Batch 31/45, Loss: 0.008224498480558395\n",
            "Epoch 225/400, Batch 32/45, Loss: 0.018503092229366302\n",
            "Epoch 225/400, Batch 33/45, Loss: 0.024731386452913284\n",
            "Epoch 225/400, Batch 34/45, Loss: 0.022091172635555267\n",
            "Epoch 225/400, Batch 35/45, Loss: 0.006776526570320129\n",
            "Epoch 225/400, Batch 36/45, Loss: 0.020733926445245743\n",
            "Epoch 225/400, Batch 37/45, Loss: 0.012445029802620411\n",
            "Epoch 225/400, Batch 38/45, Loss: 0.014863425865769386\n",
            "Epoch 225/400, Batch 39/45, Loss: 0.006758231669664383\n",
            "Epoch 225/400, Batch 40/45, Loss: 0.026351895183324814\n",
            "Epoch 225/400, Batch 41/45, Loss: 0.008560016751289368\n",
            "Epoch 225/400, Batch 42/45, Loss: 0.015862474218010902\n",
            "Epoch 225/400, Batch 43/45, Loss: 0.021713580936193466\n",
            "Epoch 225/400, Batch 44/45, Loss: 0.009628284722566605\n",
            "Epoch 225/400, Batch 45/45, Loss: 0.030022092163562775\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.3411825187504292 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  226 , Time Elapsed:  179.50610080162684  mins\n",
            "Epoch 226/400, Batch 1/45, Loss: 0.01815032958984375\n",
            "Epoch 226/400, Batch 2/45, Loss: 0.016546528786420822\n",
            "Epoch 226/400, Batch 3/45, Loss: 0.012063697911798954\n",
            "Epoch 226/400, Batch 4/45, Loss: 0.016817031428217888\n",
            "Epoch 226/400, Batch 5/45, Loss: 0.018476422876119614\n",
            "Epoch 226/400, Batch 6/45, Loss: 0.013102555647492409\n",
            "Epoch 226/400, Batch 7/45, Loss: 0.029130101203918457\n",
            "Epoch 226/400, Batch 8/45, Loss: 0.01831110194325447\n",
            "Epoch 226/400, Batch 9/45, Loss: 0.004894838202744722\n",
            "Epoch 226/400, Batch 10/45, Loss: 0.030897561460733414\n",
            "Epoch 226/400, Batch 11/45, Loss: 0.01371685042977333\n",
            "Epoch 226/400, Batch 12/45, Loss: 0.018775541335344315\n",
            "Epoch 226/400, Batch 13/45, Loss: 0.011472917161881924\n",
            "Epoch 226/400, Batch 14/45, Loss: 0.01596403494477272\n",
            "Epoch 226/400, Batch 15/45, Loss: 0.004894217476248741\n",
            "Epoch 226/400, Batch 16/45, Loss: 0.011984268203377724\n",
            "Epoch 226/400, Batch 17/45, Loss: 0.029800938442349434\n",
            "Epoch 226/400, Batch 18/45, Loss: 0.015880905091762543\n",
            "Epoch 226/400, Batch 19/45, Loss: 0.05559774488210678\n",
            "Epoch 226/400, Batch 20/45, Loss: 0.03463423252105713\n",
            "Epoch 226/400, Batch 21/45, Loss: 0.012242849916219711\n",
            "Epoch 226/400, Batch 22/45, Loss: 0.004500393755733967\n",
            "Epoch 226/400, Batch 23/45, Loss: 0.02975505217909813\n",
            "Epoch 226/400, Batch 24/45, Loss: 0.008237370289862156\n",
            "Epoch 226/400, Batch 25/45, Loss: 0.03395463153719902\n",
            "Epoch 226/400, Batch 26/45, Loss: 0.061200156807899475\n",
            "Epoch 226/400, Batch 27/45, Loss: 0.033188171684741974\n",
            "Epoch 226/400, Batch 28/45, Loss: 0.028472935780882835\n",
            "Epoch 226/400, Batch 29/45, Loss: 0.008614188060164452\n",
            "Epoch 226/400, Batch 30/45, Loss: 0.025320298969745636\n",
            "Epoch 226/400, Batch 31/45, Loss: 0.01750744879245758\n",
            "Epoch 226/400, Batch 32/45, Loss: 0.02252865955233574\n",
            "Epoch 226/400, Batch 33/45, Loss: 0.04792457073926926\n",
            "Epoch 226/400, Batch 34/45, Loss: 0.014651458710432053\n",
            "Epoch 226/400, Batch 35/45, Loss: 0.018815159797668457\n",
            "Epoch 226/400, Batch 36/45, Loss: 0.012167412787675858\n",
            "Epoch 226/400, Batch 37/45, Loss: 0.15512129664421082\n",
            "Epoch 226/400, Batch 38/45, Loss: 0.06011967733502388\n",
            "Epoch 226/400, Batch 39/45, Loss: 0.03494194895029068\n",
            "Epoch 226/400, Batch 40/45, Loss: 0.016026435419917107\n",
            "Epoch 226/400, Batch 41/45, Loss: 0.023935692384839058\n",
            "Epoch 226/400, Batch 42/45, Loss: 0.005910506937652826\n",
            "Epoch 226/400, Batch 43/45, Loss: 0.032666150480508804\n",
            "Epoch 226/400, Batch 44/45, Loss: 0.033689893782138824\n",
            "Epoch 226/400, Batch 45/45, Loss: 0.019938288256525993\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.6749217994511127 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  227 , Time Elapsed:  180.2980514248212  mins\n",
            "Epoch 227/400, Batch 1/45, Loss: 0.01676230877637863\n",
            "Epoch 227/400, Batch 2/45, Loss: 0.0195429977029562\n",
            "Epoch 227/400, Batch 3/45, Loss: 0.005964776501059532\n",
            "Epoch 227/400, Batch 4/45, Loss: 0.02315324917435646\n",
            "Epoch 227/400, Batch 5/45, Loss: 0.006455013528466225\n",
            "Epoch 227/400, Batch 6/45, Loss: 0.024878598749637604\n",
            "Epoch 227/400, Batch 7/45, Loss: 0.022432878613471985\n",
            "Epoch 227/400, Batch 8/45, Loss: 0.004131876397877932\n",
            "Epoch 227/400, Batch 9/45, Loss: 0.012785936705768108\n",
            "Epoch 227/400, Batch 10/45, Loss: 0.012625841423869133\n",
            "Epoch 227/400, Batch 11/45, Loss: 0.015213724225759506\n",
            "Epoch 227/400, Batch 12/45, Loss: 0.019359998404979706\n",
            "Epoch 227/400, Batch 13/45, Loss: 0.01716379076242447\n",
            "Epoch 227/400, Batch 14/45, Loss: 0.005496628116816282\n",
            "Epoch 227/400, Batch 15/45, Loss: 0.019217772409319878\n",
            "Epoch 227/400, Batch 16/45, Loss: 0.014941956847906113\n",
            "Epoch 227/400, Batch 17/45, Loss: 0.01990653946995735\n",
            "Epoch 227/400, Batch 18/45, Loss: 0.0075156413950026035\n",
            "Epoch 227/400, Batch 19/45, Loss: 0.017059076577425003\n",
            "Epoch 227/400, Batch 20/45, Loss: 0.008404096588492393\n",
            "Epoch 227/400, Batch 21/45, Loss: 0.028448015451431274\n",
            "Epoch 227/400, Batch 22/45, Loss: 0.014747168868780136\n",
            "Epoch 227/400, Batch 23/45, Loss: 0.00770821887999773\n",
            "Epoch 227/400, Batch 24/45, Loss: 0.013891796581447124\n",
            "Epoch 227/400, Batch 25/45, Loss: 0.020702864974737167\n",
            "Epoch 227/400, Batch 26/45, Loss: 0.017583217471837997\n",
            "Epoch 227/400, Batch 27/45, Loss: 0.01756260171532631\n",
            "Epoch 227/400, Batch 28/45, Loss: 0.011690206825733185\n",
            "Epoch 227/400, Batch 29/45, Loss: 0.0059939040802419186\n",
            "Epoch 227/400, Batch 30/45, Loss: 0.019769985228776932\n",
            "Epoch 227/400, Batch 31/45, Loss: 0.026603087782859802\n",
            "Epoch 227/400, Batch 32/45, Loss: 0.017264239490032196\n",
            "Epoch 227/400, Batch 33/45, Loss: 0.0477040596306324\n",
            "Epoch 227/400, Batch 34/45, Loss: 0.013331713154911995\n",
            "Epoch 227/400, Batch 35/45, Loss: 0.010184084065258503\n",
            "Epoch 227/400, Batch 36/45, Loss: 0.002765258541330695\n",
            "Epoch 227/400, Batch 37/45, Loss: 0.011519135907292366\n",
            "Epoch 227/400, Batch 38/45, Loss: 0.018055791035294533\n",
            "Epoch 227/400, Batch 39/45, Loss: 0.018594948574900627\n",
            "Epoch 227/400, Batch 40/45, Loss: 0.00782982911914587\n",
            "Epoch 227/400, Batch 41/45, Loss: 0.02007012814283371\n",
            "Epoch 227/400, Batch 42/45, Loss: 0.009181894361972809\n",
            "Epoch 227/400, Batch 43/45, Loss: 0.02909860759973526\n",
            "Epoch 227/400, Batch 44/45, Loss: 0.0292789489030838\n",
            "Epoch 227/400, Batch 45/45, Loss: 0.017967941239476204\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.4203888848423958 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  228 , Time Elapsed:  181.08541228373846  mins\n",
            "Epoch 228/400, Batch 1/45, Loss: 0.008137935772538185\n",
            "Epoch 228/400, Batch 2/45, Loss: 0.005992066115140915\n",
            "Epoch 228/400, Batch 3/45, Loss: 0.034805167466402054\n",
            "Epoch 228/400, Batch 4/45, Loss: 0.008660037070512772\n",
            "Epoch 228/400, Batch 5/45, Loss: 0.013062842190265656\n",
            "Epoch 228/400, Batch 6/45, Loss: 0.011612077243626118\n",
            "Epoch 228/400, Batch 7/45, Loss: 0.0030537047423422337\n",
            "Epoch 228/400, Batch 8/45, Loss: 0.0029980922117829323\n",
            "Epoch 228/400, Batch 9/45, Loss: 0.017954660579562187\n",
            "Epoch 228/400, Batch 10/45, Loss: 0.01709042116999626\n",
            "Epoch 228/400, Batch 11/45, Loss: 0.010027483105659485\n",
            "Epoch 228/400, Batch 12/45, Loss: 0.005048307590186596\n",
            "Epoch 228/400, Batch 13/45, Loss: 0.007060566451400518\n",
            "Epoch 228/400, Batch 14/45, Loss: 0.0023597641848027706\n",
            "Epoch 228/400, Batch 15/45, Loss: 0.01707932911813259\n",
            "Epoch 228/400, Batch 16/45, Loss: 0.019205737859010696\n",
            "Epoch 228/400, Batch 17/45, Loss: 0.009342735633254051\n",
            "Epoch 228/400, Batch 18/45, Loss: 0.01903444156050682\n",
            "Epoch 228/400, Batch 19/45, Loss: 0.005610598251223564\n",
            "Epoch 228/400, Batch 20/45, Loss: 0.0023912638425827026\n",
            "Epoch 228/400, Batch 21/45, Loss: 0.018203523010015488\n",
            "Epoch 228/400, Batch 22/45, Loss: 0.013175198808312416\n",
            "Epoch 228/400, Batch 23/45, Loss: 0.010339269414544106\n",
            "Epoch 228/400, Batch 24/45, Loss: 0.022838879376649857\n",
            "Epoch 228/400, Batch 25/45, Loss: 0.018284112215042114\n",
            "Epoch 228/400, Batch 26/45, Loss: 0.021345380693674088\n",
            "Epoch 228/400, Batch 27/45, Loss: 0.012570764869451523\n",
            "Epoch 228/400, Batch 28/45, Loss: 0.0030634370632469654\n",
            "Epoch 228/400, Batch 29/45, Loss: 0.027793068438768387\n",
            "Epoch 228/400, Batch 30/45, Loss: 0.005249744281172752\n",
            "Epoch 228/400, Batch 31/45, Loss: 0.005582678597420454\n",
            "Epoch 228/400, Batch 32/45, Loss: 0.011126793920993805\n",
            "Epoch 228/400, Batch 33/45, Loss: 0.008287396281957626\n",
            "Epoch 228/400, Batch 34/45, Loss: 0.0052023837342858315\n",
            "Epoch 228/400, Batch 35/45, Loss: 0.010628214105963707\n",
            "Epoch 228/400, Batch 36/45, Loss: 0.007411394268274307\n",
            "Epoch 228/400, Batch 37/45, Loss: 0.01488800160586834\n",
            "Epoch 228/400, Batch 38/45, Loss: 0.02020290493965149\n",
            "Epoch 228/400, Batch 39/45, Loss: 0.008826450444757938\n",
            "Epoch 228/400, Batch 40/45, Loss: 0.020058128982782364\n",
            "Epoch 228/400, Batch 41/45, Loss: 0.007135872263461351\n",
            "Epoch 228/400, Batch 42/45, Loss: 0.026928750798106194\n",
            "Epoch 228/400, Batch 43/45, Loss: 0.011520336382091045\n",
            "Epoch 228/400, Batch 44/45, Loss: 0.010934141464531422\n",
            "Epoch 228/400, Batch 45/45, Loss: 0.027819383889436722\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.2275532186031342 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  229 , Time Elapsed:  181.91939917405446  mins\n",
            "Epoch 229/400, Batch 1/45, Loss: 0.015507468953728676\n",
            "Epoch 229/400, Batch 2/45, Loss: 0.023063544183969498\n",
            "Epoch 229/400, Batch 3/45, Loss: 0.008926186710596085\n",
            "Epoch 229/400, Batch 4/45, Loss: 0.01169507671147585\n",
            "Epoch 229/400, Batch 5/45, Loss: 0.00909470021724701\n",
            "Epoch 229/400, Batch 6/45, Loss: 0.009302442893385887\n",
            "Epoch 229/400, Batch 7/45, Loss: 0.008818909525871277\n",
            "Epoch 229/400, Batch 8/45, Loss: 0.019605688750743866\n",
            "Epoch 229/400, Batch 9/45, Loss: 0.02488194964826107\n",
            "Epoch 229/400, Batch 10/45, Loss: 0.007341132499277592\n",
            "Epoch 229/400, Batch 11/45, Loss: 0.02127089537680149\n",
            "Epoch 229/400, Batch 12/45, Loss: 0.019235650077462196\n",
            "Epoch 229/400, Batch 13/45, Loss: 0.018990855664014816\n",
            "Epoch 229/400, Batch 14/45, Loss: 0.030726833269000053\n",
            "Epoch 229/400, Batch 15/45, Loss: 0.016748346388339996\n",
            "Epoch 229/400, Batch 16/45, Loss: 0.009709644131362438\n",
            "Epoch 229/400, Batch 17/45, Loss: 0.004100309684872627\n",
            "Epoch 229/400, Batch 18/45, Loss: 0.016217518597841263\n",
            "Epoch 229/400, Batch 19/45, Loss: 0.008490478619933128\n",
            "Epoch 229/400, Batch 20/45, Loss: 0.01740712672472\n",
            "Epoch 229/400, Batch 21/45, Loss: 0.02799951657652855\n",
            "Epoch 229/400, Batch 22/45, Loss: 0.020570343360304832\n",
            "Epoch 229/400, Batch 23/45, Loss: 0.020650364458560944\n",
            "Epoch 229/400, Batch 24/45, Loss: 0.01885715126991272\n",
            "Epoch 229/400, Batch 25/45, Loss: 0.008052133023738861\n",
            "Epoch 229/400, Batch 26/45, Loss: 0.02376331016421318\n",
            "Epoch 229/400, Batch 27/45, Loss: 0.0032866504043340683\n",
            "Epoch 229/400, Batch 28/45, Loss: 0.008373286575078964\n",
            "Epoch 229/400, Batch 29/45, Loss: 0.01285578589886427\n",
            "Epoch 229/400, Batch 30/45, Loss: 0.006084517575800419\n",
            "Epoch 229/400, Batch 31/45, Loss: 0.014115173369646072\n",
            "Epoch 229/400, Batch 32/45, Loss: 0.010533208958804607\n",
            "Epoch 229/400, Batch 33/45, Loss: 0.030480828136205673\n",
            "Epoch 229/400, Batch 34/45, Loss: 0.009609082713723183\n",
            "Epoch 229/400, Batch 35/45, Loss: 0.00974668376147747\n",
            "Epoch 229/400, Batch 36/45, Loss: 0.04698575660586357\n",
            "Epoch 229/400, Batch 37/45, Loss: 0.025686409324407578\n",
            "Epoch 229/400, Batch 38/45, Loss: 0.011172055266797543\n",
            "Epoch 229/400, Batch 39/45, Loss: 0.014987951144576073\n",
            "Epoch 229/400, Batch 40/45, Loss: 0.01444670557975769\n",
            "Epoch 229/400, Batch 41/45, Loss: 0.010644730180501938\n",
            "Epoch 229/400, Batch 42/45, Loss: 0.010127611458301544\n",
            "Epoch 229/400, Batch 43/45, Loss: 0.011267833411693573\n",
            "Epoch 229/400, Batch 44/45, Loss: 0.020930197089910507\n",
            "Epoch 229/400, Batch 45/45, Loss: 0.039065390825271606\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.5148813501000404 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  230 , Time Elapsed:  182.70181545416514  mins\n",
            "Epoch 230/400, Batch 1/45, Loss: 0.09445890039205551\n",
            "Epoch 230/400, Batch 2/45, Loss: 0.0454142764210701\n",
            "Epoch 230/400, Batch 3/45, Loss: 0.01026767399162054\n",
            "Epoch 230/400, Batch 4/45, Loss: 0.015599321573972702\n",
            "Epoch 230/400, Batch 5/45, Loss: 0.015539527870714664\n",
            "Epoch 230/400, Batch 6/45, Loss: 0.01025842223316431\n",
            "Epoch 230/400, Batch 7/45, Loss: 0.045911312103271484\n",
            "Epoch 230/400, Batch 8/45, Loss: 0.02018376812338829\n",
            "Epoch 230/400, Batch 9/45, Loss: 0.028993912041187286\n",
            "Epoch 230/400, Batch 10/45, Loss: 0.014999382197856903\n",
            "Epoch 230/400, Batch 11/45, Loss: 0.0058023445308208466\n",
            "Epoch 230/400, Batch 12/45, Loss: 0.027344297617673874\n",
            "Epoch 230/400, Batch 13/45, Loss: 0.010316386818885803\n",
            "Epoch 230/400, Batch 14/45, Loss: 0.031261660158634186\n",
            "Epoch 230/400, Batch 15/45, Loss: 0.016116682440042496\n",
            "Epoch 230/400, Batch 16/45, Loss: 0.012273058295249939\n",
            "Epoch 230/400, Batch 17/45, Loss: 0.03820957988500595\n",
            "Epoch 230/400, Batch 18/45, Loss: 0.03027784638106823\n",
            "Epoch 230/400, Batch 19/45, Loss: 0.02213057316839695\n",
            "Epoch 230/400, Batch 20/45, Loss: 0.01910983957350254\n",
            "Epoch 230/400, Batch 21/45, Loss: 0.022622045129537582\n",
            "Epoch 230/400, Batch 22/45, Loss: 0.04129292070865631\n",
            "Epoch 230/400, Batch 23/45, Loss: 0.030365165323019028\n",
            "Epoch 230/400, Batch 24/45, Loss: 0.007943372242152691\n",
            "Epoch 230/400, Batch 25/45, Loss: 0.007145073264837265\n",
            "Epoch 230/400, Batch 26/45, Loss: 0.022143952548503876\n",
            "Epoch 230/400, Batch 27/45, Loss: 0.015234516933560371\n",
            "Epoch 230/400, Batch 28/45, Loss: 0.005169457755982876\n",
            "Epoch 230/400, Batch 29/45, Loss: 0.020940368995070457\n",
            "Epoch 230/400, Batch 30/45, Loss: 0.014380388893187046\n",
            "Epoch 230/400, Batch 31/45, Loss: 0.015847966074943542\n",
            "Epoch 230/400, Batch 32/45, Loss: 0.031062712892889977\n",
            "Epoch 230/400, Batch 33/45, Loss: 0.02894587814807892\n",
            "Epoch 230/400, Batch 34/45, Loss: 0.027234617620706558\n",
            "Epoch 230/400, Batch 35/45, Loss: 0.03985561430454254\n",
            "Epoch 230/400, Batch 36/45, Loss: 0.012193223461508751\n",
            "Epoch 230/400, Batch 37/45, Loss: 0.00794157013297081\n",
            "Epoch 230/400, Batch 38/45, Loss: 0.015574660152196884\n",
            "Epoch 230/400, Batch 39/45, Loss: 0.007804615423083305\n",
            "Epoch 230/400, Batch 40/45, Loss: 0.019781919196248055\n",
            "Epoch 230/400, Batch 41/45, Loss: 0.002574650337919593\n",
            "Epoch 230/400, Batch 42/45, Loss: 0.002408158965408802\n",
            "Epoch 230/400, Batch 43/45, Loss: 0.01785162463784218\n",
            "Epoch 230/400, Batch 44/45, Loss: 0.038623612374067307\n",
            "Epoch 230/400, Batch 45/45, Loss: 0.008388666436076164\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.2445792816579342 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  231 , Time Elapsed:  183.52287280956904  mins\n",
            "Epoch 231/400, Batch 1/45, Loss: 0.020382223650813103\n",
            "Epoch 231/400, Batch 2/45, Loss: 0.012107806280255318\n",
            "Epoch 231/400, Batch 3/45, Loss: 0.01837662234902382\n",
            "Epoch 231/400, Batch 4/45, Loss: 0.03123747557401657\n",
            "Epoch 231/400, Batch 5/45, Loss: 0.022598091512918472\n",
            "Epoch 231/400, Batch 6/45, Loss: 0.007556018885225058\n",
            "Epoch 231/400, Batch 7/45, Loss: 0.01009033340960741\n",
            "Epoch 231/400, Batch 8/45, Loss: 0.005733269266784191\n",
            "Epoch 231/400, Batch 9/45, Loss: 0.01625768095254898\n",
            "Epoch 231/400, Batch 10/45, Loss: 0.020915627479553223\n",
            "Epoch 231/400, Batch 11/45, Loss: 0.009795883670449257\n",
            "Epoch 231/400, Batch 12/45, Loss: 0.005949558224529028\n",
            "Epoch 231/400, Batch 13/45, Loss: 0.016153525561094284\n",
            "Epoch 231/400, Batch 14/45, Loss: 0.014989793300628662\n",
            "Epoch 231/400, Batch 15/45, Loss: 0.023788969963788986\n",
            "Epoch 231/400, Batch 16/45, Loss: 0.010909754782915115\n",
            "Epoch 231/400, Batch 17/45, Loss: 0.004272893536835909\n",
            "Epoch 231/400, Batch 18/45, Loss: 0.16094538569450378\n",
            "Epoch 231/400, Batch 19/45, Loss: 0.013484758324921131\n",
            "Epoch 231/400, Batch 20/45, Loss: 0.01763906329870224\n",
            "Epoch 231/400, Batch 21/45, Loss: 0.039550378918647766\n",
            "Epoch 231/400, Batch 22/45, Loss: 0.014498642645776272\n",
            "Epoch 231/400, Batch 23/45, Loss: 0.0055773621425032616\n",
            "Epoch 231/400, Batch 24/45, Loss: 0.035146452486515045\n",
            "Epoch 231/400, Batch 25/45, Loss: 0.036209411919116974\n",
            "Epoch 231/400, Batch 26/45, Loss: 0.05315727740526199\n",
            "Epoch 231/400, Batch 27/45, Loss: 0.05153561383485794\n",
            "Epoch 231/400, Batch 28/45, Loss: 0.021396152675151825\n",
            "Epoch 231/400, Batch 29/45, Loss: 0.012162506580352783\n",
            "Epoch 231/400, Batch 30/45, Loss: 0.01193284336477518\n",
            "Epoch 231/400, Batch 31/45, Loss: 0.03733198344707489\n",
            "Epoch 231/400, Batch 32/45, Loss: 0.04739511013031006\n",
            "Epoch 231/400, Batch 33/45, Loss: 0.012916307896375656\n",
            "Epoch 231/400, Batch 34/45, Loss: 0.042895250022411346\n",
            "Epoch 231/400, Batch 35/45, Loss: 0.008226176723837852\n",
            "Epoch 231/400, Batch 36/45, Loss: 0.011123980395495892\n",
            "Epoch 231/400, Batch 37/45, Loss: 0.014317646622657776\n",
            "Epoch 231/400, Batch 38/45, Loss: 0.04858113452792168\n",
            "Epoch 231/400, Batch 39/45, Loss: 0.007292102091014385\n",
            "Epoch 231/400, Batch 40/45, Loss: 0.021776502951979637\n",
            "Epoch 231/400, Batch 41/45, Loss: 0.02250349149107933\n",
            "Epoch 231/400, Batch 42/45, Loss: 0.015356943942606449\n",
            "Epoch 231/400, Batch 43/45, Loss: 0.013673949055373669\n",
            "Epoch 231/400, Batch 44/45, Loss: 0.02021399699151516\n",
            "Epoch 231/400, Batch 45/45, Loss: 0.028258610516786575\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.401308000087738 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  232 , Time Elapsed:  184.30582199891407  mins\n",
            "Epoch 232/400, Batch 1/45, Loss: 0.013534467667341232\n",
            "Epoch 232/400, Batch 2/45, Loss: 0.022372692823410034\n",
            "Epoch 232/400, Batch 3/45, Loss: 0.028642786666750908\n",
            "Epoch 232/400, Batch 4/45, Loss: 0.03079974465072155\n",
            "Epoch 232/400, Batch 5/45, Loss: 0.011643164791166782\n",
            "Epoch 232/400, Batch 6/45, Loss: 0.011661101132631302\n",
            "Epoch 232/400, Batch 7/45, Loss: 0.01842661201953888\n",
            "Epoch 232/400, Batch 8/45, Loss: 0.01277001854032278\n",
            "Epoch 232/400, Batch 9/45, Loss: 0.007129443343728781\n",
            "Epoch 232/400, Batch 10/45, Loss: 0.038376741111278534\n",
            "Epoch 232/400, Batch 11/45, Loss: 0.01221816148608923\n",
            "Epoch 232/400, Batch 12/45, Loss: 0.018396081402897835\n",
            "Epoch 232/400, Batch 13/45, Loss: 0.009258615784347057\n",
            "Epoch 232/400, Batch 14/45, Loss: 0.02113889902830124\n",
            "Epoch 232/400, Batch 15/45, Loss: 0.017396152019500732\n",
            "Epoch 232/400, Batch 16/45, Loss: 0.010711907409131527\n",
            "Epoch 232/400, Batch 17/45, Loss: 0.03783590719103813\n",
            "Epoch 232/400, Batch 18/45, Loss: 0.014743626117706299\n",
            "Epoch 232/400, Batch 19/45, Loss: 0.019259557127952576\n",
            "Epoch 232/400, Batch 20/45, Loss: 0.02735404670238495\n",
            "Epoch 232/400, Batch 21/45, Loss: 0.008520400151610374\n",
            "Epoch 232/400, Batch 22/45, Loss: 0.016713201999664307\n",
            "Epoch 232/400, Batch 23/45, Loss: 0.013576436787843704\n",
            "Epoch 232/400, Batch 24/45, Loss: 0.009569143876433372\n",
            "Epoch 232/400, Batch 25/45, Loss: 0.03887643665075302\n",
            "Epoch 232/400, Batch 26/45, Loss: 0.021302826702594757\n",
            "Epoch 232/400, Batch 27/45, Loss: 0.009470265358686447\n",
            "Epoch 232/400, Batch 28/45, Loss: 0.009003291837871075\n",
            "Epoch 232/400, Batch 29/45, Loss: 0.021070847287774086\n",
            "Epoch 232/400, Batch 30/45, Loss: 0.06318949162960052\n",
            "Epoch 232/400, Batch 31/45, Loss: 0.010156569071114063\n",
            "Epoch 232/400, Batch 32/45, Loss: 0.00428023049607873\n",
            "Epoch 232/400, Batch 33/45, Loss: 0.02204078622162342\n",
            "Epoch 232/400, Batch 34/45, Loss: 0.023472614586353302\n",
            "Epoch 232/400, Batch 35/45, Loss: 0.014586000703275204\n",
            "Epoch 232/400, Batch 36/45, Loss: 0.005591742694377899\n",
            "Epoch 232/400, Batch 37/45, Loss: 0.048235103487968445\n",
            "Epoch 232/400, Batch 38/45, Loss: 0.03618522360920906\n",
            "Epoch 232/400, Batch 39/45, Loss: 0.029724428430199623\n",
            "Epoch 232/400, Batch 40/45, Loss: 0.031487006694078445\n",
            "Epoch 232/400, Batch 41/45, Loss: 0.026985879987478256\n",
            "Epoch 232/400, Batch 42/45, Loss: 0.021544557064771652\n",
            "Epoch 232/400, Batch 43/45, Loss: 0.03497176244854927\n",
            "Epoch 232/400, Batch 44/45, Loss: 0.019091539084911346\n",
            "Epoch 232/400, Batch 45/45, Loss: 0.009997593238949776\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  2.3197462633252144 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  233 , Time Elapsed:  185.092522140344  mins\n",
            "Epoch 233/400, Batch 1/45, Loss: 0.013973645865917206\n",
            "Epoch 233/400, Batch 2/45, Loss: 0.023630782961845398\n",
            "Epoch 233/400, Batch 3/45, Loss: 0.012443401850759983\n",
            "Epoch 233/400, Batch 4/45, Loss: 0.019826771691441536\n",
            "Epoch 233/400, Batch 5/45, Loss: 0.008628088049590588\n",
            "Epoch 233/400, Batch 6/45, Loss: 0.01603017747402191\n",
            "Epoch 233/400, Batch 7/45, Loss: 0.008088361471891403\n",
            "Epoch 233/400, Batch 8/45, Loss: 0.008582592010498047\n",
            "Epoch 233/400, Batch 9/45, Loss: 0.02259219065308571\n",
            "Epoch 233/400, Batch 10/45, Loss: 0.031907230615615845\n",
            "Epoch 233/400, Batch 11/45, Loss: 0.0485842265188694\n",
            "Epoch 233/400, Batch 12/45, Loss: 0.006874057464301586\n",
            "Epoch 233/400, Batch 13/45, Loss: 0.014254486188292503\n",
            "Epoch 233/400, Batch 14/45, Loss: 0.009613684378564358\n",
            "Epoch 233/400, Batch 15/45, Loss: 0.00668678991496563\n",
            "Epoch 233/400, Batch 16/45, Loss: 0.014901213347911835\n",
            "Epoch 233/400, Batch 17/45, Loss: 0.009545532986521721\n",
            "Epoch 233/400, Batch 18/45, Loss: 0.022273169830441475\n",
            "Epoch 233/400, Batch 19/45, Loss: 0.18262189626693726\n",
            "Epoch 233/400, Batch 20/45, Loss: 0.01579722948372364\n",
            "Epoch 233/400, Batch 21/45, Loss: 0.021075986325740814\n",
            "Epoch 233/400, Batch 22/45, Loss: 0.020498445257544518\n",
            "Epoch 233/400, Batch 23/45, Loss: 0.024883370846509933\n",
            "Epoch 233/400, Batch 24/45, Loss: 0.019772600382566452\n",
            "Epoch 233/400, Batch 25/45, Loss: 0.009359965100884438\n",
            "Epoch 233/400, Batch 26/45, Loss: 0.018486347049474716\n",
            "Epoch 233/400, Batch 27/45, Loss: 0.02505931816995144\n",
            "Epoch 233/400, Batch 28/45, Loss: 0.016908297315239906\n",
            "Epoch 233/400, Batch 29/45, Loss: 0.03170909732580185\n",
            "Epoch 233/400, Batch 30/45, Loss: 0.008988686837255955\n",
            "Epoch 233/400, Batch 31/45, Loss: 0.013470484875142574\n",
            "Epoch 233/400, Batch 32/45, Loss: 0.028000669553875923\n",
            "Epoch 233/400, Batch 33/45, Loss: 0.024158213287591934\n",
            "Epoch 233/400, Batch 34/45, Loss: 0.04416271299123764\n",
            "Epoch 233/400, Batch 35/45, Loss: 0.004911838099360466\n",
            "Epoch 233/400, Batch 36/45, Loss: 0.014172207564115524\n",
            "Epoch 233/400, Batch 37/45, Loss: 0.00993567518889904\n",
            "Epoch 233/400, Batch 38/45, Loss: 0.04066864401102066\n",
            "Epoch 233/400, Batch 39/45, Loss: 0.07669611275196075\n",
            "Epoch 233/400, Batch 40/45, Loss: 0.01006865594536066\n",
            "Epoch 233/400, Batch 41/45, Loss: 0.012393035925924778\n",
            "Epoch 233/400, Batch 42/45, Loss: 0.06421531736850739\n",
            "Epoch 233/400, Batch 43/45, Loss: 0.018775157630443573\n",
            "Epoch 233/400, Batch 44/45, Loss: 0.059671223163604736\n",
            "Epoch 233/400, Batch 45/45, Loss: 0.07536051422357559\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.476347342133522 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  234 , Time Elapsed:  185.89113193750381  mins\n",
            "Epoch 234/400, Batch 1/45, Loss: 0.02960306406021118\n",
            "Epoch 234/400, Batch 2/45, Loss: 0.016270892694592476\n",
            "Epoch 234/400, Batch 3/45, Loss: 0.09989919513463974\n",
            "Epoch 234/400, Batch 4/45, Loss: 0.023323500528931618\n",
            "Epoch 234/400, Batch 5/45, Loss: 0.0209449864923954\n",
            "Epoch 234/400, Batch 6/45, Loss: 0.047059983015060425\n",
            "Epoch 234/400, Batch 7/45, Loss: 0.033227916806936264\n",
            "Epoch 234/400, Batch 8/45, Loss: 0.014088602736592293\n",
            "Epoch 234/400, Batch 9/45, Loss: 0.03061031550168991\n",
            "Epoch 234/400, Batch 10/45, Loss: 0.03103257343173027\n",
            "Epoch 234/400, Batch 11/45, Loss: 0.005114886909723282\n",
            "Epoch 234/400, Batch 12/45, Loss: 0.03720362111926079\n",
            "Epoch 234/400, Batch 13/45, Loss: 0.029584234580397606\n",
            "Epoch 234/400, Batch 14/45, Loss: 0.019096922129392624\n",
            "Epoch 234/400, Batch 15/45, Loss: 0.01698455773293972\n",
            "Epoch 234/400, Batch 16/45, Loss: 0.019842684268951416\n",
            "Epoch 234/400, Batch 17/45, Loss: 0.020380444824695587\n",
            "Epoch 234/400, Batch 18/45, Loss: 0.04025209695100784\n",
            "Epoch 234/400, Batch 19/45, Loss: 0.035409461706876755\n",
            "Epoch 234/400, Batch 20/45, Loss: 0.00537536246702075\n",
            "Epoch 234/400, Batch 21/45, Loss: 0.025538373738527298\n",
            "Epoch 234/400, Batch 22/45, Loss: 0.00851599033921957\n",
            "Epoch 234/400, Batch 23/45, Loss: 0.0241753738373518\n",
            "Epoch 234/400, Batch 24/45, Loss: 0.003470994997769594\n",
            "Epoch 234/400, Batch 25/45, Loss: 0.020675692707300186\n",
            "Epoch 234/400, Batch 26/45, Loss: 0.02137625962495804\n",
            "Epoch 234/400, Batch 27/45, Loss: 0.03918437287211418\n",
            "Epoch 234/400, Batch 28/45, Loss: 0.01706862263381481\n",
            "Epoch 234/400, Batch 29/45, Loss: 0.023083603009581566\n",
            "Epoch 234/400, Batch 30/45, Loss: 0.009829086251556873\n",
            "Epoch 234/400, Batch 31/45, Loss: 0.17951253056526184\n",
            "Epoch 234/400, Batch 32/45, Loss: 0.014159388840198517\n",
            "Epoch 234/400, Batch 33/45, Loss: 0.0056428611278533936\n",
            "Epoch 234/400, Batch 34/45, Loss: 0.013685749843716621\n",
            "Epoch 234/400, Batch 35/45, Loss: 0.03374791145324707\n",
            "Epoch 234/400, Batch 36/45, Loss: 0.0039869812317192554\n",
            "Epoch 234/400, Batch 37/45, Loss: 0.05505203455686569\n",
            "Epoch 234/400, Batch 38/45, Loss: 0.0016646909061819315\n",
            "Epoch 234/400, Batch 39/45, Loss: 0.0057998839765787125\n",
            "Epoch 234/400, Batch 40/45, Loss: 0.014582732692360878\n",
            "Epoch 234/400, Batch 41/45, Loss: 0.019970446825027466\n",
            "Epoch 234/400, Batch 42/45, Loss: 0.011728139594197273\n",
            "Epoch 234/400, Batch 43/45, Loss: 0.02377507835626602\n",
            "Epoch 234/400, Batch 44/45, Loss: 0.06781626492738724\n",
            "Epoch 234/400, Batch 45/45, Loss: 0.026926323771476746\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.3884801100939512 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  235 , Time Elapsed:  186.68094422022503  mins\n",
            "Epoch 235/400, Batch 1/45, Loss: 0.053101569414138794\n",
            "Epoch 235/400, Batch 2/45, Loss: 0.1281661093235016\n",
            "Epoch 235/400, Batch 3/45, Loss: 0.05048489570617676\n",
            "Epoch 235/400, Batch 4/45, Loss: 0.015747586265206337\n",
            "Epoch 235/400, Batch 5/45, Loss: 0.02693055383861065\n",
            "Epoch 235/400, Batch 6/45, Loss: 0.019510047510266304\n",
            "Epoch 235/400, Batch 7/45, Loss: 0.026772214099764824\n",
            "Epoch 235/400, Batch 8/45, Loss: 0.017697393894195557\n",
            "Epoch 235/400, Batch 9/45, Loss: 0.05011766403913498\n",
            "Epoch 235/400, Batch 10/45, Loss: 0.022866087034344673\n",
            "Epoch 235/400, Batch 11/45, Loss: 0.037734080106019974\n",
            "Epoch 235/400, Batch 12/45, Loss: 0.014675120823085308\n",
            "Epoch 235/400, Batch 13/45, Loss: 0.003922685980796814\n",
            "Epoch 235/400, Batch 14/45, Loss: 0.03651415556669235\n",
            "Epoch 235/400, Batch 15/45, Loss: 0.025278136134147644\n",
            "Epoch 235/400, Batch 16/45, Loss: 0.046250224113464355\n",
            "Epoch 235/400, Batch 17/45, Loss: 0.04177097603678703\n",
            "Epoch 235/400, Batch 18/45, Loss: 0.013633454218506813\n",
            "Epoch 235/400, Batch 19/45, Loss: 0.29603010416030884\n",
            "Epoch 235/400, Batch 20/45, Loss: 0.02136533334851265\n",
            "Epoch 235/400, Batch 21/45, Loss: 0.015288369730114937\n",
            "Epoch 235/400, Batch 22/45, Loss: 0.030893599614501\n",
            "Epoch 235/400, Batch 23/45, Loss: 0.05764390528202057\n",
            "Epoch 235/400, Batch 24/45, Loss: 0.06490321457386017\n",
            "Epoch 235/400, Batch 25/45, Loss: 0.10497502237558365\n",
            "Epoch 235/400, Batch 26/45, Loss: 0.10353216528892517\n",
            "Epoch 235/400, Batch 27/45, Loss: 0.0397045835852623\n",
            "Epoch 235/400, Batch 28/45, Loss: 0.02369324117898941\n",
            "Epoch 235/400, Batch 29/45, Loss: 0.02665466070175171\n",
            "Epoch 235/400, Batch 30/45, Loss: 0.015748079866170883\n",
            "Epoch 235/400, Batch 31/45, Loss: 0.031073573976755142\n",
            "Epoch 235/400, Batch 32/45, Loss: 0.024681665003299713\n",
            "Epoch 235/400, Batch 33/45, Loss: 0.029304489493370056\n",
            "Epoch 235/400, Batch 34/45, Loss: 0.02915237843990326\n",
            "Epoch 235/400, Batch 35/45, Loss: 0.1452060490846634\n",
            "Epoch 235/400, Batch 36/45, Loss: 0.018482252955436707\n",
            "Epoch 235/400, Batch 37/45, Loss: 0.011144651100039482\n",
            "Epoch 235/400, Batch 38/45, Loss: 0.027499588206410408\n",
            "Epoch 235/400, Batch 39/45, Loss: 0.014058984816074371\n",
            "Epoch 235/400, Batch 40/45, Loss: 0.008085405454039574\n",
            "Epoch 235/400, Batch 41/45, Loss: 0.027249937877058983\n",
            "Epoch 235/400, Batch 42/45, Loss: 0.03791694715619087\n",
            "Epoch 235/400, Batch 43/45, Loss: 0.027251485735177994\n",
            "Epoch 235/400, Batch 44/45, Loss: 0.008266976103186607\n",
            "Epoch 235/400, Batch 45/45, Loss: 0.024123303592205048\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.7537573985755444 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  236 , Time Elapsed:  187.48702792326608  mins\n",
            "Epoch 236/400, Batch 1/45, Loss: 0.03683532029390335\n",
            "Epoch 236/400, Batch 2/45, Loss: 0.010977277532219887\n",
            "Epoch 236/400, Batch 3/45, Loss: 0.05889569967985153\n",
            "Epoch 236/400, Batch 4/45, Loss: 0.03248952329158783\n",
            "Epoch 236/400, Batch 5/45, Loss: 0.05400202050805092\n",
            "Epoch 236/400, Batch 6/45, Loss: 0.08657798916101456\n",
            "Epoch 236/400, Batch 7/45, Loss: 0.030494041740894318\n",
            "Epoch 236/400, Batch 8/45, Loss: 0.012519516050815582\n",
            "Epoch 236/400, Batch 9/45, Loss: 0.027750341221690178\n",
            "Epoch 236/400, Batch 10/45, Loss: 0.034844860434532166\n",
            "Epoch 236/400, Batch 11/45, Loss: 0.046174220740795135\n",
            "Epoch 236/400, Batch 12/45, Loss: 0.15687546133995056\n",
            "Epoch 236/400, Batch 13/45, Loss: 0.04789912700653076\n",
            "Epoch 236/400, Batch 14/45, Loss: 0.0769229382276535\n",
            "Epoch 236/400, Batch 15/45, Loss: 0.029694287106394768\n",
            "Epoch 236/400, Batch 16/45, Loss: 0.021170329302549362\n",
            "Epoch 236/400, Batch 17/45, Loss: 0.028948545455932617\n",
            "Epoch 236/400, Batch 18/45, Loss: 0.039499469101428986\n",
            "Epoch 236/400, Batch 19/45, Loss: 0.04315130412578583\n",
            "Epoch 236/400, Batch 20/45, Loss: 0.023611385375261307\n",
            "Epoch 236/400, Batch 21/45, Loss: 0.04366888850927353\n",
            "Epoch 236/400, Batch 22/45, Loss: 0.05680455267429352\n",
            "Epoch 236/400, Batch 23/45, Loss: 0.021664747968316078\n",
            "Epoch 236/400, Batch 24/45, Loss: 0.018261311575770378\n",
            "Epoch 236/400, Batch 25/45, Loss: 0.04196513071656227\n",
            "Epoch 236/400, Batch 26/45, Loss: 0.0291457362473011\n",
            "Epoch 236/400, Batch 27/45, Loss: 0.0651298388838768\n",
            "Epoch 236/400, Batch 28/45, Loss: 0.04923015832901001\n",
            "Epoch 236/400, Batch 29/45, Loss: 0.040825020521879196\n",
            "Epoch 236/400, Batch 30/45, Loss: 0.01073426567018032\n",
            "Epoch 236/400, Batch 31/45, Loss: 0.014449803158640862\n",
            "Epoch 236/400, Batch 32/45, Loss: 0.02180330641567707\n",
            "Epoch 236/400, Batch 33/45, Loss: 0.03535355255007744\n",
            "Epoch 236/400, Batch 34/45, Loss: 0.018350739032030106\n",
            "Epoch 236/400, Batch 35/45, Loss: 0.019953422248363495\n",
            "Epoch 236/400, Batch 36/45, Loss: 0.01073434017598629\n",
            "Epoch 236/400, Batch 37/45, Loss: 0.09938060492277145\n",
            "Epoch 236/400, Batch 38/45, Loss: 0.005412713624536991\n",
            "Epoch 236/400, Batch 39/45, Loss: 0.01003715954720974\n",
            "Epoch 236/400, Batch 40/45, Loss: 0.008167016319930553\n",
            "Epoch 236/400, Batch 41/45, Loss: 0.024065429344773293\n",
            "Epoch 236/400, Batch 42/45, Loss: 0.02389783039689064\n",
            "Epoch 236/400, Batch 43/45, Loss: 0.009711169637739658\n",
            "Epoch 236/400, Batch 44/45, Loss: 0.01650523953139782\n",
            "Epoch 236/400, Batch 45/45, Loss: 0.014436391182243824\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.4332090839743614 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  237 , Time Elapsed:  188.27028501033783  mins\n",
            "Epoch 237/400, Batch 1/45, Loss: 0.02555798552930355\n",
            "Epoch 237/400, Batch 2/45, Loss: 0.024499721825122833\n",
            "Epoch 237/400, Batch 3/45, Loss: 0.014346759766340256\n",
            "Epoch 237/400, Batch 4/45, Loss: 0.027279000729322433\n",
            "Epoch 237/400, Batch 5/45, Loss: 0.02546311728656292\n",
            "Epoch 237/400, Batch 6/45, Loss: 0.022468622773885727\n",
            "Epoch 237/400, Batch 7/45, Loss: 0.016206758096814156\n",
            "Epoch 237/400, Batch 8/45, Loss: 0.018945537507534027\n",
            "Epoch 237/400, Batch 9/45, Loss: 0.010781792923808098\n",
            "Epoch 237/400, Batch 10/45, Loss: 0.00859730876982212\n",
            "Epoch 237/400, Batch 11/45, Loss: 0.008025451563298702\n",
            "Epoch 237/400, Batch 12/45, Loss: 0.010129597969353199\n",
            "Epoch 237/400, Batch 13/45, Loss: 0.019245415925979614\n",
            "Epoch 237/400, Batch 14/45, Loss: 0.022071612998843193\n",
            "Epoch 237/400, Batch 15/45, Loss: 0.005023621954023838\n",
            "Epoch 237/400, Batch 16/45, Loss: 0.015399611555039883\n",
            "Epoch 237/400, Batch 17/45, Loss: 0.026256900280714035\n",
            "Epoch 237/400, Batch 18/45, Loss: 0.032717302441596985\n",
            "Epoch 237/400, Batch 19/45, Loss: 0.011117585003376007\n",
            "Epoch 237/400, Batch 20/45, Loss: 0.01769421622157097\n",
            "Epoch 237/400, Batch 21/45, Loss: 0.05823230370879173\n",
            "Epoch 237/400, Batch 22/45, Loss: 0.015056467615067959\n",
            "Epoch 237/400, Batch 23/45, Loss: 0.04061904922127724\n",
            "Epoch 237/400, Batch 24/45, Loss: 0.033831097185611725\n",
            "Epoch 237/400, Batch 25/45, Loss: 0.010180030949413776\n",
            "Epoch 237/400, Batch 26/45, Loss: 0.015454735606908798\n",
            "Epoch 237/400, Batch 27/45, Loss: 0.01112380065023899\n",
            "Epoch 237/400, Batch 28/45, Loss: 0.030873339623212814\n",
            "Epoch 237/400, Batch 29/45, Loss: 0.016755372285842896\n",
            "Epoch 237/400, Batch 30/45, Loss: 0.01304433960467577\n",
            "Epoch 237/400, Batch 31/45, Loss: 0.03182085230946541\n",
            "Epoch 237/400, Batch 32/45, Loss: 0.06217913329601288\n",
            "Epoch 237/400, Batch 33/45, Loss: 0.02165791392326355\n",
            "Epoch 237/400, Batch 34/45, Loss: 0.010283091105520725\n",
            "Epoch 237/400, Batch 35/45, Loss: 0.019223209470510483\n",
            "Epoch 237/400, Batch 36/45, Loss: 0.005506481509655714\n",
            "Epoch 237/400, Batch 37/45, Loss: 0.005255577154457569\n",
            "Epoch 237/400, Batch 38/45, Loss: 0.024018017575144768\n",
            "Epoch 237/400, Batch 39/45, Loss: 0.01638600416481495\n",
            "Epoch 237/400, Batch 40/45, Loss: 0.004761054180562496\n",
            "Epoch 237/400, Batch 41/45, Loss: 0.019878335297107697\n",
            "Epoch 237/400, Batch 42/45, Loss: 0.02183420956134796\n",
            "Epoch 237/400, Batch 43/45, Loss: 0.04670865461230278\n",
            "Epoch 237/400, Batch 44/45, Loss: 0.021910879760980606\n",
            "Epoch 237/400, Batch 45/45, Loss: 0.03529626131057739\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.1376830320805311 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  238 , Time Elapsed:  189.09268039862314  mins\n",
            "Epoch 238/400, Batch 1/45, Loss: 0.014067134819924831\n",
            "Epoch 238/400, Batch 2/45, Loss: 0.013659903779625893\n",
            "Epoch 238/400, Batch 3/45, Loss: 0.07595620304346085\n",
            "Epoch 238/400, Batch 4/45, Loss: 0.00841225404292345\n",
            "Epoch 238/400, Batch 5/45, Loss: 0.013691200874745846\n",
            "Epoch 238/400, Batch 6/45, Loss: 0.004502352327108383\n",
            "Epoch 238/400, Batch 7/45, Loss: 0.02081456407904625\n",
            "Epoch 238/400, Batch 8/45, Loss: 0.006344609893858433\n",
            "Epoch 238/400, Batch 9/45, Loss: 0.01167803630232811\n",
            "Epoch 238/400, Batch 10/45, Loss: 0.01840875670313835\n",
            "Epoch 238/400, Batch 11/45, Loss: 0.008929271250963211\n",
            "Epoch 238/400, Batch 12/45, Loss: 0.018628038465976715\n",
            "Epoch 238/400, Batch 13/45, Loss: 0.01249536219984293\n",
            "Epoch 238/400, Batch 14/45, Loss: 0.005532492883503437\n",
            "Epoch 238/400, Batch 15/45, Loss: 0.005171626806259155\n",
            "Epoch 238/400, Batch 16/45, Loss: 0.05729828029870987\n",
            "Epoch 238/400, Batch 17/45, Loss: 0.02222049981355667\n",
            "Epoch 238/400, Batch 18/45, Loss: 0.013300169259309769\n",
            "Epoch 238/400, Batch 19/45, Loss: 0.12554946541786194\n",
            "Epoch 238/400, Batch 20/45, Loss: 0.022957023233175278\n",
            "Epoch 238/400, Batch 21/45, Loss: 0.011038495227694511\n",
            "Epoch 238/400, Batch 22/45, Loss: 0.01299753226339817\n",
            "Epoch 238/400, Batch 23/45, Loss: 0.009800286963582039\n",
            "Epoch 238/400, Batch 24/45, Loss: 0.0029284099582582712\n",
            "Epoch 238/400, Batch 25/45, Loss: 0.007006666623055935\n",
            "Epoch 238/400, Batch 26/45, Loss: 0.012084851041436195\n",
            "Epoch 238/400, Batch 27/45, Loss: 0.00310177868232131\n",
            "Epoch 238/400, Batch 28/45, Loss: 0.007361436728388071\n",
            "Epoch 238/400, Batch 29/45, Loss: 0.008768404833972454\n",
            "Epoch 238/400, Batch 30/45, Loss: 0.026372719556093216\n",
            "Epoch 238/400, Batch 31/45, Loss: 0.013402803801000118\n",
            "Epoch 238/400, Batch 32/45, Loss: 0.03483805060386658\n",
            "Epoch 238/400, Batch 33/45, Loss: 0.02543739229440689\n",
            "Epoch 238/400, Batch 34/45, Loss: 0.00820334255695343\n",
            "Epoch 238/400, Batch 35/45, Loss: 0.012709390372037888\n",
            "Epoch 238/400, Batch 36/45, Loss: 0.004513745661824942\n",
            "Epoch 238/400, Batch 37/45, Loss: 0.014904225245118141\n",
            "Epoch 238/400, Batch 38/45, Loss: 0.0242936871945858\n",
            "Epoch 238/400, Batch 39/45, Loss: 0.01811228133738041\n",
            "Epoch 238/400, Batch 40/45, Loss: 0.024687886238098145\n",
            "Epoch 238/400, Batch 41/45, Loss: 0.07393896579742432\n",
            "Epoch 238/400, Batch 42/45, Loss: 0.02116483263671398\n",
            "Epoch 238/400, Batch 43/45, Loss: 0.02010197378695011\n",
            "Epoch 238/400, Batch 44/45, Loss: 0.034782979637384415\n",
            "Epoch 238/400, Batch 45/45, Loss: 0.025685736909508705\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.4443060755729675 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  239 , Time Elapsed:  189.87678214708964  mins\n",
            "Epoch 239/400, Batch 1/45, Loss: 0.05269649624824524\n",
            "Epoch 239/400, Batch 2/45, Loss: 0.012433835305273533\n",
            "Epoch 239/400, Batch 3/45, Loss: 0.005327163729816675\n",
            "Epoch 239/400, Batch 4/45, Loss: 0.00489942729473114\n",
            "Epoch 239/400, Batch 5/45, Loss: 0.017376631498336792\n",
            "Epoch 239/400, Batch 6/45, Loss: 0.009498897939920425\n",
            "Epoch 239/400, Batch 7/45, Loss: 0.048537518829107285\n",
            "Epoch 239/400, Batch 8/45, Loss: 0.006197615060955286\n",
            "Epoch 239/400, Batch 9/45, Loss: 0.01490158773958683\n",
            "Epoch 239/400, Batch 10/45, Loss: 0.03315574675798416\n",
            "Epoch 239/400, Batch 11/45, Loss: 0.020418327301740646\n",
            "Epoch 239/400, Batch 12/45, Loss: 0.0040969811379909515\n",
            "Epoch 239/400, Batch 13/45, Loss: 0.00573220569640398\n",
            "Epoch 239/400, Batch 14/45, Loss: 0.021972423419356346\n",
            "Epoch 239/400, Batch 15/45, Loss: 0.004211007617413998\n",
            "Epoch 239/400, Batch 16/45, Loss: 0.018151788040995598\n",
            "Epoch 239/400, Batch 17/45, Loss: 0.01560491044074297\n",
            "Epoch 239/400, Batch 18/45, Loss: 0.0417502261698246\n",
            "Epoch 239/400, Batch 19/45, Loss: 0.007580330595374107\n",
            "Epoch 239/400, Batch 20/45, Loss: 0.006182316690683365\n",
            "Epoch 239/400, Batch 21/45, Loss: 0.010957224294543266\n",
            "Epoch 239/400, Batch 22/45, Loss: 0.011625537648797035\n",
            "Epoch 239/400, Batch 23/45, Loss: 0.03522321581840515\n",
            "Epoch 239/400, Batch 24/45, Loss: 0.016466883942484856\n",
            "Epoch 239/400, Batch 25/45, Loss: 0.004429209977388382\n",
            "Epoch 239/400, Batch 26/45, Loss: 0.12465055286884308\n",
            "Epoch 239/400, Batch 27/45, Loss: 0.02538205310702324\n",
            "Epoch 239/400, Batch 28/45, Loss: 0.028405947610735893\n",
            "Epoch 239/400, Batch 29/45, Loss: 0.028014421463012695\n",
            "Epoch 239/400, Batch 30/45, Loss: 0.034773439168930054\n",
            "Epoch 239/400, Batch 31/45, Loss: 0.017967458814382553\n",
            "Epoch 239/400, Batch 32/45, Loss: 0.010306444019079208\n",
            "Epoch 239/400, Batch 33/45, Loss: 0.020745709538459778\n",
            "Epoch 239/400, Batch 34/45, Loss: 0.01380203478038311\n",
            "Epoch 239/400, Batch 35/45, Loss: 0.016016334295272827\n",
            "Epoch 239/400, Batch 36/45, Loss: 0.01441008411347866\n",
            "Epoch 239/400, Batch 37/45, Loss: 0.02862430177628994\n",
            "Epoch 239/400, Batch 38/45, Loss: 0.011067958548665047\n",
            "Epoch 239/400, Batch 39/45, Loss: 0.027855541557073593\n",
            "Epoch 239/400, Batch 40/45, Loss: 0.012142227962613106\n",
            "Epoch 239/400, Batch 41/45, Loss: 0.014022557064890862\n",
            "Epoch 239/400, Batch 42/45, Loss: 0.03830863535404205\n",
            "Epoch 239/400, Batch 43/45, Loss: 0.02889583632349968\n",
            "Epoch 239/400, Batch 44/45, Loss: 0.013468493707478046\n",
            "Epoch 239/400, Batch 45/45, Loss: 0.005303625948727131\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.4256676584482193 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  240 , Time Elapsed:  190.67393596569698  mins\n",
            "Epoch 240/400, Batch 1/45, Loss: 0.013755802996456623\n",
            "Epoch 240/400, Batch 2/45, Loss: 0.036736197769641876\n",
            "Epoch 240/400, Batch 3/45, Loss: 0.01601598411798477\n",
            "Epoch 240/400, Batch 4/45, Loss: 0.03186599910259247\n",
            "Epoch 240/400, Batch 5/45, Loss: 0.023720495402812958\n",
            "Epoch 240/400, Batch 6/45, Loss: 0.018295614048838615\n",
            "Epoch 240/400, Batch 7/45, Loss: 0.007450585253536701\n",
            "Epoch 240/400, Batch 8/45, Loss: 0.030855264514684677\n",
            "Epoch 240/400, Batch 9/45, Loss: 0.01961258426308632\n",
            "Epoch 240/400, Batch 10/45, Loss: 0.045058563351631165\n",
            "Epoch 240/400, Batch 11/45, Loss: 0.014028345234692097\n",
            "Epoch 240/400, Batch 12/45, Loss: 0.023995589464902878\n",
            "Epoch 240/400, Batch 13/45, Loss: 0.02903924137353897\n",
            "Epoch 240/400, Batch 14/45, Loss: 0.004684144165366888\n",
            "Epoch 240/400, Batch 15/45, Loss: 0.017105840146541595\n",
            "Epoch 240/400, Batch 16/45, Loss: 0.010474978014826775\n",
            "Epoch 240/400, Batch 17/45, Loss: 0.026810280978679657\n",
            "Epoch 240/400, Batch 18/45, Loss: 0.04031141847372055\n",
            "Epoch 240/400, Batch 19/45, Loss: 0.06576820462942123\n",
            "Epoch 240/400, Batch 20/45, Loss: 0.015537610277533531\n",
            "Epoch 240/400, Batch 21/45, Loss: 0.003233581315726042\n",
            "Epoch 240/400, Batch 22/45, Loss: 0.0029310607351362705\n",
            "Epoch 240/400, Batch 23/45, Loss: 0.021145522594451904\n",
            "Epoch 240/400, Batch 24/45, Loss: 0.02044576406478882\n",
            "Epoch 240/400, Batch 25/45, Loss: 0.010234184563159943\n",
            "Epoch 240/400, Batch 26/45, Loss: 0.027812091633677483\n",
            "Epoch 240/400, Batch 27/45, Loss: 0.016966652125120163\n",
            "Epoch 240/400, Batch 28/45, Loss: 0.0041773575358092785\n",
            "Epoch 240/400, Batch 29/45, Loss: 0.009781068190932274\n",
            "Epoch 240/400, Batch 30/45, Loss: 0.009617632254958153\n",
            "Epoch 240/400, Batch 31/45, Loss: 0.2351471185684204\n",
            "Epoch 240/400, Batch 32/45, Loss: 0.008962828665971756\n",
            "Epoch 240/400, Batch 33/45, Loss: 0.021239373832941055\n",
            "Epoch 240/400, Batch 34/45, Loss: 0.02294982224702835\n",
            "Epoch 240/400, Batch 35/45, Loss: 0.006262906827032566\n",
            "Epoch 240/400, Batch 36/45, Loss: 0.007483688183128834\n",
            "Epoch 240/400, Batch 37/45, Loss: 0.01524338684976101\n",
            "Epoch 240/400, Batch 38/45, Loss: 0.03501521795988083\n",
            "Epoch 240/400, Batch 39/45, Loss: 0.02972542867064476\n",
            "Epoch 240/400, Batch 40/45, Loss: 0.017862888053059578\n",
            "Epoch 240/400, Batch 41/45, Loss: 0.022540125995874405\n",
            "Epoch 240/400, Batch 42/45, Loss: 0.01109648123383522\n",
            "Epoch 240/400, Batch 43/45, Loss: 0.01487198006361723\n",
            "Epoch 240/400, Batch 44/45, Loss: 0.022213255986571312\n",
            "Epoch 240/400, Batch 45/45, Loss: 0.06967277824878693\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.8141456097364426 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  241 , Time Elapsed:  191.45782112677892  mins\n",
            "Epoch 241/400, Batch 1/45, Loss: 0.015020880848169327\n",
            "Epoch 241/400, Batch 2/45, Loss: 0.016931969672441483\n",
            "Epoch 241/400, Batch 3/45, Loss: 0.026741787791252136\n",
            "Epoch 241/400, Batch 4/45, Loss: 0.0593998059630394\n",
            "Epoch 241/400, Batch 5/45, Loss: 0.0262768492102623\n",
            "Epoch 241/400, Batch 6/45, Loss: 0.017733082175254822\n",
            "Epoch 241/400, Batch 7/45, Loss: 0.016395539045333862\n",
            "Epoch 241/400, Batch 8/45, Loss: 0.008879592642188072\n",
            "Epoch 241/400, Batch 9/45, Loss: 0.013484423980116844\n",
            "Epoch 241/400, Batch 10/45, Loss: 0.03087545372545719\n",
            "Epoch 241/400, Batch 11/45, Loss: 0.024768570438027382\n",
            "Epoch 241/400, Batch 12/45, Loss: 0.051327429711818695\n",
            "Epoch 241/400, Batch 13/45, Loss: 0.019427450373768806\n",
            "Epoch 241/400, Batch 14/45, Loss: 0.09890033304691315\n",
            "Epoch 241/400, Batch 15/45, Loss: 0.025505732744932175\n",
            "Epoch 241/400, Batch 16/45, Loss: 0.009585359133780003\n",
            "Epoch 241/400, Batch 17/45, Loss: 0.02033963054418564\n",
            "Epoch 241/400, Batch 18/45, Loss: 0.00836259126663208\n",
            "Epoch 241/400, Batch 19/45, Loss: 0.032543350011110306\n",
            "Epoch 241/400, Batch 20/45, Loss: 0.006349534261971712\n",
            "Epoch 241/400, Batch 21/45, Loss: 0.004062306601554155\n",
            "Epoch 241/400, Batch 22/45, Loss: 0.010361827909946442\n",
            "Epoch 241/400, Batch 23/45, Loss: 0.006091608200222254\n",
            "Epoch 241/400, Batch 24/45, Loss: 0.023020025342702866\n",
            "Epoch 241/400, Batch 25/45, Loss: 0.015067391097545624\n",
            "Epoch 241/400, Batch 26/45, Loss: 0.01298604253679514\n",
            "Epoch 241/400, Batch 27/45, Loss: 0.009931249544024467\n",
            "Epoch 241/400, Batch 28/45, Loss: 0.008905481547117233\n",
            "Epoch 241/400, Batch 29/45, Loss: 0.012924838811159134\n",
            "Epoch 241/400, Batch 30/45, Loss: 0.06730225682258606\n",
            "Epoch 241/400, Batch 31/45, Loss: 0.008625577203929424\n",
            "Epoch 241/400, Batch 32/45, Loss: 0.014581447467207909\n",
            "Epoch 241/400, Batch 33/45, Loss: 0.012851297855377197\n",
            "Epoch 241/400, Batch 34/45, Loss: 0.002903268439695239\n",
            "Epoch 241/400, Batch 35/45, Loss: 0.021889127790927887\n",
            "Epoch 241/400, Batch 36/45, Loss: 0.008524015545845032\n",
            "Epoch 241/400, Batch 37/45, Loss: 0.03240783512592316\n",
            "Epoch 241/400, Batch 38/45, Loss: 0.029232952743768692\n",
            "Epoch 241/400, Batch 39/45, Loss: 0.02884870581328869\n",
            "Epoch 241/400, Batch 40/45, Loss: 0.017607033252716064\n",
            "Epoch 241/400, Batch 41/45, Loss: 0.006814621388912201\n",
            "Epoch 241/400, Batch 42/45, Loss: 0.005041919182986021\n",
            "Epoch 241/400, Batch 43/45, Loss: 0.008727332577109337\n",
            "Epoch 241/400, Batch 44/45, Loss: 0.05071615055203438\n",
            "Epoch 241/400, Batch 45/45, Loss: 0.012016447260975838\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.6220416091382504 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  242 , Time Elapsed:  192.24253044128417  mins\n",
            "Epoch 242/400, Batch 1/45, Loss: 0.012663071043789387\n",
            "Epoch 242/400, Batch 2/45, Loss: 0.011224301531910896\n",
            "Epoch 242/400, Batch 3/45, Loss: 0.08954820036888123\n",
            "Epoch 242/400, Batch 4/45, Loss: 0.009632900357246399\n",
            "Epoch 242/400, Batch 5/45, Loss: 0.022297045215964317\n",
            "Epoch 242/400, Batch 6/45, Loss: 0.007471088320016861\n",
            "Epoch 242/400, Batch 7/45, Loss: 0.013810398988425732\n",
            "Epoch 242/400, Batch 8/45, Loss: 0.02154415100812912\n",
            "Epoch 242/400, Batch 9/45, Loss: 0.016109010204672813\n",
            "Epoch 242/400, Batch 10/45, Loss: 0.011487436480820179\n",
            "Epoch 242/400, Batch 11/45, Loss: 0.022661153227090836\n",
            "Epoch 242/400, Batch 12/45, Loss: 0.006740390323102474\n",
            "Epoch 242/400, Batch 13/45, Loss: 0.0059893629513680935\n",
            "Epoch 242/400, Batch 14/45, Loss: 0.010181239806115627\n",
            "Epoch 242/400, Batch 15/45, Loss: 0.02153126522898674\n",
            "Epoch 242/400, Batch 16/45, Loss: 0.010216869413852692\n",
            "Epoch 242/400, Batch 17/45, Loss: 0.008065947331488132\n",
            "Epoch 242/400, Batch 18/45, Loss: 0.01564551331102848\n",
            "Epoch 242/400, Batch 19/45, Loss: 0.0059786452911794186\n",
            "Epoch 242/400, Batch 20/45, Loss: 0.008183857426047325\n",
            "Epoch 242/400, Batch 21/45, Loss: 0.007102590054273605\n",
            "Epoch 242/400, Batch 22/45, Loss: 0.012019705958664417\n",
            "Epoch 242/400, Batch 23/45, Loss: 0.006886359304189682\n",
            "Epoch 242/400, Batch 24/45, Loss: 0.017172597348690033\n",
            "Epoch 242/400, Batch 25/45, Loss: 0.025385793298482895\n",
            "Epoch 242/400, Batch 26/45, Loss: 0.013673864305019379\n",
            "Epoch 242/400, Batch 27/45, Loss: 0.013327278196811676\n",
            "Epoch 242/400, Batch 28/45, Loss: 0.012783548794686794\n",
            "Epoch 242/400, Batch 29/45, Loss: 0.009992662817239761\n",
            "Epoch 242/400, Batch 30/45, Loss: 0.009248445741832256\n",
            "Epoch 242/400, Batch 31/45, Loss: 0.01574278250336647\n",
            "Epoch 242/400, Batch 32/45, Loss: 0.02380518615245819\n",
            "Epoch 242/400, Batch 33/45, Loss: 0.017094841226935387\n",
            "Epoch 242/400, Batch 34/45, Loss: 0.008346510119736195\n",
            "Epoch 242/400, Batch 35/45, Loss: 0.016558056697249413\n",
            "Epoch 242/400, Batch 36/45, Loss: 0.03024408221244812\n",
            "Epoch 242/400, Batch 37/45, Loss: 0.06325462460517883\n",
            "Epoch 242/400, Batch 38/45, Loss: 0.020700421184301376\n",
            "Epoch 242/400, Batch 39/45, Loss: 0.019870340824127197\n",
            "Epoch 242/400, Batch 40/45, Loss: 0.005838828161358833\n",
            "Epoch 242/400, Batch 41/45, Loss: 0.016134370118379593\n",
            "Epoch 242/400, Batch 42/45, Loss: 0.007440813817083836\n",
            "Epoch 242/400, Batch 43/45, Loss: 0.030252328142523766\n",
            "Epoch 242/400, Batch 44/45, Loss: 0.010751591995358467\n",
            "Epoch 242/400, Batch 45/45, Loss: 0.024150243028998375\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.4061024338006973 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  243 , Time Elapsed:  193.0504251797994  mins\n",
            "Epoch 243/400, Batch 1/45, Loss: 0.016887791454792023\n",
            "Epoch 243/400, Batch 2/45, Loss: 0.017618265002965927\n",
            "Epoch 243/400, Batch 3/45, Loss: 0.0060822684317827225\n",
            "Epoch 243/400, Batch 4/45, Loss: 0.016041606664657593\n",
            "Epoch 243/400, Batch 5/45, Loss: 0.007097290363162756\n",
            "Epoch 243/400, Batch 6/45, Loss: 0.01071056816726923\n",
            "Epoch 243/400, Batch 7/45, Loss: 0.015534428879618645\n",
            "Epoch 243/400, Batch 8/45, Loss: 0.006479046307504177\n",
            "Epoch 243/400, Batch 9/45, Loss: 0.018832610920071602\n",
            "Epoch 243/400, Batch 10/45, Loss: 0.0028108784463256598\n",
            "Epoch 243/400, Batch 11/45, Loss: 0.017543315887451172\n",
            "Epoch 243/400, Batch 12/45, Loss: 0.013487497344613075\n",
            "Epoch 243/400, Batch 13/45, Loss: 0.032135605812072754\n",
            "Epoch 243/400, Batch 14/45, Loss: 0.028818193823099136\n",
            "Epoch 243/400, Batch 15/45, Loss: 0.005333710461854935\n",
            "Epoch 243/400, Batch 16/45, Loss: 0.006217441521584988\n",
            "Epoch 243/400, Batch 17/45, Loss: 0.008894355036318302\n",
            "Epoch 243/400, Batch 18/45, Loss: 0.005808917805552483\n",
            "Epoch 243/400, Batch 19/45, Loss: 0.007645849138498306\n",
            "Epoch 243/400, Batch 20/45, Loss: 0.0028118323534727097\n",
            "Epoch 243/400, Batch 21/45, Loss: 0.03491624444723129\n",
            "Epoch 243/400, Batch 22/45, Loss: 0.13278034329414368\n",
            "Epoch 243/400, Batch 23/45, Loss: 0.011302591301500797\n",
            "Epoch 243/400, Batch 24/45, Loss: 0.027134902775287628\n",
            "Epoch 243/400, Batch 25/45, Loss: 0.014110594987869263\n",
            "Epoch 243/400, Batch 26/45, Loss: 0.013117202557623386\n",
            "Epoch 243/400, Batch 27/45, Loss: 0.011564618907868862\n",
            "Epoch 243/400, Batch 28/45, Loss: 0.006099001970142126\n",
            "Epoch 243/400, Batch 29/45, Loss: 0.010309368371963501\n",
            "Epoch 243/400, Batch 30/45, Loss: 0.03991715610027313\n",
            "Epoch 243/400, Batch 31/45, Loss: 0.010173977352678776\n",
            "Epoch 243/400, Batch 32/45, Loss: 0.10840751975774765\n",
            "Epoch 243/400, Batch 33/45, Loss: 0.019644876942038536\n",
            "Epoch 243/400, Batch 34/45, Loss: 0.014148050919175148\n",
            "Epoch 243/400, Batch 35/45, Loss: 0.017971942201256752\n",
            "Epoch 243/400, Batch 36/45, Loss: 0.01450422964990139\n",
            "Epoch 243/400, Batch 37/45, Loss: 0.007267617154866457\n",
            "Epoch 243/400, Batch 38/45, Loss: 0.013284957036376\n",
            "Epoch 243/400, Batch 39/45, Loss: 0.02843393385410309\n",
            "Epoch 243/400, Batch 40/45, Loss: 0.010232997126877308\n",
            "Epoch 243/400, Batch 41/45, Loss: 0.03422420099377632\n",
            "Epoch 243/400, Batch 42/45, Loss: 0.017749344930052757\n",
            "Epoch 243/400, Batch 43/45, Loss: 0.008233118802309036\n",
            "Epoch 243/400, Batch 44/45, Loss: 0.004740889184176922\n",
            "Epoch 243/400, Batch 45/45, Loss: 0.012569156475365162\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val MSE:  1.5787227898836136 Best Val MSE:  0.9712213538587093\n",
            "Epoch:  244 , Time Elapsed:  193.8347954630852  mins\n",
            "Epoch 244/400, Batch 1/45, Loss: 0.006582473870366812\n",
            "Epoch 244/400, Batch 2/45, Loss: 0.025662308558821678\n",
            "Epoch 244/400, Batch 3/45, Loss: 0.025136293843388557\n",
            "Epoch 244/400, Batch 4/45, Loss: 0.029521631076931953\n",
            "Epoch 244/400, Batch 5/45, Loss: 0.013227599672973156\n",
            "Epoch 244/400, Batch 6/45, Loss: 0.015263933688402176\n",
            "Epoch 244/400, Batch 7/45, Loss: 0.010631497949361801\n",
            "Epoch 244/400, Batch 8/45, Loss: 0.021853383630514145\n",
            "Epoch 244/400, Batch 9/45, Loss: 0.11101523041725159\n",
            "Epoch 244/400, Batch 10/45, Loss: 0.008305605500936508\n",
            "Epoch 244/400, Batch 11/45, Loss: 0.008401856757700443\n",
            "Epoch 244/400, Batch 12/45, Loss: 0.04670996218919754\n",
            "Epoch 244/400, Batch 13/45, Loss: 0.010281898081302643\n",
            "Epoch 244/400, Batch 14/45, Loss: 0.021389808505773544\n",
            "Epoch 244/400, Batch 15/45, Loss: 0.010953390970826149\n",
            "Epoch 244/400, Batch 16/45, Loss: 0.03785032778978348\n",
            "Epoch 244/400, Batch 17/45, Loss: 0.01092514581978321\n",
            "Epoch 244/400, Batch 18/45, Loss: 0.011109961196780205\n",
            "Epoch 244/400, Batch 19/45, Loss: 0.021923236548900604\n",
            "Epoch 244/400, Batch 20/45, Loss: 0.02429976314306259\n",
            "Epoch 244/400, Batch 21/45, Loss: 0.0017566869501024485\n",
            "Epoch 244/400, Batch 22/45, Loss: 0.03588273376226425\n",
            "Epoch 244/400, Batch 23/45, Loss: 0.031645722687244415\n",
            "Epoch 244/400, Batch 24/45, Loss: 0.014312505722045898\n",
            "Epoch 244/400, Batch 25/45, Loss: 0.007367516867816448\n",
            "Epoch 244/400, Batch 26/45, Loss: 0.013815952464938164\n",
            "Epoch 244/400, Batch 27/45, Loss: 0.02406039461493492\n",
            "Epoch 244/400, Batch 28/45, Loss: 0.022377708926796913\n",
            "Epoch 244/400, Batch 29/45, Loss: 0.00719930324703455\n",
            "Epoch 244/400, Batch 30/45, Loss: 0.011287637054920197\n",
            "Epoch 244/400, Batch 31/45, Loss: 0.01445683091878891\n",
            "Epoch 244/400, Batch 32/45, Loss: 0.0053864712826907635\n",
            "Epoch 244/400, Batch 33/45, Loss: 0.006518224719911814\n",
            "Epoch 244/400, Batch 34/45, Loss: 0.00447023194283247\n",
            "Epoch 244/400, Batch 35/45, Loss: 0.020743073895573616\n",
            "Epoch 244/400, Batch 36/45, Loss: 0.012734401039779186\n",
            "Epoch 244/400, Batch 37/45, Loss: 0.009922035969793797\n",
            "Epoch 244/400, Batch 38/45, Loss: 0.008194344118237495\n",
            "Epoch 244/400, Batch 39/45, Loss: 0.03220200166106224\n",
            "Epoch 244/400, Batch 40/45, Loss: 0.009324290789663792\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4y952vHcYzIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "drive_dir = '/content/drive/MyDrive/Colab Notebooks/growth_monitoring/Estimation of Greenhouse Lettuce Growth Indices Based on a Two-Stage CNN Using RGB-D Images'\n",
        "drive_dir += '/model_weights'\n",
        "if not os.path.exists(drive_dir):\n",
        "    os.makedirs(drive_dir)\n",
        "\n",
        "for file in os.listdir(sav_dir):\n",
        "    shutil.copy(sav_dir + '/' + file, drive_dir)"
      ],
      "metadata": {
        "id": "FwwywCNcYx-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation"
      ],
      "metadata": {
        "id": "vo196DDGKgtS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the test dataset"
      ],
      "metadata": {
        "id": "5bBqkPJUKgtS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the PyTorch datalaoder the autonomous greenhouse dataset.\n",
        "testset = GreenhouseDataset(rgb_dir = RGB_Data_Dir,\n",
        "                            d_dir = Depth_Data_Dir,\n",
        "                            jsonfile_dir = JSON_Files_Dir,\n",
        "                            rgb_transforms = get_transforms(train=False, means=dataset.means[:3], stds=dataset.stds[:3]),\n",
        "                            d_transforms = get_transforms(train=False, means=dataset.means[3:], stds=dataset.stds[3:]))\n",
        "\n",
        "# Grab last 50 images as test dataset\n",
        "testset.df = testset.df[-50:]\n",
        "\n",
        "# Get testset_size\n",
        "testset_size = testset.df.shape[0]\n",
        "\n",
        "# Create test dataloader\n",
        "test_loader = torch.utils.data.DataLoader(testset,\n",
        "                                          batch_size = 50,\n",
        "                                          num_workers = 0,\n",
        "                                          shuffle = False)"
      ],
      "metadata": {
        "id": "LNiS2urzSs2j",
        "execution": {
          "iopub.status.busy": "2023-12-18T08:50:14.905955Z",
          "iopub.execute_input": "2023-12-18T08:50:14.906787Z",
          "iopub.status.idle": "2023-12-18T08:50:14.923799Z",
          "shell.execute_reply.started": "2023-12-18T08:50:14.906746Z",
          "shell.execute_reply": "2023-12-18T08:50:14.923058Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define loss functions for model evaluation"
      ],
      "metadata": {
        "id": "gKt_khHVKgtU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cri = NMSELoss()\n",
        "mse = nn.MSELoss()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-18T08:50:18.493320Z",
          "iopub.execute_input": "2023-12-18T08:50:18.494274Z",
          "iopub.status.idle": "2023-12-18T08:50:18.498774Z",
          "shell.execute_reply.started": "2023-12-18T08:50:18.494233Z",
          "shell.execute_reply": "2023-12-18T08:50:18.497796Z"
        },
        "trusted": true,
        "id": "h4_LV8DdKgtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the evaluation Loop"
      ],
      "metadata": {
        "id": "hCJLyzwyKgtn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation loop\n",
        "device=torch.device('cuda')\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "\n",
        "    device=torch.device('cuda')\n",
        "    model = PlantTraitModel()\n",
        "    model.to(device)\n",
        "    model.load_state_dict(torch.load(sav_dir + 'bestmodel.pth'))\n",
        "    model.eval()\n",
        "\n",
        "    ap=torch.zeros((0,4))\n",
        "    at=torch.zeros((0,4))\n",
        "\n",
        "    for rgb, depth, targets in test_loader:\n",
        "        rgb = rgb.to(device)\n",
        "        depth = depth.to(device)\n",
        "        targets = targets.to(device)\n",
        "        targets = targets[:, :2]\n",
        "        pred = model(rgb, depth)\n",
        "        # mse_loss=mse(preds, targets)\n",
        "        # nmse=criterion(preds, targets)\n",
        "        # nmse, pred=cri(preds, targets)\n",
        "        ap=torch.cat((ap, pred.detach().cpu()), 0)\n",
        "        at=torch.cat((at, targets.detach().cpu()), 0)\n",
        "\n",
        "\n",
        "    print('FW MSE: ', str(mse(ap[:,0],at[:,0]).tolist()))\n",
        "    print('DW MSE: ', str(mse(ap[:,1],at[:,1]).tolist()))\n",
        "    # print('H MSE: ', str(mse(ap[:,2],at[:,2]).tolist()))\n",
        "    # print('D MSE: ', str(mse(ap[:,3],at[:,3]).tolist()))\n",
        "#     print('LA MSE: ', str(mse(ap[:,4],at[:,4]).tolist()))\n",
        "    print('Overall NMSE: ', str(cri(ap,at).tolist()))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-18T08:55:19.566507Z",
          "iopub.execute_input": "2023-12-18T08:55:19.566878Z",
          "iopub.status.idle": "2023-12-18T08:55:22.787607Z",
          "shell.execute_reply.started": "2023-12-18T08:55:19.566839Z",
          "shell.execute_reply": "2023-12-18T08:55:22.786744Z"
        },
        "trusted": true,
        "id": "DkNd7JkvKgto",
        "outputId": "15efb756-e004-4e52-dae4-57715b09eda7"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "FW MSE:  1406.3551025390625\nDW MSE:  2.855520248413086\nH MSE:  30.06348419189453\nD MSE:  13.6848783493042\nOverall NMSE:  0.2702009975910187\n",
          "output_type": "stream"
        }
      ]
    }
  ]
}